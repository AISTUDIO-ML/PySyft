{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "674378fe",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99df4a7c",
   "metadata": {},
   "source": [
    "In the remote data science landscape, the data science and machine learning tasks are collaborated between two main actors\n",
    " - Data Owner\n",
    " - Data Scientist\n",
    " \n",
    "The network that facilitates this collaboration is called **Domain Server** or **Domain Node**. \n",
    " \n",
    "As the name suggests, a **Data Owner** owns the data that will be used for remote data science. They make their datasets available for study in a secured and protected way to an outside party they may or may not fully trust to have good intentions. This outside party is usually a data scientist.\n",
    "\n",
    "**Data Scientists** are end users who desire to perform computations or answer a specific question using one or more data owners' secured datasets with remote execution. \n",
    "\n",
    "It is important to note that the people charged with protecting data (Data Owners), should not be the same people (Data Scientists) who's job is to extract meaningful value from the data. If they were the same person, their conflict of interest provides too many opportunities for things to go wrong. \n",
    "\n",
    "This tutorial will demonstrate how a Data Owner can launch their own Domain Server and securely host private datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57f62ac",
   "metadata": {},
   "source": [
    "![caption](./files/big-arch.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6222ca",
   "metadata": {},
   "source": [
    "## Required Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7de0014",
   "metadata": {},
   "source": [
    "There are three main components that work together to orchestrate the remote data science between a data owner and data scientists. \n",
    "\n",
    "- PySyft: Privacy-Preserving Library\n",
    "\n",
    "- PyGrid: Networking and Management Platform\n",
    "\n",
    "- HAGrid: Deployment and Command Line Tool\n",
    "\n",
    "**PySyft** is the main library containing a set of data serialization and remote code execution APIs which mimic existing popular Data Science tools while working interchangeably with existing popular data types. One of the ways this works is by providing a special Proxy object in Python which acts like a Network Pointer to a remote object on a Domain Server. These Pointers look, act and feel just like real objects, but cannot be copied or viewed without special permissions. Therefore, PySyft enables execution of Data Science operations without sending in raw code or copying data from the data owners' server. The python package for PySyft is called `syft`.\n",
    "\n",
    "**PyGrid** is the server component of PySyft. PyGrid nodes are referred by their type, e.g. domain server or network server. These are cross-platform servers running where the data lives (a.k.a. at the data owners' premise).\n",
    "\n",
    "Finally, **HAGrid** is a very handy `cli` tool which takes care of all the heavy-lifting in the background and makes deploying a Domain or Network server very easy. It also comes with an interactive UI. The python package for HAGrid is called `hagrid`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5abd0d3",
   "metadata": {},
   "source": [
    "## Getting Started"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7293c096",
   "metadata": {},
   "source": [
    "The purpose of this tutorial is to help you install everything you need to run a Domain node deployed in your personal machine (`localhost`) or deployed on Azure. We will also be installing everything you might need to run Jupyter notebooks with PySyft installed, such as if you’re pretending to be both Data Owner and Data Scientist as a part of an experiment. \n",
    "\n",
    "We will be setting up the following dependencies before installing `syft` and `hagrid`.\n",
    "\n",
    "- Python >=3.9\n",
    "- pip\n",
    "- Conda\n",
    "- Jupyter notebook\n",
    "- Docker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1df014",
   "metadata": {},
   "source": [
    "### Installation on Linux\n",
    "\n",
    "This section is to help you install and be able to deploy a Domain Node on Ubuntu Linux, with a version of `20.04.03` or newer, in the simplest way possible. If you have a different distribution other than Ubuntu, just replace the `apt` & `apt-get` with your package manager.\n",
    "\n",
    "#### 1. Launching a Terminal Instance\n",
    "We will use the Linux Terminal to install all the prerequisites and launch the domain. A quick way to launch the terminal is by pressing Ctrl+Alt+T.\n",
    "\n",
    "#### 2. Installing Python 3.9 or newer\n",
    "We’ll be working with Python 3.9 or newer. To check if you have it installed, you may run:\n",
    "\n",
    "`python3 --version`\n",
    "\n",
    "Your output should looks something like Python `3.x.y` where x>=9.\n",
    "\n",
    "If you don’t have the correct version of Python, installing it is as easy as running the following:\n",
    "\n",
    "```\n",
    "sudo apt update\n",
    "sudo apt install python3.9\n",
    "python3 --version\n",
    "```\n",
    "\n",
    "#### 3. Installing and using Pip\n",
    "\n",
    "Pip is the most widely used package installer for Python and will help us to install the required dependencies MUCH easier. You can install it by running the following:\n",
    "\n",
    "`python -m ensurepip --upgrade`\n",
    "\n",
    "If you already have it installed, you can check to make sure it’s the latest version by running:\n",
    "\n",
    "`python -m pip install --upgrade pip`\n",
    "\n",
    "Your output should looks something like `Requirement already satisfied: pip in <package-dir>.`\n",
    "\n",
    "#### 4. Conda and setting up a virtual environment\n",
    "\n",
    "Conda is a package manager that helps you to easily install a lot of data science and machine learning packages, but also to create a separated environment when a certain set of dependencies need to be installed. To install Conda, you can:\n",
    "\n",
    "a. Download the [Anaconda installer](https://www.anaconda.com/products/individual#Downloads).\n",
    "\n",
    "b. Run the following code, modifying it depending on where you downloaded the installer (e.g. `~/Downloads/`):\n",
    "\n",
    "`bash ~/Downloads/Anaconda3-2020.02-Linux-x86_64.sh`\n",
    "\n",
    "The naming might be different given it could be a newer version of Anaconda.\n",
    "\n",
    "c. Create a new env specifying the Python version (we recommend Python 3.8/3.9) in the terminal:\n",
    "\n",
    "```\n",
    "conda create -n syft_env python=3.9\n",
    "conda activate syft_env\n",
    "```\n",
    "\n",
    "d. To exit the env, you can run:\n",
    "\n",
    "`conda deactivate`\n",
    "\n",
    "#### 5. Install Jupyter Notebook\n",
    "\n",
    "A very convenient way to interact with a deployed node is via Python, using a Jupyter Notebook. You can install it by running:\n",
    "\n",
    "`pip install jupyterlab`\n",
    "\n",
    "If you encounter issues, you can also install it using Conda:\n",
    "\n",
    "`conda install -c conda-forge notebook`\n",
    "\n",
    "To launch the Jupyter Notebook, you can run the following in your terminal:\n",
    "\n",
    "`jupyter notebook`\n",
    "\n",
    "#### 6. Installing and configuring Docker\n",
    "\n",
    "[Docker](https://docs.docker.com/get-started/overview/) is a framework which allows us to separate the infrastructure needed to run PySyft in an isolated environment called a `container` which you can use off the shelf, without many concerns. If it sounds complicated, please don’t worry, we will walk you through all steps, and you’ll be done in no time! Additionally, we will also use [Docker Composite V2](https://docs.docker.com/compose/), which allows us to run multi-container applications.\n",
    "\n",
    "a. Install Docker by running this command:\n",
    "\n",
    "`sudo apt-get upgrade docker & docker run hello-world`\n",
    "\n",
    "b. Install Docker Composite V2 as described [here](https://docs.docker.com/compose/cli-command/#installing-compose-v2).\n",
    "\n",
    "c. Run the below command to verify the install:\n",
    "\n",
    "`docker compose version`\n",
    "\n",
    "You should see somthing like `Docker Compose version 2.x.y` in the output when runnning the above command.\n",
    "\n",
    "d. If you see something else, go through the [instructions here](https://www.rockyourcode.com/how-to-install-docker-compose-v2-on-linux-2021/) or if you are using Linux, you can try to do:\n",
    "\n",
    "```\n",
    "mkdir -p ~/.docker/cli-plugins\n",
    "curl -sSL https://github.com/docker/compose/releases/download/v2.2.3/docker-compose-linux-x86_64 -o ~/.docker/cli-plugins/docker-compose\n",
    "chmod +x ~/.docker/cli-plugins/docker-compose\n",
    "```\n",
    "\n",
    "e. Also, make sure you can run without sudo:\n",
    "\n",
    "```\n",
    "echo $USER //(should return your username)\n",
    "sudo usermod -aG docker $USER\n",
    "```\n",
    "\n",
    "#### 7. Install PySyft and Hagrid\n",
    "Finally, to install the OpenMined stack that you need in order to deploy a node, please run:\n",
    "\n",
    "`pip install -U syft hagrid --pre`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d05fedc",
   "metadata": {},
   "source": [
    "## Launch a Domain Server as a Data Owner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab54a022",
   "metadata": {},
   "source": [
    "The concept of Remote Data Science starts with a server-based model called Domain Server. It allows data owners to upload their private data into these servers and create an account with a username and password for Data Scientist.\n",
    "\n",
    "To reiterate, the advantage of using a Domain Server is that as a data owner, you can catalyze the impact your dataset can have by allowing\n",
    "\n",
    "- a Data Scientist to only get answers to the types of questions you allow them to\n",
    "- and get those answers without needing to directly access or have a copy of your data\n",
    "\n",
    "![caption](https://openmined.github.io/PySyft/_images/00-deploy-domain-00.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4512d1",
   "metadata": {},
   "source": [
    "To launch a domain node, there are three things that you need to know:\n",
    "    \n",
    "1. **What type of node do you need to deploy?** There are two different types of nodes: `Domain Node` and `Network Node`. By default, HAGrid launches the primary node that is our Domain Node.\n",
    "\n",
    "\n",
    "2. **Where are you going to launch this node to?** We need to specify that we want to launch it to the docker container at port `8081.\n",
    "\n",
    "\n",
    "3. **What is the name of your Domain Node going to be?** For that, please specify the DOMAIN_NAME to your preference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4326ffe4",
   "metadata": {},
   "source": [
    "Now the final step is to launch a domain server. For that please follow these steps:\n",
    "\n",
    "1. Start Docker (from terminal or using Docker Desktop)\n",
    "2. Run the following one-line command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "513c4c2c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K✅ Updated HAGrid from branch: dev from branch: dev\u001b[0m0m\n",
      "\u001b[2K\u001b[32m⠼\u001b[0m \u001b[1;34mUpdating HAGrid from branch: dev\u001b[0m\n",
      "\u001b[2K\u001b[32m⠴\u001b[0m \u001b[1;34mChecking for Docker Service\u001b[0m   ice\u001b[0m   \n",
      "\u001b[1A\u001b[2K✅ Docker service is running\n",
      "✅ Git 2.32.1\n",
      "✅ Docker 20.10.17\n",
      "✅ Docker Compose 2.7.0\n",
      "\n",
      "\n",
      " _   _       _     _                 _   _                       _\n",
      "| | | |     | |   | |               | | | |                     | |\n",
      "| |_| | ___ | | __| |   ___  _ __   | |_| | __ _ _ __ _ __ _   _| |\n",
      "|  _  |/ _ \\| |/ _` |  / _ \\| '_ \\  |  _  |/ _` | '__| '__| | | | |\n",
      "| | | | (_) | | (_| | | (_) | | | | | | | | (_| | |  | |  | |_| |_|\n",
      "\\_| |_/\\___/|_|\\__,_|  \\___/|_| |_| \\_| |_/\\__,_|_|  |_|   \\__, (_)\n",
      "                                                            __/ |\n",
      "                                                           |___/\n",
      "        \n",
      "Launching a PyGrid Domain node on port 8081!\n",
      "\n",
      "  - NAME: test_domain\n",
      "  - RELEASE: production\n",
      "  - TYPE: domain\n",
      "  - DOCKER_TAG: latest\n",
      "  - HAGRID_VERSION: \n",
      "  - PORT: 8081\n",
      "  - DOCKER COMPOSE: v2.7.0\n",
      "\n",
      "\n",
      "\u001b[1;32m⠋\u001b[0m\u001b[1;34m Launching Containers \u001b[0m\u001b[1;32m \u001b[0m\n",
      "\u001b[2K  ✅ \u001b[1;32mPulling [11 / 11]\u001b[0m \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100.00%   \u001b[0m;5;237m━━━\u001b[0m \u001b[35m90.91%   \u001b[0m  \u001b[0m\n",
      "\u001b[2K  ✅ \u001b[1;32mLaunching [11 / 11]\u001b[0m \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100.00%   \u001b[0m8;5;237m━━━\u001b[0m \u001b[35m90.91%   \u001b[0m  \u001b[0m\n",
      "\u001b[?25h\n",
      "\u001b[1;32m⠋\u001b[0m\u001b[1;34m Checking node API \u001b[0m\u001b[1;32m \u001b[0m   \n",
      "\u001b[2K✅ test_domain Domain Containers Createdtainer Creation\u001b[0m0m\n",
      "\u001b[2K✅ Backendm \u001b[1;38;5;202mStarting Backend\u001b[0meation\u001b[0m\n",
      "\u001b[2K✅ Startup Complete2mStarting Backend\u001b[0m\n",
      "\u001b[2K\u001b[32m⠏\u001b[0m \u001b[1;38;5;202mStarting Backend\u001b[0m\n",
      "\u001b[1A\u001b[2K┏━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━┓\n",
      "┃\u001b[1m \u001b[0m\u001b[1mPyGrid   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mInfo                                     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m600\u001b[0m\u001b[1m \u001b[0m┃\n",
      "┡━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━┩\n",
      "│\u001b[35m \u001b[0m\u001b[35mUI (βeta)\u001b[0m\u001b[35m \u001b[0m│ http://localhost:8081/login               │ ✅  │\n",
      "│\u001b[35m \u001b[0m\u001b[35mapi      \u001b[0m\u001b[35m \u001b[0m│ http://localhost:8081/api/v1/openapi.json │ ✅  │\n",
      "└───────────┴───────────────────────────────────────────┴─────┘\n",
      "╭─────────────────────────────────────────────────────────────╮\n",
      "│ 🚨🚨🚨 To view container logs run \u001b[1;31m hagrid logs test_domain \u001b[0m │\n",
      "╰─────────────────────────────────────────────────────────────╯\n"
     ]
    }
   ],
   "source": [
    "DOMAIN_NAME = 'test_domain' # edit DOMAIN_NAME as per your preference\n",
    "\n",
    "!hagrid launch {DOMAIN_NAME} domain to docker:8081 --tag=latest --tail=false\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737e90f8",
   "metadata": {},
   "source": [
    "While this command runs, you will see various `volumes` and `containers` being created. Once this step is complete, let's move on to the next step, where we will learn to monitor the health of our Domain Server."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5441d33a",
   "metadata": {},
   "source": [
    "## Monitor Domain Server"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4e9ecc",
   "metadata": {},
   "source": [
    "One exciting benefit of HAGrid is that it makes it easier for your organization/ IT department to monitor & maintain the status of your system as you move forward with other steps. Let’s do a quick health check to ensure the Domain is up and running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "70aeed85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┏━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━┓\r\n",
      "┃\u001b[1m \u001b[0m\u001b[1mPyGrid   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mInfo                                     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m  \u001b[0m\u001b[1m \u001b[0m┃\r\n",
      "┡━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━┩\r\n",
      "│\u001b[35m \u001b[0m\u001b[35mUI (βeta)\u001b[0m\u001b[35m \u001b[0m│ http://localhost:8081/login               │ ✅ │\r\n",
      "│\u001b[35m \u001b[0m\u001b[35mapi      \u001b[0m\u001b[35m \u001b[0m│ http://localhost:8081/api/v1/openapi.json │ ✅ │\r\n",
      "└───────────┴───────────────────────────────────────────┴────┘\r\n"
     ]
    }
   ],
   "source": [
    "!hagrid check localhost:8081"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df14fdfc",
   "metadata": {},
   "source": [
    "If your output is similar to the above image, voila! Your very own Domain Server was just born. When it’s ready, you will see the following in the output:\n",
    "\n",
    "- `host`: IP address of the launched Domain Node.\n",
    "\n",
    "- `UI (βeta)`: Link to an admin portal that allows you to control Domain Node from a web browser.\n",
    "\n",
    "- `api`: Application layer that we run in our notebooks to make the experience more straightforward and intuitive.\n",
    "\n",
    "- `ssh`: Key to get into virtual machine.\n",
    "\n",
    "- `jupyter`: Notebook environment you will use to upload your datasets.\n",
    "\n",
    "Congratulations 👏 You have now successfully deployed a Domain Server!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb370df7",
   "metadata": {},
   "source": [
    "## Uploading Private Data to a Domain Server"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174b0acc",
   "metadata": {},
   "source": [
    "At this point, you have successfully deployed a Domain Server that represents your organization’s private data server. Now as promised, you can upload your private data the Domain Server and make it securely available for remote data science. In this section, you will learn how to upload data to your new domain server, which involves annotating and doing ETL before uploading.\n",
    "\n",
    "#### Steps to Upload Private Data\n",
    "\n",
    " - Preprocessing of Data\n",
    "\n",
    " - Marking it with correct metadata\n",
    "\n",
    " - Uploading data to Domain Server\n",
    "\n",
    "![caption](https://openmined.github.io/PySyft/_images/01-upload-data-00.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8af19be",
   "metadata": {},
   "source": [
    "### Import Syft"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc67b6d",
   "metadata": {},
   "source": [
    "To utilize the privacy-enhancing features offered in PyGrid and to communicate with your domain server, first you need to import `syft`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a8184ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Syft is imported\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import syft as sy\n",
    "    print(\"Syft is imported\")\n",
    "    \n",
    "except:\n",
    "    print(\"Syft is not installed. Please follow the Getting Started section above.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae451404",
   "metadata": {},
   "source": [
    "### Log into Domain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f71be0a",
   "metadata": {},
   "source": [
    "By default, only the Domain server Admin can upload data, so to upload your data, you will need to first login as the admin. Upload data permissions can be customized after logging into the domain server.\n",
    "\n",
    "To login to your Domain server, you will need to define which Domain you are logging into and who you are. In this case, it will take the form of:\n",
    "\n",
    "- IP Address of the domain host\n",
    "\n",
    "- Your user account Email and Password\n",
    "\n",
    "**WARNING**: Please change the default username and password below to a more secure and private combination of your preference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aedf00a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93mWARNING:\u001b[0m CHANGE YOUR USERNAME AND PASSWORD!!! \n",
      "\n",
      "Anyone can login as an admin to your node right now because your password is still the default PySyft username and password!!!\n",
      "\n",
      "Connecting to localhost... done! \t Logging into test_domain... done!\n",
      "\n",
      "**Warning**: The syft version on your system and the node are different.\n",
      "Version on your system: 0.7.0-beta.59\n",
      "Version on the node: 0.7.0-beta.62\n",
      "\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    domain_client = sy.login(\n",
    "      port=8081,\n",
    "      email=\"info@openmined.org\",\n",
    "      password=\"changethis\"\n",
    "   )\n",
    "except Exception as e:\n",
    "    print(\"Unable to login. Please check your domain is up with `!hagrid check localhost:8081`\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc3cad4",
   "metadata": {},
   "source": [
    "You have just logged in to your Domain! It is highly recommended to change the credentials before moving forward. You can do so directly from the server UI located at the address defined as UI (βeta) in the Monitor Domain Server section. Steps to change the default admin credentials for Domain Owner are shown below.\n",
    "![caption](https://openmined.github.io/PySyft/_images/01-upload-data-01.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f39bfbc",
   "metadata": {},
   "source": [
    "### Preprocessing of Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24747293",
   "metadata": {},
   "source": [
    "For this tutorial, we will use a simple dataset of four peoples `ages` and `hourly income`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b3d8eaa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ID  Age  Hourly Income\n",
      "0  011   40             20\n",
      "1  015   39             25\n",
      "2  022    9             32\n",
      "3  034    8             18\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import pandas as pd\n",
    "    data = {'ID': ['011', '015', '022', '034'],\n",
    "         'Age': [40, 39, 9, 8],\n",
    "         'Hourly Income': [20, 25, 32, 18]  }\n",
    "\n",
    "    dataset = pd.DataFrame(data)\n",
    "    print(dataset.head())\n",
    "    \n",
    "except Exception:\n",
    "    print(\"Install the latest version of Pandas using the command: !pip install pandas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9740f6c4",
   "metadata": {},
   "source": [
    "### Marking data with correct metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9b76cc",
   "metadata": {},
   "source": [
    "Now that we have our dataset, we need to annotate it with privacy-specific metadata called `Auto DP metadata`. Auto DP metadata allows the PySyft library to protect and adjust the visibility different Data Scientists will have into any one of our data subjects. Data Subjects are the entities whose privacy we want to protect. So, in this case, they are the individual four people. \n",
    "\n",
    "In order to protect the privacy of the people within our dataset we first need to specify who those people are. In this example we have created a column with unique ID’s for each person in this dataset.\n",
    "\n",
    "#### Important Steps\n",
    "\n",
    "- Data subjects are entities whose privacy we want to protect\n",
    "\n",
    "- Each feature needs to define the appropriate minimum and maximum ranges\n",
    "\n",
    "- When defining min and max values, we are actually defining the theoretical amount of values that could be learned about that aspect.\n",
    "\n",
    "- To help obscure the variables someone may learn about these datasets we then need to set an appropriate lower_bound to the lowest possible persons age (0), and the upper_bound to the highest possible (mostly) persons age (100). Similar procedure should be followed for hourly income data.\n",
    "\n",
    "If your project has a `training set`, `validation set` and `test set`, you must annotate each data set with Auto DP metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c19a9a86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor annotated with DP Metadata!\n",
      "You can upload this Tensor to a domain node by calling `<domain_client>.load_dataset` and passing in this tensor as an asset.\n",
      "Tensor annotated with DP Metadata!\n",
      "You can upload this Tensor to a domain node by calling `<domain_client>.load_dataset` and passing in this tensor as an asset.\n"
     ]
    }
   ],
   "source": [
    "data_subjects = sy.DataSubjectArray.from_objs(dataset[\"ID\"])\n",
    "\n",
    "age_data = sy.Tensor(dataset[\"Age\"]).annotate_with_dp_metadata(\n",
    "   lower_bound=0, upper_bound=100, data_subjects=data_subjects\n",
    ")\n",
    "hourly_income_data = sy.Tensor(dataset[\"Hourly Income\"]).annotate_with_dp_metadata(\n",
    "   lower_bound=10, upper_bound=500, data_subjects=data_subjects\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce89a0c",
   "metadata": {},
   "source": [
    "### Uploading Data to Domain Server"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8c8e2a",
   "metadata": {},
   "source": [
    "Once you have prepared your data, it’s time to upload it to the Domain Server. To help Data Scientists later search and discover our datasets, we will add details like a name and a description of what this dataset represents.\n",
    "\n",
    "If your project has a train, validation and test set, you need to add them as `assets`. In this case, `Age` and `Hourly Income` columns are assets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bf8a1120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\r",
      "Loading dataset... checking assets...\r",
      "Loading dataset... checking dataset name for uniqueness...\r",
      "Loading dataset... checking dataset name for uniqueness...                                                                                                                    \r",
      "Loading dataset... checking asset types...                              \r",
      "Loading dataset... uploading...🚀                        "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "kj/filesystem-disk-unix.c++:1690: warning: PWD environment variable doesn't match current directory; pwd = /Users/zarreennaowalreza/Documents/openmined-new\n",
      "Uploading `Age_Data`: 100%|\u001b[32m███████████████████████████████████████████\u001b[0m| 1/1 [00:00<00:00, 58.35it/s]\u001b[0m\n",
      "Uploading `Hourly_Income`: 100%|\u001b[32m█████████████████████████████████████\u001b[0m| 1/1 [00:00<00:00, 128.80it/s]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Dataset is uploaded successfully !!! 🎉\n",
      "\n",
      "Run `<your client variable>.datasets` to see your new dataset loaded into your machine!\n"
     ]
    }
   ],
   "source": [
    "domain_client.load_dataset(\n",
    "   name=\"Age_Income_Dataset\",\n",
    "   assets={\n",
    "      \"Age_Data\": age_data,\n",
    "      \"Hourly_Income\": hourly_income_data\n",
    "   },\n",
    "   description=\"Our dataset contains the Ages and Hourly Incomes of four employees with unique ID's. There are 3 columns and 4 rows in our dataset.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5931691b",
   "metadata": {},
   "source": [
    "### Checking the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16fcd3c5",
   "metadata": {},
   "source": [
    "To check the dataset you uploaded to the Domain Server, please run the below command, and it will list all the datasets on this Domain with their Names, Descriptions, Assets, and Unique IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9995cde9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "                #myInput {\n",
       "                  background-position: 10px 12px; /* Position the search icon */\n",
       "                  background-repeat: no-repeat; /* Do not repeat the icon image */\n",
       "                  background-color: #bbb;\n",
       "                  width: 98%; /* Full-width */\n",
       "                  font-size: 14px; /* Increase font-size */\n",
       "                  padding: 12px 20px 12px 40px; /* Add some padding */\n",
       "                  border: 1px solid #ddd; /* Add a grey border */\n",
       "                  margin-bottom: 12px; /* Add some space below the input */\n",
       "                }\n",
       "\n",
       "                #myTable {\n",
       "                  border-collapse: collapse; /* Collapse borders */\n",
       "                  width: 100%; /* Full-width */\n",
       "                  border: 1px solid #ddd; /* Add a grey border */\n",
       "                  font-size: 14px; /* Increase font-size */\n",
       "                }\n",
       "\n",
       "                #myTable th, #myTable td {\n",
       "                  text-align: left; /* Left-align text */\n",
       "                  padding: 10px; /* Add padding */\n",
       "                }\n",
       "\n",
       "                #myTable tr {\n",
       "                  /* Add a bottom border to all table rows */\n",
       "                  border-bottom: 1px solid #ddd;\n",
       "                }\n",
       "\n",
       "                #myTable tr.header, #myTable tr:hover {\n",
       "                  /* Add a grey background color to the table header and on hover */\n",
       "                  background-color: #777;\n",
       "                }\n",
       "                </style>\n",
       "\n",
       "                <table id=\"myTable\" style=\"width:1000px\">\n",
       "                  <tr class=\"header\">\n",
       "                    <th style=\"width:30px\">Idx</th>\n",
       "                    <th style=\"width:20%;\">Name</th>\n",
       "                    <th style=\"width:35%;\">Description</th>\n",
       "                    <th style=\"width:20%;\">Assets</th>\n",
       "                    <th style=\"width:300px;\">Id</th>\n",
       "                  </tr>\n",
       "                \n",
       "\n",
       "          <tr>\n",
       "            <td>[0]</td>\n",
       "            <td>Customer data in a Mall in Canada</td>\n",
       "            <td>This dataset contains information about 200 customers from a Mall in Canada. Columnsinclude Age, Annual Income (k$), Spending Score (1-100), Male, Female</td>\n",
       "            <td>[\"age\"] -> Tensor<br /><br />[\"income\"] -> Tensor<br /><br />[\"spend\"] -> Tensor<br /><br />...<br /><br /></td>\n",
       "            <td>b9619f8b-4543-412d-8dee-3a969f9c598f</td>\n",
       "          </tr>\n",
       "\n",
       "          <tr>\n",
       "            <td>[1]</td>\n",
       "            <td>Customer data in a Mall in Canada</td>\n",
       "            <td>This dataset contains information about 200 customers from a Mall in Canada. Columnsinclude Age, Annual Income (k$), Spending Score (1-100), Male, Female</td>\n",
       "            <td>[\"age\"] -> Tensor<br /><br />[\"income\"] -> Tensor<br /><br />[\"spend\"] -> Tensor<br /><br />...<br /><br /></td>\n",
       "            <td>b03741fe-a7e1-4c0d-bb97-dc5941b6402a</td>\n",
       "          </tr>\n",
       "\n",
       "          <tr>\n",
       "            <td>[2]</td>\n",
       "            <td>Customer data in a Mall in Canada</td>\n",
       "            <td>This dataset contains information about 200 customers from a Mall in Canada. Columnsinclude Age, Annual Income (k$), Spending Score (1-100), Male, Female</td>\n",
       "            <td>[\"age\"] -> Tensor<br /><br />[\"income\"] -> Tensor<br /><br />[\"spend\"] -> Tensor<br /><br />...<br /><br /></td>\n",
       "            <td>96a79430-6a3b-4d24-ba88-ae5881bf6b6a</td>\n",
       "          </tr>\n",
       "\n",
       "          <tr>\n",
       "            <td>[3]</td>\n",
       "            <td>Customer data in a Mall in Canada</td>\n",
       "            <td>This dataset contains information about 200 customers from a Mall in Canada. Columnsinclude Age, Annual Income (k$), Spending Score (1-100), Male, Female</td>\n",
       "            <td>[\"age\"] -> Tensor<br /><br />[\"income\"] -> Tensor<br /><br />[\"spend\"] -> Tensor<br /><br />...<br /><br /></td>\n",
       "            <td>9fc2dc1c-2ce6-4153-a32e-b636ba36d475</td>\n",
       "          </tr>\n",
       "\n",
       "          <tr>\n",
       "            <td>[4]</td>\n",
       "            <td>Age_Income_Dataset</td>\n",
       "            <td>Our dataset contains the Ages and Hourly Incomes of four employees with unique ID's. There are 3 columns and 4 rows in our dataset.</td>\n",
       "            <td>[\"Age_Data\"] -> Tensor<br /><br />[\"Hourly_Income\"] -> Tensor<br /><br /></td>\n",
       "            <td>5fa28a75-2f5c-42c3-a2f0-7f387a648d23</td>\n",
       "          </tr>\n",
       "        </table>\n",
       "\n",
       "        <script>\n",
       "        function myFunction() {\n",
       "          // Declare variables\n",
       "          var input, filter, table, tr, td, i, txtValue;\n",
       "          input = document.getElementById(\"myInput\");\n",
       "          filter = input.value.toUpperCase();\n",
       "          table = document.getElementById(\"myTable\");\n",
       "          tr = table.getElementsByTagName(\"tr\");\n",
       "\n",
       "          // Loop through all table rows, and hide those who don't match the search query\n",
       "          for (i = 0; i < tr.length; i++) {\n",
       "            name_td = tr[i].getElementsByTagName(\"td\")[1];\n",
       "            desc_td = tr[i].getElementsByTagName(\"td\")[2];\n",
       "            asset_td = tr[i].getElementsByTagName(\"td\")[3];\n",
       "            id_td = tr[i].getElementsByTagName(\"td\")[4];\n",
       "            if (name_td || desc_td || asset_td || id_td) {\n",
       "              name_txtValue = name_td.textContent || name_td.innerText;\n",
       "              desc_txtValue = desc_td.textContent || name_td.innerText;\n",
       "              asset_txtValue = asset_td.textContent || name_td.innerText;\n",
       "              id_txtValue = id_td.textContent || name_td.innerText;\n",
       "              name_bool = name_txtValue.toUpperCase().indexOf(filter) > -1;\n",
       "              desc_bool = desc_txtValue.toUpperCase().indexOf(filter) > -1;\n",
       "              asset_bool = asset_txtValue.toUpperCase().indexOf(filter) > -1;\n",
       "              id_bool = id_txtValue.toUpperCase().indexOf(filter) > -1;\n",
       "              if (name_bool || desc_bool || asset_bool || id_bool) {\n",
       "                tr[i].style.display = \"\";\n",
       "              } else {\n",
       "                tr[i].style.display = \"none\";\n",
       "              }\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "        </script>"
      ],
      "text/plain": [
       "<syft.core.node.common.client_manager.dataset_api.DatasetRequestAPI at 0x294050d00>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "domain_client.datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2ac80f6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: Age_Income_Dataset\n",
      "Description: Our dataset contains the Ages and Hourly Incomes of four employees with unique ID's. There are 3 columns and 4 rows in our dataset.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "        #myInput {\n",
       "          background-position: 10px 12px; /* Position the search icon */\n",
       "          background-repeat: no-repeat; /* Do not repeat the icon image */\n",
       "          background-color: #bbb;\n",
       "          width: 98%; /* Full-width */\n",
       "          font-size: 14px; /* Increase font-size */\n",
       "          padding: 12px 20px 12px 40px; /* Add some padding */\n",
       "          border: 1px solid #ddd; /* Add a grey border */\n",
       "          margin-bottom: 12px; /* Add some space below the input */\n",
       "        }\n",
       "\n",
       "        #myTable {\n",
       "          border-collapse: collapse; /* Collapse borders */\n",
       "          width: 50%; /* Full-width */\n",
       "          border: 1px solid #ddd; /* Add a grey border */\n",
       "          font-size: 14px; /* Increase font-size */\n",
       "        }\n",
       "\n",
       "        #myTable th, #myTable td {\n",
       "          text-align: left; /* Left-align text */\n",
       "          padding: 10px; /* Add padding */\n",
       "        }\n",
       "\n",
       "        #myTable tr {\n",
       "          /* Add a bottom border to all table rows */\n",
       "          border-bottom: 1px solid #ddd;\n",
       "        }\n",
       "\n",
       "        #myTable tr.header, #myTable tr:hover {\n",
       "          /* Add a grey background color to the table header and on hover */\n",
       "          background-color: #777;\n",
       "        }\n",
       "        </style>\n",
       "\n",
       "        <table id=\"myTable\">\n",
       "          <tr class=\"header\">\n",
       "            <th style=\"width:15%;\">Asset Key</th>\n",
       "            <th style=\"width:20%;\">Type</th>\n",
       "            <th style=\"width:10%;\">Shape</th>\n",
       "          </tr>\n",
       "        \n",
       "\n",
       "              <tr>\n",
       "            <td>[\"Age_Data\"]</td>\n",
       "            <td>Tensor</td>\n",
       "            <td>(4,)</td>\n",
       "          </tr>\n",
       "\n",
       "              <tr>\n",
       "            <td>[\"Hourly_Income\"]</td>\n",
       "            <td>Tensor</td>\n",
       "            <td>(4,)</td>\n",
       "          </tr>\n",
       "        </table>\n",
       "\n",
       "        "
      ],
      "text/plain": [
       "<syft.core.node.common.client_manager.dataset_api.Dataset at 0x29366fca0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "domain_client.datasets[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7eb54b0",
   "metadata": {},
   "source": [
    "Awesome 👏 !! You have uploaded the dataset onto your Domain Server!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a820b37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f0a9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "- Overview (Data Owner, Data Scientist)\n",
    "- PySyft, PyGrid, HAGrid short intro \n",
    "- The picture demonstrating the whole landscape\n",
    "- Getting Started\n",
    "- Install pre-requisite libraries\n",
    "- Install PySyft and Hagrid\n",
    "- Data Owner Side: Launch a Domain Server\n",
    "- Checking your Domain Server\n",
    "- Upload Private Data to a Domain Server\n",
    "- (Optional) Create an user account for data scientist"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
