{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aaf8e073-2d63-4e1a-bb47-ff93218ae1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import syft as sy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ddf14148-1d37-486a-a898-b92c6d79270b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from syft.core.adp.data_subject_ledger import DataSubjectLedger as DSL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5f3ae00-629e-4aea-a419-840a7603c1ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[syft.core.adp.data_subject_ledger.DataSubjectLedger,\n",
       " syft.core.adp.abstract_ledger_store.AbstractDataSubjectLedger,\n",
       " object]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DSL.mro()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b1cc5d9-59ed-4e65-a7f6-59453e2b693d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# future\n",
    "from __future__ import annotations\n",
    "\n",
    "# stdlib\n",
    "from functools import partial\n",
    "import os\n",
    "from pathlib import Path\n",
    "import time\n",
    "from typing import Any\n",
    "from typing import Callable\n",
    "from typing import Optional\n",
    "from typing import TYPE_CHECKING\n",
    "from typing import Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ebc5b0ce-0f39-49dd-9340-0e1a5cc27f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# third party\n",
    "from typing_extensions import Final\n",
    "\n",
    "# relative\n",
    "# from ...logger import info\n",
    "\n",
    "if TYPE_CHECKING:\n",
    "    # stdlib\n",
    "    from dataclasses import dataclass\n",
    "else:\n",
    "    from flax.struct import dataclass\n",
    "\n",
    "# third party\n",
    "import jax\n",
    "from jax import numpy as jnp\n",
    "from nacl.signing import VerifyKey\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize_scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4082ac-3215-4c6e-a7d0-29a2505f74e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# relative\n",
    "from ...core.node.common.node_manager.user_manager import RefreshBudgetException\n",
    "from ...lib.numpy.array import capnp_deserialize\n",
    "from ...lib.numpy.array import capnp_serialize\n",
    "from ..common.serde.capnp import CapnpModule\n",
    "from ..common.serde.capnp import get_capnp_schema\n",
    "from ..common.serde.capnp import serde_magic_header\n",
    "from ..common.serde.serializable import serializable\n",
    "from .abstract_ledger_store import AbstractDataSubjectLedger\n",
    "from .abstract_ledger_store import AbstractLedgerStore\n",
    "\n",
    "\n",
    "def get_cache_path(cache_filename: str) -> str:\n",
    "    here = os.path.dirname(__file__)\n",
    "    root_dir = Path(here) / \"..\" / \"..\" / \"cache\"\n",
    "    return os.path.abspath(root_dir / cache_filename)\n",
    "\n",
    "\n",
    "def load_cache(filename: str) -> np.ndarray:\n",
    "    CACHE_PATH = get_cache_path(filename)\n",
    "    if not os.path.exists(CACHE_PATH):\n",
    "        raise Exception(f\"Cannot load {CACHE_PATH}\")\n",
    "    cache_array = np.load(CACHE_PATH)\n",
    "    info(f\"Loaded constant2epsilon cache of size: {cache_array.shape}\")\n",
    "    return cache_array\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class RDPParams:\n",
    "    sigmas: jnp.array\n",
    "    l2_norms: jnp.array\n",
    "    l2_norm_bounds: jnp.array\n",
    "    Ls: jnp.array\n",
    "    coeffs: jnp.array\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        res = \"RDPParams:\"\n",
    "        res = f\"{res}\\n sigmas:{self.sigmas}\"\n",
    "        res = f\"{res}\\n l2_norms:{self.l2_norms}\"\n",
    "        res = f\"{res}\\n l2_norm_bounds:{self.l2_norm_bounds}\"\n",
    "        res = f\"{res}\\n Ls:{self.Ls}\"\n",
    "        res = f\"{res}\\n coeffs:{self.coeffs}\"\n",
    "\n",
    "        return res\n",
    "\n",
    "\n",
    "@partial(jax.jit, static_argnums=3, donate_argnums=(1, 2))\n",
    "def first_try_branch(\n",
    "    constant: jax.numpy.DeviceArray,\n",
    "    rdp_constants: np.ndarray,\n",
    "    entity_ids_query: np.ndarray,\n",
    "    max_entity: int,\n",
    ") -> jax.numpy.DeviceArray:\n",
    "    summed_constant = constant.take(entity_ids_query) + rdp_constants.take(\n",
    "        entity_ids_query\n",
    "    )\n",
    "    if max_entity < len(rdp_constants):\n",
    "        return rdp_constants.at[entity_ids_query].set(summed_constant)\n",
    "    else:\n",
    "        pad_length = max_entity - len(rdp_constants) + 1\n",
    "        rdp_constants = jnp.concatenate([rdp_constants, jnp.zeros(shape=pad_length)])\n",
    "        summed_constant = constant + rdp_constants.take(entity_ids_query)\n",
    "        return rdp_constants.at[entity_ids_query].set(summed_constant)\n",
    "\n",
    "\n",
    "@partial(jax.jit, static_argnums=1)\n",
    "def compute_rdp_constant(rdp_params: RDPParams, private: bool) -> jax.numpy.DeviceArray:\n",
    "    squared_Ls = rdp_params.Ls**2\n",
    "    squared_sigma = rdp_params.sigmas**2\n",
    "\n",
    "    if private:\n",
    "        # this is calculated on the private true values\n",
    "        squared_l2 = rdp_params.l2_norms**2\n",
    "    else:\n",
    "        # bounds is computed on the metadata\n",
    "        squared_l2 = rdp_params.l2_norm_bounds**2\n",
    "\n",
    "    return (squared_Ls * squared_l2 / (2 * squared_sigma)) * rdp_params.coeffs\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def get_budgets_and_mask(\n",
    "    epsilon_spend: jnp.array, user_budget: jnp.float64\n",
    ") -> Tuple[float, float, jax.numpy.DeviceArray]:\n",
    "    # Function to vectorize the result of the budget computation.\n",
    "    mask = jnp.ones_like(epsilon_spend) * user_budget < epsilon_spend\n",
    "    # get the highest value which was under budget and represented by False in the mask\n",
    "    highest_possible_spend = jnp.max(epsilon_spend * (1 - mask))\n",
    "    return (highest_possible_spend, user_budget, mask)\n",
    "\n",
    "\n",
    "@serializable(capnp_bytes=True)\n",
    "class DataSubjectLedger(AbstractDataSubjectLedger):\n",
    "    \"\"\"for a particular data subject, this is the list\n",
    "    of all mechanisms releasing informationo about this\n",
    "    particular subject, stored in a vectorized form\"\"\"\n",
    "\n",
    "    CONSTANT2EPSILSON_CACHE_FILENAME = \"constant2epsilon_300k.npy\"\n",
    "    _cache_constant2epsilon = load_cache(filename=CONSTANT2EPSILSON_CACHE_FILENAME)\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        constants: Optional[np.ndarray] = None,\n",
    "        update_number: int = 0,\n",
    "        timestamp_of_last_update: Optional[float] = None,\n",
    "    ) -> None:\n",
    "        self._rdp_constants = (\n",
    "            constants if constants is not None else np.array([], dtype=np.float64)\n",
    "        )\n",
    "        self._update_number = update_number\n",
    "        self._timestamp_of_last_update = (\n",
    "            timestamp_of_last_update\n",
    "            if timestamp_of_last_update is not None\n",
    "            else time.time()\n",
    "        )\n",
    "        self._pending_save = False\n",
    "\n",
    "    def __eq__(self, other: Any) -> bool:\n",
    "        if not isinstance(other, DataSubjectLedger):\n",
    "            return self == other\n",
    "        return (\n",
    "            self._update_number == other._update_number\n",
    "            and self._timestamp_of_last_update == other._timestamp_of_last_update\n",
    "            and all(self._rdp_constants == other._rdp_constants)\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def delta(self) -> float:\n",
    "        FIXED_DELTA: Final = 1e-6\n",
    "        return FIXED_DELTA  # WARNING: CHANGING DELTA INVALIDATES THE CACHE\n",
    "\n",
    "    def bind_to_store_with_key(\n",
    "        self, store: AbstractLedgerStore, user_key: VerifyKey\n",
    "    ) -> None:\n",
    "        self.store = store\n",
    "        self.user_key = user_key\n",
    "\n",
    "    @staticmethod\n",
    "    def get_or_create(\n",
    "        store: AbstractLedgerStore, user_key: VerifyKey\n",
    "    ) -> Optional[AbstractDataSubjectLedger]:\n",
    "        ledger: Optional[AbstractDataSubjectLedger] = None\n",
    "        try:\n",
    "            # todo change user_key or uid?\n",
    "            ledger = store.get(key=user_key)\n",
    "            ledger.bind_to_store_with_key(store=store, user_key=user_key)\n",
    "        except KeyError:\n",
    "            print(\"Creating new Ledger\")\n",
    "            ledger = DataSubjectLedger()\n",
    "            ledger.bind_to_store_with_key(store=store, user_key=user_key)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to read ledger from ledger store. {e}\")\n",
    "\n",
    "        return ledger\n",
    "\n",
    "    def get_entity_overbudget_mask_for_epsilon_and_append(\n",
    "        self,\n",
    "        unique_entity_ids_query: np.ndarray,\n",
    "        rdp_params: RDPParams,\n",
    "        get_budget_for_user: Callable,\n",
    "        deduct_epsilon_for_user: Callable,\n",
    "        private: bool = True,\n",
    "    ) -> np.ndarray:\n",
    "        # coerce to np.int64\n",
    "        entity_ids_query: np.ndarray = unique_entity_ids_query.astype(np.int64)\n",
    "        # calculate constants\n",
    "        rdp_constants = self._get_batch_rdp_constants(\n",
    "            entity_ids_query=entity_ids_query, rdp_params=rdp_params, private=private\n",
    "        )\n",
    "\n",
    "        # here we iteratively attempt to calculate the overbudget mask and save\n",
    "        # changes to the database\n",
    "        mask = self._get_overbudgeted_entities(\n",
    "            get_budget_for_user=get_budget_for_user,\n",
    "            deduct_epsilon_for_user=deduct_epsilon_for_user,\n",
    "            rdp_constants=rdp_constants,\n",
    "        )\n",
    "\n",
    "        # at this point we are confident that the database budget field has been updated\n",
    "        # so now we should flush the _rdp_constants that we have calculated to storage\n",
    "        if self._write_ledger():\n",
    "            return mask\n",
    "\n",
    "    def _write_ledger(self) -> bool:\n",
    "\n",
    "        self._update_number += 1\n",
    "        try:\n",
    "            self._pending_save = False\n",
    "            self.store.set(key=self.user_key, value=self)\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            self._pending_save = True\n",
    "            print(f\"Failed to write ledger to ledger store. {e}\")\n",
    "            raise e\n",
    "\n",
    "    def _increase_max_cache(self, new_size: int) -> None:\n",
    "        new_entries = []\n",
    "        current_size = len(self._cache_constant2epsilon)\n",
    "        new_alphas = []\n",
    "        for i in range(new_size - current_size):\n",
    "            alph, eps = self._get_optimal_alpha_for_constant(\n",
    "                constant=i + 1 + current_size\n",
    "            )\n",
    "            new_entries.append(eps)\n",
    "            new_alphas.append(alph)\n",
    "\n",
    "        self._cache_constant2epsilon = np.concatenate(\n",
    "            [self._cache_constant2epsilon, np.array(new_entries)]\n",
    "        )\n",
    "\n",
    "    def _get_fake_rdp_func(self, constant: int) -> Callable:\n",
    "        def func(alpha: float) -> float:\n",
    "            return alpha * constant\n",
    "\n",
    "        return func\n",
    "\n",
    "    def _get_alpha_search_function(self, rdp_compose_func: Callable) -> Callable:\n",
    "        log_delta = np.log(self.delta)\n",
    "\n",
    "        def fun(alpha: float) -> float:  # the input is the RDP's \\alpha\n",
    "            if alpha <= 1:\n",
    "                return np.inf\n",
    "            else:\n",
    "                alpha_minus_1 = alpha - 1\n",
    "                return np.maximum(\n",
    "                    rdp_compose_func(alpha)\n",
    "                    + np.log(alpha_minus_1 / alpha)\n",
    "                    - (log_delta + np.log(alpha)) / alpha_minus_1,\n",
    "                    0,\n",
    "                )\n",
    "\n",
    "        return fun\n",
    "\n",
    "    def _get_optimal_alpha_for_constant(\n",
    "        self, constant: int = 3\n",
    "    ) -> Tuple[np.ndarray, Callable]:\n",
    "        f = self._get_fake_rdp_func(constant=constant)\n",
    "        f2 = self._get_alpha_search_function(rdp_compose_func=f)\n",
    "        results = minimize_scalar(\n",
    "            f2, method=\"Brent\", bracket=(1, 2), bounds=[1, np.inf]\n",
    "        )\n",
    "\n",
    "        return results.x, results.fun\n",
    "\n",
    "    def _get_batch_rdp_constants(\n",
    "        self, entity_ids_query: jnp.ndarray, rdp_params: RDPParams, private: bool = True\n",
    "    ) -> jnp.ndarray:\n",
    "        constant = compute_rdp_constant(rdp_params, private)\n",
    "        if self._rdp_constants.size == 0:\n",
    "            self._rdp_constants = np.zeros_like(np.asarray(constant, constant.dtype))\n",
    "        print(\"constant: \", constant)\n",
    "        print(\"_rdp_constants: \", self._rdp_constants)\n",
    "        print(\"entity ids query\", entity_ids_query)\n",
    "        print(jnp.max(entity_ids_query))\n",
    "        self._rdp_constants = first_try_branch(\n",
    "            constant,\n",
    "            self._rdp_constants,\n",
    "            entity_ids_query,\n",
    "            int(jnp.max(entity_ids_query)),\n",
    "        )\n",
    "        return constant\n",
    "\n",
    "    def _get_epsilon_spend(self, rdp_constants: np.ndarray) -> np.ndarray:\n",
    "        rdp_constants_lookup = (rdp_constants - 1).astype(np.int64)\n",
    "        try:\n",
    "            # needed as np.int64 to use take\n",
    "            eps_spend = jax.jit(jnp.take)(\n",
    "                self._cache_constant2epsilon, rdp_constants_lookup\n",
    "            )\n",
    "        except IndexError:\n",
    "            print(f\"Cache missed the value at {max(rdp_constants_lookup)}\")\n",
    "            self._increase_max_cache(int(max(rdp_constants_lookup) * 1.1))\n",
    "            eps_spend = jax.jit(jnp.take)(\n",
    "                self._cache_constant2epsilon, rdp_constants_lookup\n",
    "            )\n",
    "        return eps_spend\n",
    "\n",
    "    def _calculate_mask_for_current_budget(\n",
    "        self, get_budget_for_user: Callable, epsilon_spend: np.ndarray\n",
    "    ) -> Tuple[float, float, np.ndarray]:\n",
    "        user_budget = get_budget_for_user(verify_key=self.user_key)\n",
    "        # create a mask of True and False where true is over current user_budget\n",
    "        return get_budgets_and_mask(epsilon_spend, user_budget)\n",
    "\n",
    "    def _get_overbudgeted_entities(\n",
    "        self,\n",
    "        get_budget_for_user: Callable,\n",
    "        deduct_epsilon_for_user: Callable,\n",
    "        rdp_constants: np.ndarray,\n",
    "    ) -> Tuple[np.ndarray]:\n",
    "        \"\"\"TODO:\n",
    "        In our current implementation, user_budget is obtained by querying the\n",
    "        Adversarial Accountant's entity2ledger with the Data Scientist's User Key.\n",
    "        When we replace the entity2ledger with something else, we could perhaps directly\n",
    "        add it into this method\n",
    "        \"\"\"\n",
    "        epsilon_spend = self._get_epsilon_spend(rdp_constants=rdp_constants)\n",
    "\n",
    "        # try first time\n",
    "        (\n",
    "            highest_possible_spend,\n",
    "            user_budget,\n",
    "            mask,\n",
    "        ) = self._calculate_mask_for_current_budget(\n",
    "            get_budget_for_user=get_budget_for_user, epsilon_spend=epsilon_spend\n",
    "        )\n",
    "\n",
    "        mask = np.array(mask, copy=False)\n",
    "        highest_possible_spend = float(highest_possible_spend)\n",
    "        user_budget = float(user_budget)\n",
    "        print(\"Epsilon spend \", epsilon_spend)\n",
    "        print(\"Highest possible spend \", highest_possible_spend)\n",
    "        if highest_possible_spend > 0:\n",
    "            # go spend it in the db\n",
    "            attempts = 0\n",
    "            while attempts < 5:\n",
    "                print(\n",
    "                    f\"Attemping to spend epsilon: {highest_possible_spend}. Try: {attempts}\"\n",
    "                )\n",
    "                attempts += 1\n",
    "                try:\n",
    "                    user_budget = self.spend_epsilon(\n",
    "                        deduct_epsilon_for_user=deduct_epsilon_for_user,\n",
    "                        epsilon_spend=highest_possible_spend,\n",
    "                        old_user_budget=user_budget,\n",
    "                    )\n",
    "                    break\n",
    "                except RefreshBudgetException:  # nosec\n",
    "                    # this is the only exception we allow to retry\n",
    "                    (\n",
    "                        highest_possible_spend,\n",
    "                        user_budget,\n",
    "                        mask,\n",
    "                    ) = self._calculate_mask_for_current_budget(\n",
    "                        get_budget_for_user=get_budget_for_user,\n",
    "                        epsilon_spend=epsilon_spend,\n",
    "                    )\n",
    "                except Exception as e:\n",
    "                    print(f\"Problem spending epsilon. {e}\")\n",
    "                    raise e\n",
    "\n",
    "        if user_budget is None:\n",
    "            raise Exception(\"Failed to spend_epsilon\")\n",
    "\n",
    "        return mask\n",
    "\n",
    "    def spend_epsilon(\n",
    "        self,\n",
    "        deduct_epsilon_for_user: Callable,\n",
    "        epsilon_spend: float,\n",
    "        old_user_budget: float,\n",
    "    ) -> float:\n",
    "        # get the budget\n",
    "        print(\"got user budget\", old_user_budget, \"epsilon_spent\", epsilon_spend)\n",
    "        deduct_epsilon_for_user(\n",
    "            verify_key=self.user_key,\n",
    "            old_budget=old_user_budget,\n",
    "            epsilon_spend=epsilon_spend,\n",
    "        )\n",
    "        # return the budget we used\n",
    "        return old_user_budget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e2977441-ec61-4252-924b-79e3f5eee797",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DSL_dummy:\n",
    "    def __init__(self):\n",
    "        self._cache_constant2epsilon = np.zeros(0)\n",
    "        self.delta = 1e-6\n",
    "    def _increase_max_cache(self, new_size: int) -> None:\n",
    "        new_entries = []\n",
    "        current_size = len(self._cache_constant2epsilon)\n",
    "        new_alphas = []\n",
    "        for i in range(new_size - current_size):\n",
    "            current_constant = i + 1 + current_size\n",
    "            alph, eps = self._get_optimal_alpha_for_constant(\n",
    "                constant=current_constant\n",
    "            )\n",
    "            print(f\"current_constant={current_constant}, alpha={alph}, eps={eps}\")\n",
    "            new_entries.append(eps)\n",
    "            new_alphas.append(alph)\n",
    "\n",
    "        self._cache_constant2epsilon = np.concatenate(\n",
    "            [self._cache_constant2epsilon, np.array(new_entries)]\n",
    "        )\n",
    "\n",
    "    def _get_fake_rdp_func(self, constant: int) -> Callable:\n",
    "        def func(alpha: float) -> float:\n",
    "            return alpha * constant\n",
    "\n",
    "        return func\n",
    "\n",
    "    def _get_alpha_search_function(self, rdp_compose_func: Callable) -> Callable:\n",
    "        log_delta = np.log(self.delta)\n",
    "\n",
    "        def fun(alpha: float) -> float:  # the input is the RDP's \\alpha\n",
    "            if alpha <= 1:\n",
    "                return np.inf\n",
    "            else:\n",
    "                alpha_minus_1 = alpha - 1\n",
    "                return np.maximum(\n",
    "                    rdp_compose_func(alpha)\n",
    "                    + np.log(alpha_minus_1 / alpha)\n",
    "                    - (log_delta + np.log(alpha)) / alpha_minus_1,\n",
    "                    0,\n",
    "                )\n",
    "\n",
    "        return fun\n",
    "\n",
    "    def _get_optimal_alpha_for_constant(\n",
    "        self, constant: int = 3\n",
    "    ) -> Tuple[np.ndarray, Callable]:\n",
    "        f = self._get_fake_rdp_func(constant=constant)\n",
    "        f2 = self._get_alpha_search_function(rdp_compose_func=f)\n",
    "        results = minimize_scalar(\n",
    "            f2, method=\"Brent\", bracket=(1, 2), bounds=[1, np.inf]\n",
    "        )\n",
    "\n",
    "        return results.x, results.fun\n",
    "\n",
    "dsl = DSL_dummy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "12cf4840-59e0-4298-a91f-21600ec38395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_constant=1, alpha=4.508496357814772, eps=7.766216625311721\n",
      "current_constant=2, alpha=3.5060933368492333, eps=11.688596249354894\n",
      "current_constant=3, alpha=3.0573417104696294, eps=14.947919164492593\n",
      "current_constant=4, alpha=2.7881643639977356, eps=17.861121033014\n",
      "current_constant=5, alpha=2.6036578950410423, eps=20.551948814041253\n",
      "current_constant=6, alpha=2.4669985432838435, eps=23.08419874777858\n",
      "current_constant=7, alpha=2.360495652447485, eps=25.495916596130975\n",
      "current_constant=8, alpha=2.2744494959477497, eps=27.811968501910776\n",
      "current_constant=9, alpha=2.2030366150496095, eps=30.049671251820154\n",
      "current_constant=10, alpha=2.1425203717085815, eps=32.2216609490976\n"
     ]
    }
   ],
   "source": [
    "dsl._increase_max_cache(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f60cf6f6-0dd7-4b7c-beaf-5246572f23f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7.76621663, 11.68859625, 14.94791916, 17.86112103, 20.55194881,\n",
       "       23.08419875, 25.4959166 , 27.8119685 , 30.04967125, 32.22166095])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsl._cache_constant2epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8ffc1311-d69b-43cd-b519-af8827ef8744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_constant=1, alpha=4.508496357814772, eps=7.766216625311721\n",
      "current_constant=2, alpha=3.5060933368492333, eps=11.688596249354894\n",
      "current_constant=3, alpha=3.0573417104696294, eps=14.947919164492593\n",
      "current_constant=4, alpha=2.7881643639977356, eps=17.861121033014\n",
      "current_constant=5, alpha=2.6036578950410423, eps=20.551948814041253\n",
      "current_constant=6, alpha=2.4669985432838435, eps=23.08419874777858\n",
      "current_constant=7, alpha=2.360495652447485, eps=25.495916596130975\n",
      "current_constant=8, alpha=2.2744494959477497, eps=27.811968501910776\n",
      "current_constant=9, alpha=2.2030366150496095, eps=30.049671251820154\n",
      "current_constant=10, alpha=2.1425203717085815, eps=32.2216609490976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/e/anaconda3/envs/Hagrid/lib/python3.9/site-packages/scipy/optimize/optimize.py:2621: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  w = xb - ((xb - xc) * tmp2 - (xb - xa) * tmp1) / denom\n"
     ]
    }
   ],
   "source": [
    "class DSL_dummy:\n",
    "    def __init__(self):\n",
    "        self._cache_constant2epsilon = np.zeros(0)\n",
    "        self.delta = 1e-6\n",
    "    def generate_cache(self, new_size: int) -> None:\n",
    "        new_entries = []\n",
    "        current_size = len(self._cache_constant2epsilon)\n",
    "        new_alphas = []\n",
    "        for i in range(new_size - current_size):\n",
    "            current_constant = i + 1 + current_size\n",
    "            alph, eps = self._get_optimal_alpha_for_constant(\n",
    "                constant=current_constant\n",
    "            )\n",
    "            print(f\"current_constant={current_constant}, alpha={alph}, eps={eps}\")\n",
    "            new_entries.append(eps)\n",
    "            new_alphas.append(alph)\n",
    "\n",
    "        self._cache_constant2epsilon = np.concatenate(\n",
    "            [self._cache_constant2epsilon, np.array(new_entries)]\n",
    "        )\n",
    "\n",
    "    def _get_fake_rdp_func(self, constant: int) -> Callable:\n",
    "        def func(alpha: float) -> float:\n",
    "            return alpha * constant\n",
    "\n",
    "        return func\n",
    "\n",
    "    def _get_alpha_search_function(self, rdp_compose_func: Callable) -> Callable:\n",
    "        log_delta = np.log(self.delta)\n",
    "\n",
    "        def fun(alpha: float) -> float:  # the input is the RDP's \\alpha\n",
    "            if alpha <= 1:\n",
    "                return np.inf\n",
    "            else:\n",
    "                alpha_minus_1 = alpha - 1\n",
    "                return np.maximum(\n",
    "                    rdp_compose_func(alpha)\n",
    "                    + np.log(alpha_minus_1 / alpha)\n",
    "                    - (log_delta + np.log(alpha)) / alpha_minus_1,\n",
    "                    0,\n",
    "                )\n",
    "\n",
    "        return fun\n",
    "\n",
    "    def _get_optimal_alpha_for_constant(\n",
    "        self, constant: int = 3\n",
    "    ) -> Tuple[np.ndarray, Callable]:\n",
    "        f = self._get_fake_rdp_func(constant=constant)\n",
    "        f2 = self._get_alpha_search_function(rdp_compose_func=f)\n",
    "        results = minimize_scalar(\n",
    "            f2, method=\"Brent\", bracket=(1, 2), bounds=[1, np.inf]\n",
    "        )\n",
    "\n",
    "        return results.x, results.fun\n",
    "\n",
    "dsl = DSL_dummy()\n",
    "dsl.generate_cache(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5702b25f-cc3a-40c7-870b-0f2420ceb751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[97.12251083101317, 70.15491645692052, 58.02245402213006, 50.722099788120715, 45.70631656976294, 41.98417926409472, 39.078737814336485, 36.728085079712216, 34.774773648441766, 33.11766463196606] [4.523903536255165, 4.52218148173842, 4.520461928432599, 4.518744869795365, 4.517030433069764, 4.515318545333842, 4.513609200248531, 4.511902391492057, 4.510198112774016, 4.508496357814772]\n",
      "Epsilon values\n",
      "[0.1828953771900762, 0.2642629269144414, 0.3277497653368189, 0.38186458783541993, 0.4299414688369493, 0.47370340854757575, 0.5141798669688136, 0.5520447234105068, 0.5877678882920911, 0.6216926545596025] [7.7255709801844255, 7.730094022480236, 7.734615343937549, 7.739134947121293, 7.743652834590001, 7.748169008895832, 7.752683472584593, 7.757196228195763, 7.761707278262511, 7.766216625311721]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/e/anaconda3/envs/Hagrid/lib/python3.9/site-packages/scipy/optimize/optimize.py:2621: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  w = xb - ((xb - xc) * tmp2 - (xb - xa) * tmp1) / denom\n"
     ]
    }
   ],
   "source": [
    "dsl = DSL_dummy()\n",
    "alphas = []\n",
    "epsilons = []\n",
    "\n",
    "# This will also serve as our step size\n",
    "min_val = 0.001\n",
    "\n",
    "for i in np.arange(min_val, 1 + min_val, min_val):\n",
    "    alpha, eps = dsl._get_optimal_alpha_for_constant(i)\n",
    "    alphas.append(alpha)\n",
    "    epsilons.append(eps)\n",
    "\n",
    "print(alphas[:10], alphas[-10:])\n",
    "print(\"Epsilon values\")\n",
    "print(epsilons[:10], epsilons[-10:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6adf55a-abf4-442b-a1ff-f5bba87af1ca",
   "metadata": {},
   "source": [
    "Okay so now we can generate cache values for any number "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
