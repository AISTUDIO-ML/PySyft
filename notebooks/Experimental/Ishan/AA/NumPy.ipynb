{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7c74cc9-fb3f-4872-8e62-ef181c4a3011",
   "metadata": {},
   "source": [
    "Goal:\n",
    "- Implement LeakyRelu activation function --> Done\n",
    "- Implement forward pass & backward pass for every layer of our CNN in pure NumPy:\n",
    "    - conv2d\n",
    "    - batchnorm2d\n",
    "    - avgpool2d\n",
    "    - maxpool2d\n",
    "    - linear\n",
    "- Implement AdaMax optimizer in pure NumPy\n",
    "- Implement Cross-Entropy Loss in pure NumPy\n",
    "- Modify to work with DP Tensors instead of numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cb8a4810-8f7f-4eec-8656-3378465f3b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9570ecfe-9aeb-4c4d-9f4c-b5e250993cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class leaky_ReLU():\n",
    "\n",
    "    def __init__(self, slope=0.01):\n",
    "        super(leaky_ReLU, self).__init__()\n",
    "        self.slope = slope\n",
    "\n",
    "    def forward(self, input_array):\n",
    "        self.last_forward = input_array  # Last image that has been forward passed through this activation function\n",
    "        return ((input_array > 0) * input_array) + ((input_array <= 0) * input_array * self.slope)\n",
    "\n",
    "    def derivative(self, input_array=None):\n",
    "        last_forward = input_array if input_array else self.last_forward\n",
    "        res = np.ones(last_forward.shape)\n",
    "        res[last_forward <= 0] = self.slope\n",
    "        return res\n",
    "    \n",
    "    def __str__(self):\n",
    "        return self.__class__.__name__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2fcc3c8d-5f35-41ae-9cfd-dee729717732",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decompose_size(size):\n",
    "    if len(size) == 2:\n",
    "        fan_in = size[0]\n",
    "        fan_out = size[1]\n",
    "\n",
    "    elif len(size) == 4 or len(size) == 5:\n",
    "        respective_field_size = np.prod(size[2:])\n",
    "        fan_in = size[1] * respective_field_size\n",
    "        fan_out = size[0] * respective_field_size\n",
    "\n",
    "    else:\n",
    "        fan_in = fan_out = int(np.sqrt(np.prod(size)))\n",
    "\n",
    "    return fan_in, fan_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c6fd353b-f0fe-4423-b919-9961f86e46f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Uniform():\n",
    "    def __init__(self, scale=0.05):\n",
    "        self.scale = scale\n",
    "        \n",
    "    def __call__(self, size):\n",
    "        return self.call(size)\n",
    "\n",
    "    def call(self, size):\n",
    "        return np.array(np.random.uniform(-self.scale, self.scale, size=size))\n",
    "    \n",
    "    def __str__(self):\n",
    "        return self.__class__.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "43f67671-2b55-43d4-91a2-7165e50601f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class XavierInitialization():\n",
    "    def __call__(self, size):\n",
    "        return self.call(size)\n",
    "    \n",
    "    def call(self, size):\n",
    "        fan_in, fan_out = decompose_size(size)\n",
    "        return Uniform(np.sqrt(6 / (fan_in + fan_out)))(size)\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.__class__.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8a656e1d-8003-4529-a985-ff7885cd553d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer():\n",
    "    \"\"\"\n",
    "    Subclassed when implementing new types of layers.\n",
    "    \n",
    "    Each layer can keep track of the layer(s) feeding into it, a\n",
    "    network's output :class:`Layer` instance can double as a handle to the full\n",
    "    network.\n",
    "    \"\"\"\n",
    "\n",
    "    first_layer = False\n",
    "\n",
    "    def forward(self, input, *args, **kwargs):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def backward(self, pre_grad, *args, **kwargs):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def connect_to(self, prev_layer):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    @property\n",
    "    def params(self):\n",
    "        \"\"\" Layer parameters. \n",
    "        \n",
    "        Returns a list of numpy.array variables or expressions that\n",
    "        parameterize the layer.\n",
    "        Returns\n",
    "        -------\n",
    "        list of numpy.array variables or expressions\n",
    "            A list of variables that parameterize the layer\n",
    "        Notes\n",
    "        -----\n",
    "        For layers without any parameters, this will return an empty list.\n",
    "        \"\"\"\n",
    "        return []\n",
    "\n",
    "    @property\n",
    "    def grads(self):\n",
    "        \"\"\" Get layer parameter gradients as calculated from backward(). \"\"\"\n",
    "        return []\n",
    "\n",
    "    @property\n",
    "    def param_grads(self):\n",
    "        \"\"\" Layer parameters and corresponding gradients. \"\"\"\n",
    "        return list(zip(self.params, self.grads))\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.__class__.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "dbcf3cc8-0c49-452f-9c05-ebffded0b409",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Convolution(Layer):\n",
    "    \"\"\"\n",
    "    If this is the first layer in a model, provide the keyword argument `input_shape`\n",
    "    (tuple of integers, does NOT include the sample axis, N.),\n",
    "    e.g. `input_shape=(3, 128, 128)` for 128x128 RGB pictures.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, nb_filter, filter_size, input_shape=None, stride=1):\n",
    "        self.nb_filter = nb_filter\n",
    "        self.filter_size = filter_size\n",
    "        self.input_shape = input_shape\n",
    "        self.stride = stride\n",
    "\n",
    "        self.W, self.dW = None, None\n",
    "        self.b, self.db = None, None\n",
    "        self.out_shape = None\n",
    "        self.last_output = None\n",
    "        self.last_input = None\n",
    "\n",
    "        self.init = XavierInitialization()\n",
    "        self.activation = leaky_ReLU()\n",
    "\n",
    "    def connect_to(self, prev_layer=None):\n",
    "        if prev_layer is None:\n",
    "            assert self.input_shape is not None\n",
    "            input_shape = self.input_shape\n",
    "        else:\n",
    "            input_shape = prev_layer.out_shape\n",
    "\n",
    "        # input_shape: (batch size, num input feature maps, image height, image width)\n",
    "        assert len(input_shape) == 4\n",
    "\n",
    "        nb_batch, pre_nb_filter, pre_height, pre_width = input_shape\n",
    "        if isinstance(self.filter_size, tuple):\n",
    "            filter_height, filter_width = self.filter_size\n",
    "        elif isinstance(self.filter_size, int):\n",
    "            filter_height = filter_width = self.filter_size\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        height = (pre_height - filter_height) // self.stride + 1\n",
    "        width = (pre_width - filter_width) // self.stride + 1\n",
    "\n",
    "        # output shape\n",
    "        self.out_shape = (nb_batch, self.nb_filter, height, width)\n",
    "\n",
    "        # filters\n",
    "        self.W = self.init((self.nb_filter, pre_nb_filter, filter_height, filter_width))\n",
    "        self.b = np.zeros((self.nb_filter,))\n",
    "\n",
    "    def forward(self, input, *args, **kwargs):\n",
    "\n",
    "        self.last_input = input\n",
    "\n",
    "        # shape\n",
    "        nb_batch, input_depth, old_img_h, old_img_w = input.shape\n",
    "        if isinstance(self.filter_size, tuple):\n",
    "            filter_height, filter_width = self.filter_size\n",
    "        elif isinstance(self.filter_size, int):\n",
    "            filter_height = filter_width = self.filter_size\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "#         filter_h, filter_w = self.filter_size\n",
    "        new_img_h, new_img_w = self.out_shape[2:]\n",
    "\n",
    "        # init\n",
    "        outputs = np.zeros((nb_batch, self.nb_filter, new_img_h, new_img_w))\n",
    "\n",
    "        # convolution operation\n",
    "        for x in np.arange(nb_batch):\n",
    "            for y in np.arange(self.nb_filter):\n",
    "                for h in np.arange(new_img_h):\n",
    "                    for w in np.arange(new_img_w):\n",
    "                        h_shift, w_shift = h * self.stride, w * self.stride\n",
    "                        # patch: (input_depth, filter_h, filter_w)\n",
    "                        patch = input[x, :, h_shift: h_shift + filter_height, w_shift: w_shift + filter_width]\n",
    "                        outputs[x, y, h, w] = np.sum(patch * self.W[y]) + self.b[y]\n",
    "\n",
    "        # nonlinear activation\n",
    "        # self.last_output: (nb_batch, output_depth, image height, image width)\n",
    "        self.last_output = self.activation.forward(outputs)\n",
    "\n",
    "        return self.last_output\n",
    "\n",
    "    def backward(self, pre_grad, *args, **kwargs):\n",
    "\n",
    "        # shape\n",
    "        assert pre_grad.shape == self.last_output.shape\n",
    "        nb_batch, input_depth, old_img_h, old_img_w = self.last_input.shape\n",
    "        new_img_h, new_img_w = self.out_shape[2:]\n",
    "        \n",
    "        if isinstance(self.filter_size, tuple):\n",
    "            filter_height, filter_width = self.filter_size\n",
    "        elif isinstance(self.filter_size, int):\n",
    "            filter_height = filter_width = self.filter_size\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        \n",
    "#         filter_h, filter_w = self.filter_size\n",
    "        old_img_h, old_img_w = self.last_input.shape[-2:]\n",
    "\n",
    "        # gradients\n",
    "        self.dW = np.zeros((self.W.shape))\n",
    "        self.db = np.zeros((self.b.shape))\n",
    "        delta = pre_grad * self.activation.derivative()\n",
    "\n",
    "        # dW\n",
    "        for r in np.arange(self.nb_filter):\n",
    "            for t in np.arange(input_depth):\n",
    "                for h in np.arange(filter_h):\n",
    "                    for w in np.arange(filter_w):\n",
    "                        input_window = self.last_input[:, t,\n",
    "                                       h:old_img_h - filter_h + h + 1:self.stride,\n",
    "                                       w:old_img_w - filter_w + w + 1:self.stride]\n",
    "                        delta_window = delta[:, r]\n",
    "                        self.dW[r, t, h, w] = np.sum(input_window * delta_window) / nb_batch\n",
    "\n",
    "        # db\n",
    "        for r in np.arange(self.nb_filter):\n",
    "            self.db[r] = np.sum(delta[:, r]) / nb_batch\n",
    "\n",
    "        # dX\n",
    "        if not self.first_layer:\n",
    "            layer_grads = np.zeros(self.last_input.shape)\n",
    "            for b in np.arange(nb_batch):\n",
    "                for r in np.arange(self.nb_filter):\n",
    "                    for t in np.arange(input_depth):\n",
    "                        for h in np.arange(new_img_h):\n",
    "                            for w in np.arange(new_img_w):\n",
    "                                h_shift, w_shift = h * self.stride, w * self.stride\n",
    "                                layer_grads[b, t, h_shift:h_shift + filter_height, w_shift:w_shift + filter_width] += \\\n",
    "                                    self.W[r, t] * delta[b, r, h, w]\n",
    "            return layer_grads\n",
    "\n",
    "    @property\n",
    "    def params(self):\n",
    "        return self.W, self.b\n",
    "\n",
    "    @property\n",
    "    def grads(self):\n",
    "        return self.dW, self.db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "f0bfa725-40be-4c48-9cd8-0c583a34c0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = Convolution(3, 3, input_shape=(1, 3, 50, 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "6480805b-c623-4f5a-83b8-7bdc0dd3b242",
   "metadata": {},
   "outputs": [],
   "source": [
    "c.connect_to()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "454d6256-d500-4669-a8f4-61d96c4d4879",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[-0.01015495, -0.01015495, -0.01015495, ..., -0.01015495,\n",
       "          -0.01015495, -0.01015495],\n",
       "         [-0.01015495, -0.01015495, -0.01015495, ..., -0.01015495,\n",
       "          -0.01015495, -0.01015495],\n",
       "         [-0.01015495, -0.01015495, -0.01015495, ..., -0.01015495,\n",
       "          -0.01015495, -0.01015495],\n",
       "         ...,\n",
       "         [-0.01015495, -0.01015495, -0.01015495, ..., -0.01015495,\n",
       "          -0.01015495, -0.01015495],\n",
       "         [-0.01015495, -0.01015495, -0.01015495, ..., -0.01015495,\n",
       "          -0.01015495, -0.01015495],\n",
       "         [-0.01015495, -0.01015495, -0.01015495, ..., -0.01015495,\n",
       "          -0.01015495, -0.01015495]],\n",
       "\n",
       "        [[-0.00241782, -0.00241782, -0.00241782, ..., -0.00241782,\n",
       "          -0.00241782, -0.00241782],\n",
       "         [-0.00241782, -0.00241782, -0.00241782, ..., -0.00241782,\n",
       "          -0.00241782, -0.00241782],\n",
       "         [-0.00241782, -0.00241782, -0.00241782, ..., -0.00241782,\n",
       "          -0.00241782, -0.00241782],\n",
       "         ...,\n",
       "         [-0.00241782, -0.00241782, -0.00241782, ..., -0.00241782,\n",
       "          -0.00241782, -0.00241782],\n",
       "         [-0.00241782, -0.00241782, -0.00241782, ..., -0.00241782,\n",
       "          -0.00241782, -0.00241782],\n",
       "         [-0.00241782, -0.00241782, -0.00241782, ..., -0.00241782,\n",
       "          -0.00241782, -0.00241782]],\n",
       "\n",
       "        [[-0.00815905, -0.00815905, -0.00815905, ..., -0.00815905,\n",
       "          -0.00815905, -0.00815905],\n",
       "         [-0.00815905, -0.00815905, -0.00815905, ..., -0.00815905,\n",
       "          -0.00815905, -0.00815905],\n",
       "         [-0.00815905, -0.00815905, -0.00815905, ..., -0.00815905,\n",
       "          -0.00815905, -0.00815905],\n",
       "         ...,\n",
       "         [-0.00815905, -0.00815905, -0.00815905, ..., -0.00815905,\n",
       "          -0.00815905, -0.00815905],\n",
       "         [-0.00815905, -0.00815905, -0.00815905, ..., -0.00815905,\n",
       "          -0.00815905, -0.00815905],\n",
       "         [-0.00815905, -0.00815905, -0.00815905, ..., -0.00815905,\n",
       "          -0.00815905, -0.00815905]]]])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.ones((1, 3, 50, 50))\n",
    "\n",
    "c.forward(input=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "df10cfa0-63cd-431b-bccd-d5c6b72516cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchNorm(Layer):\n",
    "    def __init__(self, epsilon=1e-6, momentum=0.9, axis=0,\n",
    "                 beta_init='zero', gamma_init='one'):\n",
    "        self.epsilon = epsilon\n",
    "        self.momentum = momentum\n",
    "        self.axis = axis\n",
    "\n",
    "        self.beta, self.dbeta = None, None\n",
    "        self.gamma, self.dgamma = None, None\n",
    "        self.cache = None\n",
    "\n",
    "    def connect_to(self, prev_layer):\n",
    "        n_in = prev_layer.out_shape[-1]\n",
    "\n",
    "        self.beta = np.zeros((n_in,))\n",
    "        self.gamma = np.ones((n_in,))\n",
    "\n",
    "    def forward(self, input, *args, **kwargs):\n",
    "        # N, D = x.shape\n",
    "\n",
    "        # step1: calculate the mean\n",
    "        # mu = 1. / N * np.sum(x, axis=0)\n",
    "        mean = np.mean(input, axis=0)\n",
    "\n",
    "        xmu = input - mean\n",
    "\n",
    "        # step3:\n",
    "        # sq = xmu ** 2\n",
    "        # var = 1. / N * np.sum(sq, axis=0)\n",
    "        var = np.std(xmu, axis=0)\n",
    "\n",
    "        sqrtvar = np.sqrt(var + self.epsilon)\n",
    "        ivar = 1. / sqrtvar\n",
    "\n",
    "        # step5: normalization->x^\n",
    "        xhat = xmu * ivar\n",
    "\n",
    "        # step6: scale and shift\n",
    "        gammax = self.gamma * xhat\n",
    "        out = gammax + self.beta\n",
    "\n",
    "        self.cache = (xhat, xmu, ivar, sqrtvar, var)\n",
    "\n",
    "        return out\n",
    "\n",
    "    def backward(self, pre_grad, *args, **kwargs):\n",
    "        xhat, xmu, ivar, sqrtvar, var = self.cache\n",
    "\n",
    "        N, D = pre_grad.shape\n",
    "\n",
    "        # step6\n",
    "        self.dbeta = np.sum(pre_grad, axis=0)\n",
    "        dgammax = pre_grad\n",
    "        self.dgamma = np.sum(dgammax * xhat, axis=0)\n",
    "        dxhat = dgammax * self.gamma\n",
    "\n",
    "        # step5\n",
    "        divar = np.sum(dxhat * xmu, axis=0)\n",
    "        dxmu1 = dxhat * ivar \n",
    "\n",
    "        # step4\n",
    "        dsqrtvar = -1. / (sqrtvar ** 2) * divar\n",
    "        dvar = 0.5 * 1. / np.sqrt(var + self.epsilon) * dsqrtvar\n",
    "\n",
    "        # step3\n",
    "        dsq = 1. / N * np.ones((N, D)) * dvar\n",
    "        dxmu2 = 2 * xmu * dsq  \n",
    "\n",
    "        # step2, \n",
    "        dx1 = (dxmu1 + dxmu2)\n",
    "\n",
    "        # step1, \n",
    "        dmu = -1 * np.sum(dxmu1 + dxmu2, axis=0)\n",
    "        dx2 = 1. / N * np.ones((N, D)) * dmu\n",
    "\n",
    "        # step0 done!\n",
    "        dx = dx1 + dx2\n",
    "\n",
    "        return dx\n",
    "\n",
    "    @property\n",
    "    def params(self):\n",
    "        return self.beta, self.gamma\n",
    "\n",
    "    @property\n",
    "    def grades(self):\n",
    "        return self.dbeta, self.dgamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "7ae4d42f-8304-4b44-ae8b-f9ff20cbb45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bn = BatchNorm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "d88ac13b-56b4-4670-b006-ad4f9cc4599d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bn.connect_to(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "66d5f635-a953-429b-a2ba-d95165bb5994",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]]]])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn.forward(c.forward(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151727af-639b-470d-9cdd-d7e94841ffe4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Hagrid",
   "language": "python",
   "name": "hagrid"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
