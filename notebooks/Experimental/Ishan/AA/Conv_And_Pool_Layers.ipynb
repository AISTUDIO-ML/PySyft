{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10e63b02",
   "metadata": {},
   "source": [
    "### Conv Numpy Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0879767",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shubham/anaconda3/envs/syft/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/shubham/PySyft/packages/syft/src/syft/core/common/serde/serializable.py:105: UserWarning: __attr_allowlist__ not defined for type Activation, even if it uses recursive serde, defaulting on the empty list.\n",
      "  warnings.warn(\n",
      "/home/shubham/PySyft/packages/syft/src/syft/core/common/serde/serializable.py:105: UserWarning: __attr_allowlist__ not defined for type Linear, even if it uses recursive serde, defaulting on the empty list.\n",
      "  warnings.warn(\n",
      "/home/shubham/PySyft/packages/syft/src/syft/core/common/serde/serializable.py:105: UserWarning: __attr_allowlist__ not defined for type BatchNorm, even if it uses recursive serde, defaulting on the empty list.\n",
      "  warnings.warn(\n",
      "/home/shubham/PySyft/packages/syft/src/syft/core/common/serde/serializable.py:105: UserWarning: __attr_allowlist__ not defined for type AvgPool, even if it uses recursive serde, defaulting on the empty list.\n",
      "  warnings.warn(\n",
      "/home/shubham/PySyft/packages/syft/src/syft/core/common/serde/serializable.py:105: UserWarning: __attr_allowlist__ not defined for type MaxPool, even if it uses recursive serde, defaulting on the empty list.\n",
      "  warnings.warn(\n",
      "/home/shubham/PySyft/packages/syft/src/syft/core/common/serde/serializable.py:105: UserWarning: __attr_allowlist__ not defined for type Loss, even if it uses recursive serde, defaulting on the empty list.\n",
      "  warnings.warn(\n",
      "/home/shubham/PySyft/packages/syft/src/syft/core/common/serde/serializable.py:105: UserWarning: __attr_allowlist__ not defined for type Optimizer, even if it uses recursive serde, defaulting on the empty list.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from typing import Dict\n",
    "from typing import Optional\n",
    "from typing import Tuple\n",
    "from typing import Union\n",
    "\n",
    "# third party\n",
    "import numpy as np\n",
    "\n",
    "# relative\n",
    "from syft.core.tensor.nn import activations\n",
    "from syft.core.tensor.autodp.gamma_tensor import GammaTensor\n",
    "from syft.core.tensor.autodp.phi_tensor import PhiTensor\n",
    "from syft.core.tensor.nn.initializations import XavierInitialization\n",
    "from syft.core.tensor.nn.utils import dp_zeros\n",
    "from syft.core.tensor.nn.layers.base import Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ffa0210",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_im2col_indices(x_shape, field_height, field_width, padding=1, stride=1):\n",
    "    # First figure out what the size of the output should be\n",
    "    N, C, H, W = x_shape\n",
    "    assert (H + 2 * padding - field_height) % stride == 0\n",
    "    assert (W + 2 * padding - field_height) % stride == 0\n",
    "    out_height = int((H + 2 * padding - field_height) / stride + 1)\n",
    "    out_width = int((W + 2 * padding - field_width) / stride + 1)\n",
    "\n",
    "    i0 = np.repeat(np.arange(field_height), field_width)\n",
    "    i0 = np.tile(i0, C)\n",
    "    i1 = stride * np.repeat(np.arange(out_height), out_width)\n",
    "    j0 = np.tile(np.arange(field_width), field_height * C)\n",
    "    j1 = stride * np.tile(np.arange(out_width), out_height)\n",
    "    i = i0.reshape(-1, 1) + i1.reshape(1, -1)\n",
    "    j = j0.reshape(-1, 1) + j1.reshape(1, -1)\n",
    "\n",
    "    k = np.repeat(np.arange(C), field_height * field_width).reshape(-1, 1)\n",
    "\n",
    "    return (k.astype(int), i.astype(int), j.astype(int))\n",
    "\n",
    "def im2col_indices(x, field_height, field_width, padding=1, stride=1):\n",
    "    \"\"\" An implementation of im2col based on some fancy indexing \"\"\"\n",
    "    # Zero-pad the input\n",
    "    p = padding\n",
    "    x_padded = np.pad(x, ((0, 0), (0, 0), (p, p), (p, p)), mode='constant')\n",
    "\n",
    "    k, i, j = get_im2col_indices(x.shape, field_height, field_width, padding, stride)\n",
    "\n",
    "    cols = x_padded[:, k, i, j]\n",
    "    C = x.shape[1]\n",
    "    cols = cols.transpose(1, 2, 0).reshape(field_height * field_width * C, -1)\n",
    "    return cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fcd046e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from syft import DataSubjectList\n",
    "from syft import lazyrepeatarray\n",
    "\n",
    "def dp_pad(input: Union[PhiTensor, GammaTensor], width, padding_mode=\"constant\", **kwargs):\n",
    "    \n",
    "    data = input.child    \n",
    "    output_data = np.pad(data, width, mode=padding_mode, **kwargs)\n",
    "    min_v = lazyrepeatarray(data=min(input.min_vals.data.min(), output_data.min()), shape=output_data.shape)\n",
    "    max_v = lazyrepeatarray(data=min(input.max_vals.data.max(), output_data.max()), shape=output_data.shape)\n",
    "    \n",
    "    output_data_subjects=DataSubjectList(\n",
    "        one_hot_lookup=input.data_subjects.one_hot_lookup,\n",
    "        data_subjects_indexed=np.pad(input.data_subjects.data_subjects_indexed, width, mode=padding_mode, **kwargs)\n",
    "    )\n",
    "\n",
    "    if isinstance(input, PhiTensor):\n",
    "        return PhiTensor(\n",
    "            child=output_data,\n",
    "            data_subjects=output_data_subjects,\n",
    "            min_vals=min_v,\n",
    "            max_vals=max_v\n",
    "        )\n",
    "    elif isinstance(input, GammaTensor):\n",
    "        return GammaTensor(\n",
    "            child=output_data,\n",
    "            data_subjects=output_data_subjects,\n",
    "            min_vals=min_v,\n",
    "            max_vals=max_v,\n",
    "        )\n",
    "    else:\n",
    "        raise NotImplementedError(f\"Padding is not implemented for Input Type: {type(input)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93819291",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10\n",
    "C_in = 3\n",
    "H_in = 50\n",
    "W_in = 50\n",
    "\n",
    "\n",
    "input_shape = (N, C_in, H_in, W_in)\n",
    "x = PhiTensor(child=np.random.randint(low=0, high=255, size=input_shape),\n",
    "              data_subjects=np.zeros(input_shape),\n",
    "              min_vals=0,\n",
    "              max_vals=255\n",
    "             )\n",
    "\n",
    "# TEST Padding\n",
    "# dp_pad(x, ((0, 0), (0, 0), (p, p), (p, p)), padding_mode=\"constant\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9ba6fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def im2col_indices_dp(x, field_height, field_width, padding=1, stride=1):\n",
    "    \"\"\" An implementation of im2col based on some fancy indexing \"\"\"\n",
    "    # Zero-pad the input\n",
    "    p = padding\n",
    "    x_padded = dp_pad(x, ((0, 0), (0, 0), (p, p), (p, p)), padding_mode='constant')\n",
    "\n",
    "    k, i, j = get_im2col_indices(x.shape, field_height, field_width, padding, stride)\n",
    "\n",
    "    cols = x_padded[:, k, i, j]\n",
    "    C = x.shape[1]\n",
    "    cols = cols.transpose((1, 2, 0)).reshape((field_height * field_width * C, -1))\n",
    "    return cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e77c03bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy implementation\n",
      "(3072, 5290)\n",
      "dp implementation\n",
      "(3072, 5290)\n"
     ]
    }
   ],
   "source": [
    "print(\"numpy implementation\")\n",
    "print(im2col_indices(x.child, 32, 32, padding=2, stride=1).shape)\n",
    "print(\"dp implementation\")\n",
    "print(im2col_indices_dp(x, 32, 32, padding=2, stride=1).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93417d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def conv_forward(X, W, b, stride=1, padding=1):\n",
    "    cache = W, b, stride, padding\n",
    "    n_filters, d_filter, h_filter, w_filter = W.shape\n",
    "    n_x, d_x, h_x, w_x = X.shape\n",
    "    h_out = (h_x - h_filter + 2 * padding) / stride + 1\n",
    "    w_out = (w_x - w_filter + 2 * padding) / stride + 1\n",
    "\n",
    "    if not h_out.is_integer() or not w_out.is_integer():\n",
    "        raise Exception('Invalid output dimension!')\n",
    "\n",
    "    h_out, w_out = int(h_out), int(w_out)\n",
    "    print(h_out, w_out)\n",
    "\n",
    "    X_col = im2col_indices(X, h_filter, w_filter, padding=padding, stride=stride)\n",
    "    W_col = W.reshape(n_filters, -1)\n",
    "    \n",
    "    print(W_col.shape)\n",
    "    print(X_col.shape)\n",
    "    #return W_col,X_col\n",
    "    \n",
    "\n",
    "    out = (W_col @ X_col).T + b\n",
    "    out = out.reshape(n_filters, h_out, w_out, n_x)\n",
    "    out = out.transpose(3, 0, 1, 2)\n",
    "\n",
    "    cache = (X, W, b, stride, padding, X_col)\n",
    "\n",
    "    return out, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df381dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from syft.core.tensor.nn.utils import dp_zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2b723de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52 52\n",
      "(32, 27)\n",
      "(27, 27040)\n"
     ]
    }
   ],
   "source": [
    "from syft.core.tensor.nn.initializations import XavierInitialization\n",
    "\n",
    "nb_filter = 32\n",
    "filter_height = filter_width = 3\n",
    "nb_batch, pre_nb_filter, pre_height, pre_width = x.shape\n",
    "W = XavierInitialization()((nb_filter, pre_nb_filter, filter_height, filter_width))\n",
    "W = PhiTensor(\n",
    "    child=W, \n",
    "    data_subjects=DataSubjectList(one_hot_lookup=x.data_subjects.one_hot_lookup, data_subjects_indexed=np.zeros_like(W)),\n",
    "    min_vals=W.min(),\n",
    "    max_vals=W.max()\n",
    ")\n",
    "\n",
    "b = dp_zeros(shape=(nb_filter, ), data_subjects=x.data_subjects)\n",
    "\n",
    "out, c = conv_forward(x.child, W.child, b.child, padding=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d546fd56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 32, 52, 52)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "56c2cfed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_forward_dp(X, W, b, stride=1, padding=1):\n",
    "    cache = W, b, stride, padding\n",
    "    n_filters, d_filter, h_filter, w_filter = W.shape\n",
    "    n_x, d_x, h_x, w_x = X.shape\n",
    "    h_out = (h_x - h_filter + 2 * padding) / stride + 1\n",
    "    w_out = (w_x - w_filter + 2 * padding) / stride + 1\n",
    "\n",
    "    if not h_out.is_integer() or not w_out.is_integer():\n",
    "        raise Exception('Invalid output dimension!')\n",
    "\n",
    "    h_out, w_out = int(h_out), int(w_out)\n",
    "    \n",
    "    print(h_out, w_out)\n",
    "\n",
    "    X_col = im2col_indices_dp(X, h_filter, w_filter, padding=padding, stride=stride)\n",
    "    \n",
    "    W_col = W.reshape((n_filters, -1))\n",
    "    \n",
    "    #return W_col, X_col\n",
    "    \n",
    "    \n",
    "    out = X_col.transpose() @ W_col.T + b\n",
    "    out = out.reshape((n_filters, h_out, w_out, n_x))\n",
    "    out = out.transpose((3, 0, 1, 2))\n",
    "\n",
    "    cache = (X, W, b, stride, padding, X_col)\n",
    "\n",
    "    return out, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "85d79355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52 52\n"
     ]
    }
   ],
   "source": [
    "out_dp, cache_dp = conv_forward_dp(x, W.child, b.child, padding=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b28d428c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 32, 52, 52)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_dp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a7b8c20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def col2im_indices(cols, x_shape, field_height=3, field_width=3, padding=1,\n",
    "                   stride=1):\n",
    "    \"\"\" An implementation of col2im based on fancy indexing and np.add.at \"\"\"\n",
    "    N, C, H, W = x_shape\n",
    "    H_padded, W_padded = H + 2 * padding, W + 2 * padding\n",
    "    x_padded = np.zeros((N, C, H_padded, W_padded), dtype=cols.dtype)\n",
    "    k, i, j = get_im2col_indices(x_shape, field_height, field_width, padding, stride)\n",
    "    cols_reshaped = cols.reshape(C * field_height * field_width, -1, N)\n",
    "    cols_reshaped = cols_reshaped.transpose(2, 0, 1)\n",
    "    np.add.at(x_padded, (slice(None), k, i, j), cols_reshaped)\n",
    "    if padding == 0:\n",
    "        return x_padded\n",
    "    return x_padded[:, :, padding:-padding, padding:-padding]\n",
    "\n",
    "\n",
    "def conv_backward(dout, cache):\n",
    "    X, W, b, stride, padding, X_col = cache\n",
    "    n_filter, d_filter, h_filter, w_filter = W.shape\n",
    "\n",
    "    db = np.sum(dout, axis=(0, 2, 3))\n",
    "    db = db.reshape(n_filter, -1)\n",
    "\n",
    "    dout_reshaped = dout.transpose(1, 2, 3, 0).reshape(n_filter, -1)\n",
    "    dW = dout_reshaped @ X_col.T\n",
    "    dW = dW.reshape(W.shape)\n",
    "\n",
    "    W_reshape = W.reshape(n_filter, -1)\n",
    "    dX_col = W_reshape.T @ dout_reshaped\n",
    "    print(\"dX_col\", dX_col.shape)\n",
    "    dX = col2im_indices(dX_col, X.shape, h_filter, w_filter, padding=padding, stride=stride)\n",
    "    return dX, dW, db\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "df891a74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dX_col (27, 27040)\n"
     ]
    }
   ],
   "source": [
    "dX, dW, db = conv_backward(out, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cb55a3b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10, 3, 50, 50), (32, 3, 3, 3), (32, 1))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dX.shape, dW.shape, db.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "104d93dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dp_add_at(a, indices, b):\n",
    "    data_a = a.child\n",
    "    data_b = b.child\n",
    "    np.add.at(data_a,indices, data_b)\n",
    "    return PhiTensor(\n",
    "        child=data_a,\n",
    "        data_subjects=a.data_subjects,\n",
    "        min_vals=data_a.min(),\n",
    "        max_vals=data_a.max()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "13e231b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def col2im_indices_dp(cols, x_shape, field_height=3, field_width=3, padding=1, stride=1):\n",
    "    \"\"\" An implementation of col2im based on fancy indexing and np.add.at \"\"\"\n",
    "    N, C, H, W = x_shape\n",
    "    H_padded, W_padded = H + 2 * padding, W + 2 * padding\n",
    "    x_padded = dp_zeros((N, C, H_padded, W_padded), data_subjects=cols.data_subjects)\n",
    "    k, i, j = get_im2col_indices(x_shape, field_height, field_width, padding, stride)\n",
    "    cols_reshaped = cols.reshape((C * field_height * field_width, -1, N))\n",
    "    cols_reshaped = cols_reshaped.transpose((2, 0, 1))\n",
    "    x_padded = dp_add_at(x_padded, (slice(None), k, i, j), cols_reshaped)\n",
    "    if padding == 0:\n",
    "        return x_padded\n",
    "    return x_padded[:, :, padding:-padding, padding:-padding]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f7751999",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_backward_dp(dout, cache):\n",
    "    X, W, b, stride, padding, X_col = cache\n",
    "    n_filter, d_filter, h_filter, w_filter = W.shape\n",
    "\n",
    "    db = dout.sum(axis=(0, 2, 3))\n",
    "    db = db.reshape((n_filter, -1))\n",
    "\n",
    "    dout_reshaped = dout.transpose((1, 2, 3, 0)).reshape((n_filter, -1))\n",
    "    \n",
    "    dW = dout_reshaped @ X_col.T\n",
    "    dW = dW.reshape(W.shape)\n",
    "\n",
    "    W_reshape = W.reshape(n_filter, -1)\n",
    "    dX_col = dout_reshaped.transpose() @ W_reshape\n",
    "    dX = col2im_indices_dp(dX_col, X.shape, h_filter, w_filter, padding=padding, stride=stride)\n",
    "\n",
    "    return dX, dW, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6c5391ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dX_col (27040, 27)\n",
      "<class 'syft.core.tensor.autodp.phi_tensor.PhiTensor'>\n"
     ]
    }
   ],
   "source": [
    "dX_dp, dW_dp, db_dp = conv_backward_dp(out_dp, cache_dp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f26767e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10, 3, 50, 50), (32, 3, 3, 3), (32, 1))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dX_dp.shape, dW_dp.shape, db_dp.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6647836b",
   "metadata": {},
   "source": [
    "### Conv PhiTensor Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "ec11af2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stdlib\n",
    "from typing import Dict\n",
    "from typing import Optional\n",
    "from typing import Tuple\n",
    "from typing import Union\n",
    "\n",
    "# third party\n",
    "import numpy as np\n",
    "\n",
    "# relative\n",
    "from syft.core.tensor.nn import activations\n",
    "from syft.core.tensor.autodp.gamma_tensor import GammaTensor\n",
    "from syft.core.tensor.autodp.phi_tensor import PhiTensor\n",
    "from syft.core.tensor.nn.initializations import XavierInitialization\n",
    "from syft.core.tensor.nn.utils import dp_zeros\n",
    "from syft.core.tensor.nn.layers.base import Layer\n",
    "\n",
    "\n",
    "class Convolution(Layer):\n",
    "    \"\"\"\n",
    "    If this is the first layer in a model, provide the keyword argument `input_shape`\n",
    "    (tuple of integers, does NOT include the sample axis, N.),\n",
    "    e.g. `input_shape=(3, 128, 128)` for 128x128 RGB pictures.\n",
    "    \"\"\"\n",
    "    __name__ = \"ConvPointer\"\n",
    "    __module__ = \"syft.core.tensor.nn.layers.convolution\"\n",
    "    __attr_allowlist__ = [\n",
    "        \"nb_filter\",\n",
    "        \"filter_size\",\n",
    "        \"input_shape\",\n",
    "        \"stride\",\n",
    "        \"W\",\n",
    "        \"b\",\n",
    "        \"dW\",\n",
    "        \"db\",\n",
    "        \"out_shape\",\n",
    "        \"last_output\",\n",
    "        \"last_input\"\n",
    "    ]\n",
    "\n",
    "    def __init__(self, nb_filter, filter_size, input_shape: Optional[Tuple]=None, stride: int=1, padding: int=0, activation: Optional[activations.Activation]=None):\n",
    "        self.nb_filter = nb_filter\n",
    "        self.filter_size = filter_size\n",
    "        self.input_shape = input_shape\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "\n",
    "        self.W, self.dW = None, None\n",
    "        self.b, self.db = None, None\n",
    "        self.out_shape = None\n",
    "        self.last_output = None\n",
    "        self.last_input = None\n",
    "\n",
    "        self.init = XavierInitialization()\n",
    "        self.activation = activations.get(activation)\n",
    "\n",
    "    def connect_to(self, prev_layer: Optional[Layer]=None):\n",
    "        if prev_layer is None:\n",
    "            assert self.input_shape is not None\n",
    "            input_shape = self.input_shape\n",
    "        else:\n",
    "            input_shape = prev_layer.out_shape\n",
    "\n",
    "        # input_shape: (batch size, num input feature maps, image height, image width)\n",
    "        assert len(input_shape) == 4\n",
    "\n",
    "        nb_batch, pre_nb_filter, pre_height, pre_width = input_shape\n",
    "        if isinstance(self.filter_size, tuple):\n",
    "            filter_height, filter_width = self.filter_size\n",
    "        elif isinstance(self.filter_size, int):\n",
    "            filter_height = filter_width = self.filter_size\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        height = (pre_height - filter_height + 2 * self.padding) // self.stride + 1\n",
    "        width = (pre_width - filter_width +  2 * self.padding) // self.stride + 1\n",
    "\n",
    "        # output shape\n",
    "        self.out_shape = (nb_batch, self.nb_filter, height, width)\n",
    "\n",
    "        # filters\n",
    "        self.W = self.init((self.nb_filter, pre_nb_filter, filter_height, filter_width))\n",
    "        self.b = np.zeros((self.nb_filter,))\n",
    "        \n",
    "        \n",
    "    def forward(self, input, *args, **kwargs):\n",
    "        self.last_input = input\n",
    "        \n",
    "        n_filters, d_filter, h_filter, w_filter = self.W.shape\n",
    "        n_x, d_x, h_x, w_x = input.shape\n",
    "        \n",
    "        _, _, h_out, w_out, = self.out_shape\n",
    "\n",
    "        self.X_col = im2col_indices_dp(input, h_filter, w_filter, padding=self.padding, stride=self.stride)\n",
    "\n",
    "        W_col = self.W.reshape((n_filters, -1))\n",
    "\n",
    "        out = self.X_col.transpose() @ W_col.T + self.b\n",
    "        out = out.reshape((n_filters, h_out, w_out, n_x))\n",
    "        out = out.transpose((3, 0, 1, 2))\n",
    "        \n",
    "        self.last_output = self.activation.forward(out) if self.activation is not None else out\n",
    "        return out\n",
    "    \n",
    "    def backward(self, pre_grads, *args, **kwargs):\n",
    "        n_filter, d_filter, h_filter, w_filter = self.W.shape\n",
    "        \n",
    "        pre_grads = (pre_grads * self.activation.derivative(pre_grads)) if self.activation is not None else pre_grad\n",
    "        db = pre_grads.sum(axis=(0, 2, 3))\n",
    "        self.db = db.reshape((n_filter, -1))\n",
    "\n",
    "        pre_grads_reshaped = pre_grads.transpose((1, 2, 3, 0)).reshape((n_filter, -1))\n",
    "\n",
    "        dW = pre_grads_reshaped @ self.X_col.T\n",
    "        self.dW = dW.reshape(W.shape)\n",
    "\n",
    "        W_reshape = self.W.reshape(n_filter, -1)\n",
    "        dX_col = pre_grads_reshaped.transpose() @ W_reshape\n",
    "        dX = col2im_indices_dp(dX_col, self.input_shape, h_filter, w_filter, padding=self.padding, stride=self.stride)\n",
    "        return dX\n",
    "\n",
    "\n",
    "#     def forward(self, input: Union[PhiTensor, GammaTensor], *args: Tuple, **kwargs: Dict):\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "#         # TODO: This could fail if the DP Tensor has < 4 dimensions\n",
    "\n",
    "#         # shape\n",
    "#         nb_batch, input_depth, old_img_h, old_img_w = input.shape\n",
    "#         if isinstance(self.filter_size, tuple):\n",
    "#             filter_height, filter_width = self.filter_size\n",
    "#         elif isinstance(self.filter_size, int):\n",
    "#             filter_height = filter_width = self.filter_size\n",
    "#         else:\n",
    "#             raise NotImplementedError\n",
    "\n",
    "#         new_img_h, new_img_w = self.out_shape[2:]\n",
    "\n",
    "#         # init\n",
    "#         outputs = dp_zeros((nb_batch, self.nb_filter, new_img_h, new_img_w), input.data_subjects)\n",
    "\n",
    "#         # convolution operation\n",
    "#         for x in np.arange(nb_batch):\n",
    "#             for y in np.arange(self.nb_filter):\n",
    "#                 for h in np.arange(new_img_h):\n",
    "#                     for w in np.arange(new_img_w):\n",
    "#                         h_shift, w_shift = h * self.stride, w * self.stride\n",
    "#                         # patch: (input_depth, filter_h, filter_w)\n",
    "#                         patch = input[x, :, h_shift: h_shift + filter_height, w_shift: w_shift + filter_width]\n",
    "#                         outputs[x, y, h, w] = (patch * self.W[y]).sum() + self.b[y]\n",
    "\n",
    "#         # nonlinear activation\n",
    "#         # self.last_output: (nb_batch, output_depth, image height, image width)\n",
    "\n",
    "#         # TODO: Min/max vals are direct function of private data- fix this when we have time\n",
    "\n",
    "#         self.last_output = self.activation.forward(outputs) if self.activation is not None else outputs\n",
    "\n",
    "#         return self.last_output\n",
    "\n",
    "#     def backward(self, pre_grad, *args, **kwargs):\n",
    "\n",
    "#         # shape\n",
    "#         assert pre_grad.shape == self.last_output.shape\n",
    "#         nb_batch, input_depth, old_img_h, old_img_w = self.last_input.shape\n",
    "#         new_img_h, new_img_w = self.out_shape[2:]\n",
    "\n",
    "#         if isinstance(self.filter_size, tuple):\n",
    "#             filter_height, filter_width = self.filter_size\n",
    "#         elif isinstance(self.filter_size, int):\n",
    "#             filter_height = filter_width = self.filter_size\n",
    "#         else:\n",
    "#             raise NotImplementedError\n",
    "\n",
    "#         #         filter_h, filter_w = self.filter_size\n",
    "#         old_img_h, old_img_w = self.last_input.shape[-2:]\n",
    "\n",
    "#         # gradients\n",
    "#         # TODO: Decide if dW and db needs to be DP Tensors or can they live as numpy arrays\n",
    "#         self.dW = np.zeros((self.W.shape))\n",
    "#         self.db = np.zeros((self.b.shape))\n",
    "#         delta = (pre_grad * self.activation.derivative()) if self.activation is not None else pre_grad\n",
    "\n",
    "#         # dW\n",
    "#         for r in np.arange(self.nb_filter):\n",
    "#             for t in np.arange(input_depth):\n",
    "#                 for h in np.arange(filter_height):\n",
    "#                     for w in np.arange(filter_width):\n",
    "#                         input_window = self.last_input[:, t,\n",
    "#                                        h:old_img_h - filter_height + h + 1:self.stride,\n",
    "#                                        w:old_img_w - filter_width + w + 1:self.stride]\n",
    "#                         delta_window = delta[:, r]\n",
    "#                         self.dW[r, t, h, w] = ((input_window * delta_window).sum() * (1/nb_batch)).child\n",
    "#         # db\n",
    "#         for r in np.arange(self.nb_filter):\n",
    "#             self.db[r] = (delta[:, r].sum() * (1/nb_batch)).child\n",
    "\n",
    "#         # dX\n",
    "#         if not self.first_layer:\n",
    "#             layer_grads = self.last_input.zeros_like()\n",
    "#             for b in np.arange(nb_batch):\n",
    "#                 for r in np.arange(self.nb_filter):\n",
    "#                     for t in np.arange(input_depth):\n",
    "#                         for h in np.arange(new_img_h):\n",
    "#                             for w in np.arange(new_img_w):\n",
    "#                                 h_shift, w_shift = h * self.stride, w * self.stride\n",
    "#                                 temp = layer_grads[b, t, h_shift:h_shift + filter_height, w_shift:w_shift + filter_width]\n",
    "#                                 layer_grads[b, t, h_shift:h_shift + filter_height, w_shift:w_shift + filter_width] = temp+ (delta[b, r, h, w] * self.W[r, t])\n",
    "\n",
    "#             return layer_grads\n",
    "\n",
    "\n",
    "    @property\n",
    "    def params(self):\n",
    "        return self.W, self.b\n",
    "\n",
    "    @property\n",
    "    def grads(self):\n",
    "        return self.dW, self.db\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "e6018966",
   "metadata": {},
   "outputs": [],
   "source": [
    "from syft.core.tensor.nn import Model, leaky_ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "03d25f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "30358bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.add(Convolution(32, (3, 3), input_shape=(10, 3, 50, 50), padding=2, activation=leaky_ReLU()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "32673e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "a94d6a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = net.layers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "8595121c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 3, 50, 50)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "9e0fb3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = conv.forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "d5318670",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 3, 50, 50)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv.backward(out).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "b26f1561",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((32,), (32, 3, 3, 3), (32, 1), (32, 3, 3, 3))"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv.b.shape, conv.W.shape, conv.db.shape, conv.dW.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "c22cbf2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PhiTensor(child=[[[[242 111  43 ... 109  75 174]\n",
       "   [150 176 123 ... 110 160 113]\n",
       "   [165 239  13 ... 201 100  50]]\n",
       "\n",
       "  [[175  69 120 ... 167   1 144]\n",
       "   [233  67  66 ...  75 102 196]\n",
       "   [246   8   0 ... 231 140  55]]\n",
       "\n",
       "  [[ 29  93 124 ... 223  53 219]\n",
       "   [ 77  96 107 ... 166 252 162]\n",
       "   [151 149  71 ... 111  90 222]]\n",
       "\n",
       "  ...\n",
       "\n",
       "  [[ 54 165 212 ... 185 115 127]\n",
       "   [ 18 219 159 ...  31  84 201]\n",
       "   [237 133 101 ...  28 222 186]]\n",
       "\n",
       "  [[ 38 232  79 ... 141 170 158]\n",
       "   [ 33 228 165 ... 240 178 176]\n",
       "   [228  34 222 ...  35   5 133]]\n",
       "\n",
       "  [[212  95 229 ... 220  78 230]\n",
       "   [ 53  94 226 ... 151  54 224]\n",
       "   [139  55 230 ...   5 140  29]]]\n",
       "\n",
       "\n",
       " [[[196 215 251 ... 170 116 166]\n",
       "   [ 88  58 248 ...  98  34 253]\n",
       "   [181 204   0 ...  58  40 129]]\n",
       "\n",
       "  [[ 51 239  19 ...  64 155  90]\n",
       "   [ 92 174 243 ... 205  52  37]\n",
       "   [ 79  59 241 ... 161 184  46]]\n",
       "\n",
       "  [[242  22  54 ... 137 146 222]\n",
       "   [  3  50  31 ... 248  37  78]\n",
       "   [ 88  44  34 ... 144 252 173]]\n",
       "\n",
       "  ...\n",
       "\n",
       "  [[ 66 101 171 ...   7 220 114]\n",
       "   [141 169 213 ...  40 194  46]\n",
       "   [ 91  48 204 ...  84  99  15]]\n",
       "\n",
       "  [[165 138 189 ...  74  75 133]\n",
       "   [251 181  14 ... 202  24 184]\n",
       "   [ 82 105 133 ...   9  78 211]]\n",
       "\n",
       "  [[ 83  59 203 ... 239  96 168]\n",
       "   [248  49 100 ... 233  81 120]\n",
       "   [ 81 129 243 ... 238 234 208]]]\n",
       "\n",
       "\n",
       " [[[ 29 246  28 ...  65 137  47]\n",
       "   [ 68 109 101 ... 242  67 194]\n",
       "   [151  10 143 ... 233  55 136]]\n",
       "\n",
       "  [[ 28  34 162 ... 173 164  16]\n",
       "   [ 74  67 174 ...  47 228 179]\n",
       "   [134  50 237 ... 196 174 200]]\n",
       "\n",
       "  [[ 42 242 170 ...   6 112 220]\n",
       "   [ 23 182  57 ...  17  13  84]\n",
       "   [251  95 182 ...  40  40 199]]\n",
       "\n",
       "  ...\n",
       "\n",
       "  [[ 39  88 176 ... 221  56 149]\n",
       "   [ 88 241 101 ... 144  43  83]\n",
       "   [141  39  97 ... 229 215 197]]\n",
       "\n",
       "  [[183 157 254 ...  57 165 184]\n",
       "   [250  20 116 ... 227  84 247]\n",
       "   [ 57 108  86 ... 193 252 155]]\n",
       "\n",
       "  [[  5   4 126 ...  22   7  72]\n",
       "   [135 236 108 ... 199 150  66]\n",
       "   [197 227 107 ... 134 222 163]]]\n",
       "\n",
       "\n",
       " ...\n",
       "\n",
       "\n",
       " [[[ 59 151 217 ... 120 125   4]\n",
       "   [253  31 228 ...   2 139  43]\n",
       "   [162 141 228 ...  27 100 219]]\n",
       "\n",
       "  [[ 88 132  42 ... 205 134 108]\n",
       "   [112 231 142 ...  44 137 193]\n",
       "   [158  28 253 ... 232 103 159]]\n",
       "\n",
       "  [[216  36  52 ... 195 145   6]\n",
       "   [189 151 154 ... 222   0 200]\n",
       "   [ 47 118 211 ...  82  53 216]]\n",
       "\n",
       "  ...\n",
       "\n",
       "  [[ 63 149 123 ... 220 251  81]\n",
       "   [115  18  46 ... 243 215 248]\n",
       "   [ 73 106  13 ... 145  17  43]]\n",
       "\n",
       "  [[100 218 173 ...   2   0 165]\n",
       "   [ 51 102 104 ... 194 170 222]\n",
       "   [217  52 211 ...  85 195 240]]\n",
       "\n",
       "  [[129  89  88 ...  32   0 140]\n",
       "   [177  75  37 ...  87  40 169]\n",
       "   [  8 183  72 ... 241 193 247]]]\n",
       "\n",
       "\n",
       " [[[ 40 155 115 ...  16  58 100]\n",
       "   [223 216 223 ... 233 229 187]\n",
       "   [134 131 112 ... 196 201 188]]\n",
       "\n",
       "  [[ 58 250  99 ... 130  71  76]\n",
       "   [213 130 203 ... 247 194 182]\n",
       "   [210  46  51 ...  53 170  23]]\n",
       "\n",
       "  [[117  42 149 ...  94 231 151]\n",
       "   [ 75 217  72 ... 193  30  49]\n",
       "   [103 215 157 ... 224  12 202]]\n",
       "\n",
       "  ...\n",
       "\n",
       "  [[136 140 133 ... 139  33 187]\n",
       "   [238  52 137 ... 174  63  51]\n",
       "   [171  76 214 ... 220 155   0]]\n",
       "\n",
       "  [[233  72 160 ... 182 252 144]\n",
       "   [116 129 162 ... 175 164  90]\n",
       "   [ 76  80  37 ... 154  64 161]]\n",
       "\n",
       "  [[100  93 151 ... 238 211 193]\n",
       "   [ 94 125 230 ...  41  88 138]\n",
       "   [ 92 110  80 ...  46  96 197]]]\n",
       "\n",
       "\n",
       " [[[ 28 179 220 ...  85  33 117]\n",
       "   [184 112 162 ...  18   7  67]\n",
       "   [204  40 162 ... 174  55  45]]\n",
       "\n",
       "  [[ 72 227 207 ... 192  58 102]\n",
       "   [168 208 232 ... 183 235 169]\n",
       "   [100 187  29 ...  71 150  46]]\n",
       "\n",
       "  [[ 84  34   0 ...  16 189   6]\n",
       "   [134  23  91 ... 159  80 203]\n",
       "   [170 156 117 ... 207 224 220]]\n",
       "\n",
       "  ...\n",
       "\n",
       "  [[ 22 197 150 ...  61 135  95]\n",
       "   [ 83 169  57 ...  39 178 213]\n",
       "   [  5  10 129 ... 131 173 140]]\n",
       "\n",
       "  [[ 55 180  30 ...  55  79 162]\n",
       "   [ 53 254  81 ...  78  86 215]\n",
       "   [172 179 183 ...  92  53  83]]\n",
       "\n",
       "  [[ 52 152  96 ...  60 244  42]\n",
       "   [254 213  89 ... 174  98 235]\n",
       "   [ 97 249 249 ...  64 129 224]]]], min_vals=<lazyrepeatarray data: 0 -> shape: (50, 50, 3, 10)>, max_vals=<lazyrepeatarray data: 254 -> shape: (50, 50, 3, 10)>)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d31bf11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
