{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10e63b02",
   "metadata": {},
   "source": [
    "### Conv Numpy Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0879767",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shubham/anaconda3/envs/syft/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from typing import Dict\n",
    "from typing import Optional\n",
    "from typing import Tuple\n",
    "from typing import Union\n",
    "\n",
    "# third party\n",
    "import numpy as np\n",
    "\n",
    "# relative\n",
    "from syft.core.tensor.nn import activations\n",
    "from syft.core.tensor.autodp.gamma_tensor import GammaTensor\n",
    "from syft.core.tensor.autodp.phi_tensor import PhiTensor\n",
    "from syft.core.tensor.nn.initializations import XavierInitialization\n",
    "from syft.core.tensor.nn.utils import dp_zeros\n",
    "from syft.core.tensor.nn.layers.base import Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ffa0210",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_im2col_indices(x_shape, field_height, field_width, padding=1, stride=1):\n",
    "    # First figure out what the size of the output should be\n",
    "    N, C, H, W = x_shape\n",
    "    assert (H + 2 * padding - field_height) % stride == 0\n",
    "    assert (W + 2 * padding - field_height) % stride == 0\n",
    "    out_height = int((H + 2 * padding - field_height) / stride + 1)\n",
    "    out_width = int((W + 2 * padding - field_width) / stride + 1)\n",
    "\n",
    "    i0 = np.repeat(np.arange(field_height), field_width)\n",
    "    i0 = np.tile(i0, C)\n",
    "    i1 = stride * np.repeat(np.arange(out_height), out_width)\n",
    "    j0 = np.tile(np.arange(field_width), field_height * C)\n",
    "    j1 = stride * np.tile(np.arange(out_width), out_height)\n",
    "    i = i0.reshape(-1, 1) + i1.reshape(1, -1)\n",
    "    j = j0.reshape(-1, 1) + j1.reshape(1, -1)\n",
    "\n",
    "    k = np.repeat(np.arange(C), field_height * field_width).reshape(-1, 1)\n",
    "\n",
    "    return (k.astype(int), i.astype(int), j.astype(int))\n",
    "\n",
    "def im2col_indices(x, field_height, field_width, padding=1, stride=1):\n",
    "    \"\"\" An implementation of im2col based on some fancy indexing \"\"\"\n",
    "    # Zero-pad the input\n",
    "    p = padding\n",
    "    x_padded = np.pad(x, ((0, 0), (0, 0), (p, p), (p, p)), mode='constant')\n",
    "\n",
    "    k, i, j = get_im2col_indices(x.shape, field_height, field_width, padding, stride)\n",
    "\n",
    "    cols = x_padded[:, k, i, j]\n",
    "    C = x.shape[1]\n",
    "    cols = cols.transpose(1, 2, 0).reshape(field_height * field_width * C, -1)\n",
    "    return cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fcd046e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from syft import DataSubjectList\n",
    "from syft import lazyrepeatarray\n",
    "\n",
    "def dp_pad(input: Union[PhiTensor, GammaTensor], width, padding_mode=\"constant\", **kwargs):\n",
    "    \n",
    "    data = input.child    \n",
    "    output_data = np.pad(data, width, mode=padding_mode, **kwargs)\n",
    "    min_v = lazyrepeatarray(data=min(input.min_vals.data.min(), output_data.min()), shape=output_data.shape)\n",
    "    max_v = lazyrepeatarray(data=min(input.max_vals.data.max(), output_data.max()), shape=output_data.shape)\n",
    "    \n",
    "    output_data_subjects=DataSubjectList(\n",
    "        one_hot_lookup=input.data_subjects.one_hot_lookup,\n",
    "        data_subjects_indexed=np.pad(input.data_subjects.data_subjects_indexed, width, mode=padding_mode, **kwargs)\n",
    "    )\n",
    "\n",
    "    if isinstance(input, PhiTensor):\n",
    "        return PhiTensor(\n",
    "            child=output_data,\n",
    "            data_subjects=output_data_subjects,\n",
    "            min_vals=min_v,\n",
    "            max_vals=max_v\n",
    "        )\n",
    "    elif isinstance(input, GammaTensor):\n",
    "        return GammaTensor(\n",
    "            child=output_data,\n",
    "            data_subjects=output_data_subjects,\n",
    "            min_vals=min_v,\n",
    "            max_vals=max_v,\n",
    "        )\n",
    "    else:\n",
    "        raise NotImplementedError(f\"Padding is not implemented for Input Type: {type(input)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93819291",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10\n",
    "C_in = 3\n",
    "H_in = 50\n",
    "W_in = 50\n",
    "\n",
    "\n",
    "input_shape = (N, C_in, H_in, W_in)\n",
    "x = PhiTensor(child=np.random.randint(low=0, high=255, size=input_shape),\n",
    "              data_subjects=np.zeros(input_shape),\n",
    "              min_vals=0,\n",
    "              max_vals=255\n",
    "             )\n",
    "\n",
    "# TEST Padding\n",
    "# dp_pad(x, ((0, 0), (0, 0), (p, p), (p, p)), padding_mode=\"constant\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9ba6fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def im2col_indices_dp(x, field_height, field_width, padding=1, stride=1):\n",
    "    \"\"\" An implementation of im2col based on some fancy indexing \"\"\"\n",
    "    # Zero-pad the input\n",
    "    p = padding\n",
    "    x_padded = dp_pad(x, ((0, 0), (0, 0), (p, p), (p, p)), padding_mode='constant')\n",
    "\n",
    "    k, i, j = get_im2col_indices(x.shape, field_height, field_width, padding, stride)\n",
    "\n",
    "    cols = x_padded[:, k, i, j]\n",
    "    C = x.shape[1]\n",
    "    cols = cols.transpose((1, 2, 0)).reshape((field_height * field_width * C, -1))\n",
    "    return cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e77c03bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy implementation\n",
      "(3072, 5290)\n",
      "dp implementation\n",
      "(3072, 5290)\n"
     ]
    }
   ],
   "source": [
    "print(\"numpy implementation\")\n",
    "print(im2col_indices(x.child, 32, 32, padding=2, stride=1).shape)\n",
    "print(\"dp implementation\")\n",
    "print(im2col_indices_dp(x, 32, 32, padding=2, stride=1).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93417d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def conv_forward(X, W, b, stride=1, padding=1):\n",
    "    cache = W, b, stride, padding\n",
    "    n_filters, d_filter, h_filter, w_filter = W.shape\n",
    "    n_x, d_x, h_x, w_x = X.shape\n",
    "    h_out = (h_x - h_filter + 2 * padding) / stride + 1\n",
    "    w_out = (w_x - w_filter + 2 * padding) / stride + 1\n",
    "\n",
    "    if not h_out.is_integer() or not w_out.is_integer():\n",
    "        raise Exception('Invalid output dimension!')\n",
    "\n",
    "    h_out, w_out = int(h_out), int(w_out)\n",
    "    print(h_out, w_out)\n",
    "\n",
    "    X_col = im2col_indices(X, h_filter, w_filter, padding=padding, stride=stride)\n",
    "    W_col = W.reshape(n_filters, -1)\n",
    "    \n",
    "    print(W_col.shape)\n",
    "    print(X_col.shape)\n",
    "    #return W_col,X_col\n",
    "    \n",
    "\n",
    "    out = (W_col @ X_col).T + b\n",
    "    out = out.reshape(n_filters, h_out, w_out, n_x)\n",
    "    out = out.transpose(3, 0, 1, 2)\n",
    "\n",
    "    cache = (X, W, b, stride, padding, X_col)\n",
    "\n",
    "    return out, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df381dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from syft.core.tensor.nn.utils import dp_zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2b723de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52 52\n",
      "(32, 27)\n",
      "(27, 27040)\n"
     ]
    }
   ],
   "source": [
    "from syft.core.tensor.nn.initializations import XavierInitialization\n",
    "\n",
    "nb_filter = 32\n",
    "filter_height = filter_width = 3\n",
    "nb_batch, pre_nb_filter, pre_height, pre_width = x.shape\n",
    "W = XavierInitialization()((nb_filter, pre_nb_filter, filter_height, filter_width))\n",
    "W = PhiTensor(\n",
    "    child=W, \n",
    "    data_subjects=DataSubjectList(one_hot_lookup=x.data_subjects.one_hot_lookup, data_subjects_indexed=np.zeros_like(W)),\n",
    "    min_vals=W.min(),\n",
    "    max_vals=W.max()\n",
    ")\n",
    "\n",
    "b = dp_zeros(shape=(nb_filter, ), data_subjects=x.data_subjects)\n",
    "\n",
    "out, c = conv_forward(x.child, W.child, b.child, padding=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d546fd56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 32, 52, 52)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "56c2cfed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_forward_dp(X, W, b, stride=1, padding=1):\n",
    "    cache = W, b, stride, padding\n",
    "    n_filters, d_filter, h_filter, w_filter = W.shape\n",
    "    n_x, d_x, h_x, w_x = X.shape\n",
    "    h_out = (h_x - h_filter + 2 * padding) / stride + 1\n",
    "    w_out = (w_x - w_filter + 2 * padding) / stride + 1\n",
    "\n",
    "    if not h_out.is_integer() or not w_out.is_integer():\n",
    "        raise Exception('Invalid output dimension!')\n",
    "\n",
    "    h_out, w_out = int(h_out), int(w_out)\n",
    "    \n",
    "    print(h_out, w_out)\n",
    "\n",
    "    X_col = im2col_indices_dp(X, h_filter, w_filter, padding=padding, stride=stride)\n",
    "    \n",
    "    W_col = W.reshape((n_filters, -1))\n",
    "    \n",
    "    #return W_col, X_col\n",
    "    \n",
    "    \n",
    "    out = X_col.transpose() @ W_col.T + b\n",
    "    out = out.reshape((n_filters, h_out, w_out, n_x))\n",
    "    out = out.transpose((3, 0, 1, 2))\n",
    "\n",
    "    cache = (X, W, b, stride, padding, X_col)\n",
    "\n",
    "    return out, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "85d79355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52 52\n"
     ]
    }
   ],
   "source": [
    "out_dp, cache_dp = conv_forward_dp(x, W.child, b.child, padding=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b28d428c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 32, 52, 52)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_dp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a7b8c20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def col2im_indices(cols, x_shape, field_height=3, field_width=3, padding=1,\n",
    "                   stride=1):\n",
    "    \"\"\" An implementation of col2im based on fancy indexing and np.add.at \"\"\"\n",
    "    N, C, H, W = x_shape\n",
    "    H_padded, W_padded = H + 2 * padding, W + 2 * padding\n",
    "    x_padded = np.zeros((N, C, H_padded, W_padded), dtype=cols.dtype)\n",
    "    k, i, j = get_im2col_indices(x_shape, field_height, field_width, padding, stride)\n",
    "    cols_reshaped = cols.reshape(C * field_height * field_width, -1, N)\n",
    "    cols_reshaped = cols_reshaped.transpose(2, 0, 1)\n",
    "    np.add.at(x_padded, (slice(None), k, i, j), cols_reshaped)\n",
    "    if padding == 0:\n",
    "        return x_padded\n",
    "    return x_padded[:, :, padding:-padding, padding:-padding]\n",
    "\n",
    "\n",
    "def conv_backward(dout, cache):\n",
    "    X, W, b, stride, padding, X_col = cache\n",
    "    n_filter, d_filter, h_filter, w_filter = W.shape\n",
    "\n",
    "    db = np.sum(dout, axis=(0, 2, 3))\n",
    "    db = db.reshape(n_filter, -1)\n",
    "\n",
    "    dout_reshaped = dout.transpose(1, 2, 3, 0).reshape(n_filter, -1)\n",
    "    dW = dout_reshaped @ X_col.T\n",
    "    dW = dW.reshape(W.shape)\n",
    "\n",
    "    W_reshape = W.reshape(n_filter, -1)\n",
    "    dX_col = W_reshape.T @ dout_reshaped\n",
    "    print(\"dX_col\", dX_col.shape)\n",
    "    dX = col2im_indices(dX_col, X.shape, h_filter, w_filter, padding=padding, stride=stride)\n",
    "    return dX, dW, db\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "df891a74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dX_col (27, 27040)\n"
     ]
    }
   ],
   "source": [
    "dX, dW, db = conv_backward(out, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cb55a3b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10, 3, 50, 50), (32, 3, 3, 3), (32, 1))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dX.shape, dW.shape, db.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "104d93dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dp_add_at(a, indices, b):\n",
    "    data_a = a.child\n",
    "    data_b = b.child\n",
    "    np.add.at(data_a,indices, data_b)\n",
    "    return PhiTensor(\n",
    "        child=data_a,\n",
    "        data_subjects=a.data_subjects,\n",
    "        min_vals=data_a.min(),\n",
    "        max_vals=data_a.max()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "13e231b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def col2im_indices_dp(cols, x_shape, field_height=3, field_width=3, padding=1, stride=1):\n",
    "    \"\"\" An implementation of col2im based on fancy indexing and np.add.at \"\"\"\n",
    "    N, C, H, W = x_shape\n",
    "    H_padded, W_padded = H + 2 * padding, W + 2 * padding\n",
    "    x_padded = dp_zeros((N, C, H_padded, W_padded), data_subjects=cols.data_subjects)\n",
    "    k, i, j = get_im2col_indices(x_shape, field_height, field_width, padding, stride)\n",
    "    cols_reshaped = cols.reshape((C * field_height * field_width, -1, N))\n",
    "    cols_reshaped = cols_reshaped.transpose((2, 0, 1))\n",
    "    x_padded = dp_add_at(x_padded, (slice(None), k, i, j), cols_reshaped)\n",
    "    if padding == 0:\n",
    "        return x_padded\n",
    "    return x_padded[:, :, padding:-padding, padding:-padding]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f7751999",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_backward_dp(dout, cache):\n",
    "    X, W, b, stride, padding, X_col = cache\n",
    "    n_filter, d_filter, h_filter, w_filter = W.shape\n",
    "\n",
    "    db = dout.sum(axis=(0, 2, 3))\n",
    "    db = db.reshape((n_filter, -1))\n",
    "\n",
    "    dout_reshaped = dout.transpose((1, 2, 3, 0)).reshape((n_filter, -1))\n",
    "    \n",
    "    dW = dout_reshaped @ X_col.T\n",
    "    dW = dW.reshape(W.shape)\n",
    "\n",
    "    W_reshape = W.reshape(n_filter, -1)\n",
    "    dX_col = dout_reshaped.transpose() @ W_reshape\n",
    "    dX = col2im_indices_dp(dX_col, X.shape, h_filter, w_filter, padding=padding, stride=stride)\n",
    "\n",
    "    return dX, dW, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6c5391ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "dX_dp, dW_dp, db_dp = conv_backward_dp(out_dp, cache_dp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f26767e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10, 3, 50, 50), (32, 3, 3, 3), (32, 1))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dX_dp.shape, dW_dp.shape, db_dp.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6647836b",
   "metadata": {},
   "source": [
    "### Conv PhiTensor Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "ec11af2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stdlib\n",
    "from typing import Dict\n",
    "from typing import Optional\n",
    "from typing import Tuple\n",
    "from typing import Union\n",
    "\n",
    "# third party\n",
    "import numpy as np\n",
    "\n",
    "# relative\n",
    "from syft.core.tensor.nn import activations\n",
    "from syft.core.tensor.autodp.gamma_tensor import GammaTensor\n",
    "from syft.core.tensor.autodp.phi_tensor import PhiTensor\n",
    "from syft.core.tensor.nn.initializations import XavierInitialization\n",
    "from syft.core.tensor.nn.utils import dp_zeros\n",
    "from syft.core.tensor.nn.layers.base import Layer\n",
    "\n",
    "\n",
    "class Convolution(Layer):\n",
    "    \"\"\"\n",
    "    If this is the first layer in a model, provide the keyword argument `input_shape`\n",
    "    (tuple of integers, does NOT include the sample axis, N.),\n",
    "    e.g. `input_shape=(3, 128, 128)` for 128x128 RGB pictures.\n",
    "    \"\"\"\n",
    "    __name__ = \"ConvPointer\"\n",
    "    __module__ = \"syft.core.tensor.nn.layers.convolution\"\n",
    "    __attr_allowlist__ = [\n",
    "        \"nb_filter\",\n",
    "        \"filter_size\",\n",
    "        \"input_shape\",\n",
    "        \"stride\",\n",
    "        \"W\",\n",
    "        \"b\",\n",
    "        \"dW\",\n",
    "        \"db\",\n",
    "        \"out_shape\",\n",
    "        \"last_output\",\n",
    "        \"last_input\"\n",
    "    ]\n",
    "\n",
    "    def __init__(self, nb_filter, filter_size, input_shape: Optional[Tuple]=None, stride: int=1, padding: int=0, activation: Optional[activations.Activation]=None):\n",
    "        self.nb_filter = nb_filter\n",
    "        self.filter_size = filter_size\n",
    "        self.input_shape = input_shape\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "\n",
    "        self.W, self.dW = None, None\n",
    "        self.b, self.db = None, None\n",
    "        self.out_shape = None\n",
    "        self.last_output = None\n",
    "        self.last_input = None\n",
    "\n",
    "        self.init = XavierInitialization()\n",
    "        self.activation = activations.get(activation)\n",
    "\n",
    "    def connect_to(self, prev_layer: Optional[Layer]=None):\n",
    "        if prev_layer is None:\n",
    "            assert self.input_shape is not None\n",
    "            input_shape = self.input_shape\n",
    "        else:\n",
    "            input_shape = prev_layer.out_shape\n",
    "\n",
    "        # input_shape: (batch size, num input feature maps, image height, image width)\n",
    "        assert len(input_shape) == 4\n",
    "\n",
    "        nb_batch, pre_nb_filter, pre_height, pre_width = input_shape\n",
    "        if isinstance(self.filter_size, tuple):\n",
    "            filter_height, filter_width = self.filter_size\n",
    "        elif isinstance(self.filter_size, int):\n",
    "            filter_height = filter_width = self.filter_size\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        height = (pre_height - filter_height + 2 * self.padding) // self.stride + 1\n",
    "        width = (pre_width - filter_width +  2 * self.padding) // self.stride + 1\n",
    "\n",
    "        # output shape\n",
    "        self.out_shape = (nb_batch, self.nb_filter, height, width)\n",
    "\n",
    "        # filters\n",
    "        self.W = self.init((self.nb_filter, pre_nb_filter, filter_height, filter_width))\n",
    "        self.b = np.zeros((self.nb_filter,))\n",
    "        \n",
    "        \n",
    "    def forward(self, input, *args, **kwargs):\n",
    "        self.last_input = input\n",
    "        \n",
    "        n_filters, d_filter, h_filter, w_filter = self.W.shape\n",
    "        n_x, d_x, h_x, w_x = input.shape\n",
    "        \n",
    "        _, _, h_out, w_out, = self.out_shape\n",
    "\n",
    "        self.X_col = im2col_indices_dp(input, h_filter, w_filter, padding=self.padding, stride=self.stride)\n",
    "\n",
    "        W_col = self.W.reshape((n_filters, -1))\n",
    "\n",
    "        out = self.X_col.transpose() @ W_col.T + self.b\n",
    "        out = out.reshape((n_filters, h_out, w_out, n_x))\n",
    "        out = out.transpose((3, 0, 1, 2))\n",
    "        \n",
    "        self.last_output = self.activation.forward(out) if self.activation is not None else out\n",
    "        return out\n",
    "    \n",
    "    def backward(self, pre_grads, *args, **kwargs):\n",
    "        n_filter, d_filter, h_filter, w_filter = self.W.shape\n",
    "        \n",
    "        pre_grads = (pre_grads * self.activation.derivative(pre_grads)) if self.activation is not None else pre_grad\n",
    "        db = pre_grads.sum(axis=(0, 2, 3))\n",
    "        self.db = db.reshape((n_filter, -1))\n",
    "\n",
    "        pre_grads_reshaped = pre_grads.transpose((1, 2, 3, 0)).reshape((n_filter, -1))\n",
    "\n",
    "        dW = pre_grads_reshaped @ self.X_col.T\n",
    "        self.dW = dW.reshape(W.shape)\n",
    "\n",
    "        W_reshape = self.W.reshape(n_filter, -1)\n",
    "        dX_col = pre_grads_reshaped.transpose() @ W_reshape\n",
    "        dX = col2im_indices_dp(dX_col, self.input_shape, h_filter, w_filter, padding=self.padding, stride=self.stride)\n",
    "        return dX\n",
    "\n",
    "\n",
    "#     def forward(self, input: Union[PhiTensor, GammaTensor], *args: Tuple, **kwargs: Dict):\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "#         # TODO: This could fail if the DP Tensor has < 4 dimensions\n",
    "\n",
    "#         # shape\n",
    "#         nb_batch, input_depth, old_img_h, old_img_w = input.shape\n",
    "#         if isinstance(self.filter_size, tuple):\n",
    "#             filter_height, filter_width = self.filter_size\n",
    "#         elif isinstance(self.filter_size, int):\n",
    "#             filter_height = filter_width = self.filter_size\n",
    "#         else:\n",
    "#             raise NotImplementedError\n",
    "\n",
    "#         new_img_h, new_img_w = self.out_shape[2:]\n",
    "\n",
    "#         # init\n",
    "#         outputs = dp_zeros((nb_batch, self.nb_filter, new_img_h, new_img_w), input.data_subjects)\n",
    "\n",
    "#         # convolution operation\n",
    "#         for x in np.arange(nb_batch):\n",
    "#             for y in np.arange(self.nb_filter):\n",
    "#                 for h in np.arange(new_img_h):\n",
    "#                     for w in np.arange(new_img_w):\n",
    "#                         h_shift, w_shift = h * self.stride, w * self.stride\n",
    "#                         # patch: (input_depth, filter_h, filter_w)\n",
    "#                         patch = input[x, :, h_shift: h_shift + filter_height, w_shift: w_shift + filter_width]\n",
    "#                         outputs[x, y, h, w] = (patch * self.W[y]).sum() + self.b[y]\n",
    "\n",
    "#         # nonlinear activation\n",
    "#         # self.last_output: (nb_batch, output_depth, image height, image width)\n",
    "\n",
    "#         # TODO: Min/max vals are direct function of private data- fix this when we have time\n",
    "\n",
    "#         self.last_output = self.activation.forward(outputs) if self.activation is not None else outputs\n",
    "\n",
    "#         return self.last_output\n",
    "\n",
    "#     def backward(self, pre_grad, *args, **kwargs):\n",
    "\n",
    "#         # shape\n",
    "#         assert pre_grad.shape == self.last_output.shape\n",
    "#         nb_batch, input_depth, old_img_h, old_img_w = self.last_input.shape\n",
    "#         new_img_h, new_img_w = self.out_shape[2:]\n",
    "\n",
    "#         if isinstance(self.filter_size, tuple):\n",
    "#             filter_height, filter_width = self.filter_size\n",
    "#         elif isinstance(self.filter_size, int):\n",
    "#             filter_height = filter_width = self.filter_size\n",
    "#         else:\n",
    "#             raise NotImplementedError\n",
    "\n",
    "#         #         filter_h, filter_w = self.filter_size\n",
    "#         old_img_h, old_img_w = self.last_input.shape[-2:]\n",
    "\n",
    "#         # gradients\n",
    "#         # TODO: Decide if dW and db needs to be DP Tensors or can they live as numpy arrays\n",
    "#         self.dW = np.zeros((self.W.shape))\n",
    "#         self.db = np.zeros((self.b.shape))\n",
    "#         delta = (pre_grad * self.activation.derivative()) if self.activation is not None else pre_grad\n",
    "\n",
    "#         # dW\n",
    "#         for r in np.arange(self.nb_filter):\n",
    "#             for t in np.arange(input_depth):\n",
    "#                 for h in np.arange(filter_height):\n",
    "#                     for w in np.arange(filter_width):\n",
    "#                         input_window = self.last_input[:, t,\n",
    "#                                        h:old_img_h - filter_height + h + 1:self.stride,\n",
    "#                                        w:old_img_w - filter_width + w + 1:self.stride]\n",
    "#                         delta_window = delta[:, r]\n",
    "#                         self.dW[r, t, h, w] = ((input_window * delta_window).sum() * (1/nb_batch)).child\n",
    "#         # db\n",
    "#         for r in np.arange(self.nb_filter):\n",
    "#             self.db[r] = (delta[:, r].sum() * (1/nb_batch)).child\n",
    "\n",
    "#         # dX\n",
    "#         if not self.first_layer:\n",
    "#             layer_grads = self.last_input.zeros_like()\n",
    "#             for b in np.arange(nb_batch):\n",
    "#                 for r in np.arange(self.nb_filter):\n",
    "#                     for t in np.arange(input_depth):\n",
    "#                         for h in np.arange(new_img_h):\n",
    "#                             for w in np.arange(new_img_w):\n",
    "#                                 h_shift, w_shift = h * self.stride, w * self.stride\n",
    "#                                 temp = layer_grads[b, t, h_shift:h_shift + filter_height, w_shift:w_shift + filter_width]\n",
    "#                                 layer_grads[b, t, h_shift:h_shift + filter_height, w_shift:w_shift + filter_width] = temp+ (delta[b, r, h, w] * self.W[r, t])\n",
    "\n",
    "#             return layer_grads\n",
    "\n",
    "\n",
    "    @property\n",
    "    def params(self):\n",
    "        return self.W, self.b\n",
    "\n",
    "    @property\n",
    "    def grads(self):\n",
    "        return self.dW, self.db\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6018966",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shubham/anaconda3/envs/syft/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from syft.core.tensor.nn import Model, leaky_ReLU, Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03d25f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "30358bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.add(Convolution(32, (3, 3), input_shape=(10, 3, 50, 50), padding=2, activation=leaky_ReLU()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "32673e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a94d6a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = net.layers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8595121c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 3, 50, 50)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6ebcb6c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 3, 3, 3)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv.W.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9e0fb3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = conv.forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d5318670",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 3, 50, 50)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv.backward(out).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b26f1561",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((32,), (32, 3, 3, 3), (32, 1), (32, 3, 3, 3))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv.b.shape, conv.W.shape, conv.db.shape, conv.dW.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d31bf11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shubham/anaconda3/envs/syft/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from syft import PhiTensor\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e341e72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10\n",
    "C_in = 3\n",
    "H_in = 50\n",
    "W_in = 50\n",
    "\n",
    "\n",
    "input_shape = (N, C_in, H_in, W_in)\n",
    "x = PhiTensor(child=np.random.randint(low=0, high=255, size=input_shape),\n",
    "              data_subjects=np.zeros(input_shape),\n",
    "              min_vals=0,\n",
    "              max_vals=255\n",
    "             )\n",
    "\n",
    "# TEST Padding\n",
    "# dp_pad(x, ((0, 0), (0, 0), (p, p), (p, p)), padding_mode=\"constant\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c72e4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from syft.core.tensor.nn import Convolution, Model, leaky_ReLU, MaxPool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a03bc68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward pass (10, 32, 52, 52)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10, 3, 50, 50)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = Model()\n",
    "net.add(Convolution(32, (3, 3), input_shape=(10, 3, 50, 50), padding=2, activation=leaky_ReLU()))\n",
    "net.add(MaxPool(pool_size=2, stride=2))\n",
    "net.compile()\n",
    "conv = net.layers[0]\n",
    "out = conv.forward(x)\n",
    "print(\"Forward pass\", out.shape)\n",
    "conv.backward(out).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2bd411a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_col, max_idx, h_out, w_out, n, d = net.layers[1].forward(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e7694cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 216320)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_col.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1d20552",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(320, 4, 676)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_col.data_subjects.data_subjects_indexed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "faf936df",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = X_col.child[max_idx, range(max_idx.size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "314bedc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26, 26, 10, 32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.reshape((h_out, w_out, n, d)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3acd2c66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 32, 26, 26)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_grad = outputs.reshape((h_out, w_out, n, d)).transpose((2, 3, 0, 1))\n",
    "pre_grad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd497c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_grad_dp = PhiTensor(pre_grad, data_subjects=out.data_subjects, min_vals=pre_grad.min(), max_vals=pre_grad.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f8658e40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PhiTensor(child=[[[[ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ... -6.99675377e+00\n",
       "     0.00000000e+00  0.00000000e+00]\n",
       "   [ 3.73643371e+01  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
       "     3.95675068e+01  0.00000000e+00]\n",
       "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
       "     0.00000000e+00  0.00000000e+00]\n",
       "   ...\n",
       "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
       "     0.00000000e+00  0.00000000e+00]\n",
       "   [ 0.00000000e+00  3.62330216e+01  0.00000000e+00 ...  0.00000000e+00\n",
       "     0.00000000e+00  0.00000000e+00]\n",
       "   [ 0.00000000e+00  0.00000000e+00  4.54815898e+01 ...  3.19487632e+01\n",
       "     0.00000000e+00  2.86792358e+01]]\n",
       "\n",
       "  [[ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
       "     0.00000000e+00  2.71262295e+01]\n",
       "   [ 2.68434059e+01  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
       "     0.00000000e+00  0.00000000e+00]\n",
       "   [ 0.00000000e+00  4.11775064e+01  0.00000000e+00 ...  3.53986042e+01\n",
       "     0.00000000e+00  0.00000000e+00]\n",
       "   ...\n",
       "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
       "     0.00000000e+00  0.00000000e+00]\n",
       "   [ 0.00000000e+00  1.70757847e+02  0.00000000e+00 ...  1.07050139e+02\n",
       "     5.40531835e+01  0.00000000e+00]\n",
       "   [ 0.00000000e+00  0.00000000e+00  1.18366825e+02 ...  0.00000000e+00\n",
       "     0.00000000e+00  0.00000000e+00]]\n",
       "\n",
       "  [[ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  5.65828776e+01\n",
       "     0.00000000e+00  1.33360840e+02]\n",
       "   [ 0.00000000e+00  3.16820270e+01  0.00000000e+00 ...  0.00000000e+00\n",
       "     0.00000000e+00  0.00000000e+00]\n",
       "   [ 0.00000000e+00  7.23013506e+01  0.00000000e+00 ...  0.00000000e+00\n",
       "     0.00000000e+00  0.00000000e+00]\n",
       "   ...\n",
       "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
       "     0.00000000e+00  0.00000000e+00]\n",
       "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  5.45396960e+01\n",
       "     0.00000000e+00  0.00000000e+00]\n",
       "   [ 0.00000000e+00  1.11025093e+02  7.71772423e+01 ...  0.00000000e+00\n",
       "     8.73664115e+01  0.00000000e+00]]\n",
       "\n",
       "  ...\n",
       "\n",
       "  [[ 0.00000000e+00  2.79324344e+01  0.00000000e+00 ...  0.00000000e+00\n",
       "     0.00000000e+00  1.33767429e+02]\n",
       "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  4.51048265e+01\n",
       "     0.00000000e+00  0.00000000e+00]\n",
       "   [ 0.00000000e+00  7.55475437e+01  0.00000000e+00 ...  5.12135737e+01\n",
       "     0.00000000e+00  0.00000000e+00]\n",
       "   ...\n",
       "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
       "     0.00000000e+00  0.00000000e+00]\n",
       "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  9.67741613e+01\n",
       "     0.00000000e+00  0.00000000e+00]\n",
       "   [ 4.72718388e+01  0.00000000e+00  2.71977039e+01 ...  0.00000000e+00\n",
       "     6.49279447e+01  0.00000000e+00]]\n",
       "\n",
       "  [[ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
       "     0.00000000e+00  1.33811112e+02]\n",
       "   [ 0.00000000e+00  5.39234236e+01  0.00000000e+00 ...  0.00000000e+00\n",
       "     0.00000000e+00  0.00000000e+00]\n",
       "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  7.68129465e+01\n",
       "     0.00000000e+00  0.00000000e+00]\n",
       "   ...\n",
       "   [ 0.00000000e+00  3.31025636e+01  0.00000000e+00 ...  0.00000000e+00\n",
       "     0.00000000e+00  0.00000000e+00]\n",
       "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
       "     0.00000000e+00  0.00000000e+00]\n",
       "   [ 7.52175047e+01  0.00000000e+00  1.22159939e+02 ...  0.00000000e+00\n",
       "     1.08992821e+02  0.00000000e+00]]\n",
       "\n",
       "  [[ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
       "     0.00000000e+00  5.56161478e+01]\n",
       "   [ 0.00000000e+00  8.57840105e+01  0.00000000e+00 ...  6.57355259e+01\n",
       "     0.00000000e+00  0.00000000e+00]\n",
       "   [ 0.00000000e+00  0.00000000e+00  7.34097598e+01 ...  6.25389466e+01\n",
       "     0.00000000e+00  0.00000000e+00]\n",
       "   ...\n",
       "   [ 0.00000000e+00  3.13398143e+01  0.00000000e+00 ...  8.01198305e+01\n",
       "     0.00000000e+00  0.00000000e+00]\n",
       "   [ 0.00000000e+00  4.29959165e+01  8.84912823e+01 ...  0.00000000e+00\n",
       "     0.00000000e+00  0.00000000e+00]\n",
       "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
       "     0.00000000e+00  2.34652635e+01]]]\n",
       "\n",
       "\n",
       " [[[ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
       "     0.00000000e+00  0.00000000e+00]\n",
       "   [ 0.00000000e+00  2.31641971e+01  3.44288465e+01 ... -1.16917847e+01\n",
       "     1.92037702e+01  0.00000000e+00]\n",
       "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
       "     0.00000000e+00  0.00000000e+00]\n",
       "   ...\n",
       "   [ 0.00000000e+00  4.66600010e+01  0.00000000e+00 ...  0.00000000e+00\n",
       "     3.87526136e+01  0.00000000e+00]\n",
       "   [ 0.00000000e+00  5.02012043e+01  0.00000000e+00 ...  3.94589770e+01\n",
       "     0.00000000e+00  0.00000000e+00]\n",
       "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
       "     0.00000000e+00  4.97204138e+01]]\n",
       "\n",
       "  [[ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
       "     0.00000000e+00  2.81654207e+01]\n",
       "   [ 0.00000000e+00  3.05183792e+01  2.64336296e+01 ...  5.68212987e+01\n",
       "     0.00000000e+00  0.00000000e+00]\n",
       "   [ 0.00000000e+00  4.20728524e+01  0.00000000e+00 ...  7.25266939e+01\n",
       "     0.00000000e+00  0.00000000e+00]\n",
       "   ...\n",
       "   [ 0.00000000e+00  1.52723180e+01  0.00000000e+00 ...  2.36890836e+00\n",
       "     4.36107529e+01  0.00000000e+00]\n",
       "   [ 0.00000000e+00 -4.71902785e-01  0.00000000e+00 ...  0.00000000e+00\n",
       "     1.14405087e+01  0.00000000e+00]\n",
       "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  3.90320095e+01\n",
       "     0.00000000e+00  0.00000000e+00]]\n",
       "\n",
       "  [[ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
       "     0.00000000e+00  8.85093352e+01]\n",
       "   [ 0.00000000e+00  1.20644085e+01  0.00000000e+00 ...  0.00000000e+00\n",
       "     0.00000000e+00  0.00000000e+00]\n",
       "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  1.85671299e+01\n",
       "     0.00000000e+00  4.25192549e+01]\n",
       "   ...\n",
       "   [ 0.00000000e+00  2.27889961e+01  6.42930096e+01 ...  2.70918319e+00\n",
       "     0.00000000e+00  0.00000000e+00]\n",
       "   [ 0.00000000e+00  4.77753551e+01  0.00000000e+00 ...  2.74273259e+01\n",
       "     0.00000000e+00  5.05458966e+01]\n",
       "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
       "     0.00000000e+00  0.00000000e+00]]\n",
       "\n",
       "  ...\n",
       "\n",
       "  [[ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
       "     0.00000000e+00  6.99125522e+01]\n",
       "   [ 0.00000000e+00  4.93905149e+01  6.77138483e+01 ... -2.62073372e+01\n",
       "     0.00000000e+00  0.00000000e+00]\n",
       "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ... -3.56295491e-03\n",
       "     0.00000000e+00  0.00000000e+00]\n",
       "   ...\n",
       "   [ 0.00000000e+00 -2.16062869e+01  0.00000000e+00 ...  3.24616610e+01\n",
       "     0.00000000e+00  0.00000000e+00]\n",
       "   [ 0.00000000e+00 -9.51744267e+00  0.00000000e+00 ...  0.00000000e+00\n",
       "     5.70953172e+01  0.00000000e+00]\n",
       "   [ 0.00000000e+00  0.00000000e+00  2.53521273e+01 ...  0.00000000e+00\n",
       "     0.00000000e+00  0.00000000e+00]]\n",
       "\n",
       "  [[ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
       "     0.00000000e+00  0.00000000e+00]\n",
       "   [ 0.00000000e+00  4.78030696e+01  0.00000000e+00 ...  0.00000000e+00\n",
       "     9.86054547e+01  0.00000000e+00]\n",
       "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
       "     0.00000000e+00  0.00000000e+00]\n",
       "   ...\n",
       "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
       "     0.00000000e+00  0.00000000e+00]\n",
       "   [ 0.00000000e+00  0.00000000e+00  4.52092554e+00 ...  0.00000000e+00\n",
       "     9.34121172e+00  0.00000000e+00]\n",
       "   [ 0.00000000e+00  1.07550586e+01  0.00000000e+00 ...  0.00000000e+00\n",
       "     0.00000000e+00  0.00000000e+00]]\n",
       "\n",
       "  [[ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
       "     0.00000000e+00  5.91305083e+01]\n",
       "   [-8.10565081e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
       "     0.00000000e+00  0.00000000e+00]\n",
       "   [ 0.00000000e+00  0.00000000e+00  2.39384574e+01 ...  0.00000000e+00\n",
       "     0.00000000e+00  1.37574020e+01]\n",
       "   ...\n",
       "   [ 5.39751231e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
       "     0.00000000e+00  0.00000000e+00]\n",
       "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
       "     0.00000000e+00  0.00000000e+00]\n",
       "   [ 0.00000000e+00  2.53631890e+01  0.00000000e+00 ...  2.50741538e+01\n",
       "     0.00000000e+00  6.05823197e+00]]]\n",
       "\n",
       "\n",
       " [[[ 9.66009710e+00  0.00000000e+00  2.64014253e+01 ...  0.00000000e+00\n",
       "     0.00000000e+00  0.00000000e+00]\n",
       "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
       "     3.80939006e+01  0.00000000e+00]\n",
       "   [ 0.00000000e+00  3.48933618e+01  2.05545111e+01 ...  0.00000000e+00\n",
       "     0.00000000e+00  0.00000000e+00]\n",
       "   ...\n",
       "   [ 0.00000000e+00  0.00000000e+00  8.89850506e+01 ...  0.00000000e+00\n",
       "     4.72271896e+01  0.00000000e+00]\n",
       "   [ 0.00000000e+00  0.00000000e+00  4.07461977e+01 ...  0.00000000e+00\n",
       "     4.19031696e+01  0.00000000e+00]\n",
       "   [ 5.64486062e+01  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
       "     0.00000000e+00  0.00000000e+00]]\n",
       "\n",
       "  [[ 5.25810659e+01  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
       "     0.00000000e+00  0.00000000e+00]\n",
       "   [ 0.00000000e+00  0.00000000e+00  4.97788507e+01 ...  0.00000000e+00\n",
       "     5.28418278e+01  0.00000000e+00]\n",
       "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
       "     5.42642374e+01  0.00000000e+00]\n",
       "   ...\n",
       "   [ 0.00000000e+00  0.00000000e+00  1.15859093e+02 ...  0.00000000e+00\n",
       "     1.03680843e+02  0.00000000e+00]\n",
       "   [ 0.00000000e+00  0.00000000e+00  2.27381424e+01 ...  0.00000000e+00\n",
       "     0.00000000e+00  4.26338537e+01]\n",
       "   [ 6.84871538e+01  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
       "     0.00000000e+00  0.00000000e+00]]\n",
       "\n",
       "  [[ 0.00000000e+00  4.83506763e+01  0.00000000e+00 ...  0.00000000e+00\n",
       "     0.00000000e+00  0.00000000e+00]\n",
       "   [ 0.00000000e+00  0.00000000e+00  5.70867916e+01 ...  0.00000000e+00\n",
       "     1.11545060e+02  0.00000000e+00]\n",
       "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
       "     0.00000000e+00  0.00000000e+00]\n",
       "   ...\n",
       "   [ 0.00000000e+00  0.00000000e+00  6.39519676e+01 ...  0.00000000e+00\n",
       "     6.48990192e+01  0.00000000e+00]\n",
       "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
       "     0.00000000e+00  0.00000000e+00]\n",
       "   [ 1.07994166e+02  0.00000000e+00  3.61775107e+01 ...  0.00000000e+00\n",
       "     0.00000000e+00  7.24697286e-01]]\n",
       "\n",
       "  ...\n",
       "\n",
       "  [[ 0.00000000e+00  9.58358694e+01  0.00000000e+00 ...  9.78234816e+01\n",
       "     0.00000000e+00  0.00000000e+00]\n",
       "   [ 0.00000000e+00  0.00000000e+00  1.29977021e+02 ...  0.00000000e+00\n",
       "     1.09115931e+02  0.00000000e+00]\n",
       "   [ 0.00000000e+00  0.00000000e+00  5.54064136e+01 ...  0.00000000e+00\n",
       "     0.00000000e+00  0.00000000e+00]\n",
       "   ...\n",
       "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
       "     1.06108414e+02  0.00000000e+00]\n",
       "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
       "     0.00000000e+00  6.80103274e+01]\n",
       "   [ 6.75026306e+01  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
       "     0.00000000e+00  0.00000000e+00]]\n",
       "\n",
       "  [[ 4.20492862e+01  0.00000000e+00  0.00000000e+00 ...  6.94720126e+01\n",
       "     0.00000000e+00  0.00000000e+00]\n",
       "   [ 0.00000000e+00  0.00000000e+00  7.44462126e+01 ...  0.00000000e+00\n",
       "     7.61596825e+01  0.00000000e+00]\n",
       "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
       "     4.96322671e+01  0.00000000e+00]\n",
       "   ...\n",
       "   [ 0.00000000e+00  7.52083262e+01  8.29613852e+01 ...  0.00000000e+00\n",
       "     7.01599386e+01  0.00000000e+00]\n",
       "   [ 9.00440078e+01  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
       "     0.00000000e+00  0.00000000e+00]\n",
       "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  6.95407847e+01\n",
       "     0.00000000e+00  4.25578288e+01]]\n",
       "\n",
       "  [[ 0.00000000e+00  1.16892147e+02  0.00000000e+00 ...  0.00000000e+00\n",
       "     0.00000000e+00  0.00000000e+00]\n",
       "   [ 0.00000000e+00  0.00000000e+00  1.19138666e+02 ...  6.24522452e+01\n",
       "     8.87380818e+01  0.00000000e+00]\n",
       "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
       "     0.00000000e+00  0.00000000e+00]\n",
       "   ...\n",
       "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
       "     1.13496084e+02  0.00000000e+00]\n",
       "   [ 9.57684577e+01  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
       "     0.00000000e+00  2.31985047e+01]\n",
       "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
       "     0.00000000e+00  0.00000000e+00]]]\n",
       "\n",
       "\n",
       " ...\n",
       "\n",
       "\n",
       " [[[ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
       "     0.00000000e+00  0.00000000e+00]\n",
       "   [ 0.00000000e+00  4.44544741e+01  0.00000000e+00 ...  0.00000000e+00\n",
       "     0.00000000e+00  5.35885202e+01]\n",
       "   [ 2.83688518e+01  0.00000000e+00  0.00000000e+00 ...  8.34756474e+00\n",
       "     0.00000000e+00  0.00000000e+00]\n",
       "   ...\n",
       "   [ 5.92127986e+01  0.00000000e+00  0.00000000e+00 ...  2.88310838e+01\n",
       "     0.00000000e+00  0.00000000e+00]\n",
       "   [ 3.34886042e+01  0.00000000e+00  1.57166100e+01 ...  0.00000000e+00\n",
       "     0.00000000e+00  0.00000000e+00]\n",
       "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
       "     2.93181817e+01  0.00000000e+00]]\n",
       "\n",
       "  [[ 0.00000000e+00  0.00000000e+00 -6.70080106e+00 ...  0.00000000e+00\n",
       "     6.70621873e+01  0.00000000e+00]\n",
       "   [ 3.92661091e+01  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
       "     0.00000000e+00  0.00000000e+00]\n",
       "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
       "     2.13498072e+01  0.00000000e+00]\n",
       "   ...\n",
       "   [ 0.00000000e+00  2.29687359e+01  2.09986627e+01 ...  0.00000000e+00\n",
       "     0.00000000e+00  0.00000000e+00]\n",
       "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
       "     0.00000000e+00  0.00000000e+00]\n",
       "   [ 9.62810661e+01  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
       "     0.00000000e+00  3.13858206e+01]]\n",
       "\n",
       "  [[ 5.85996782e+01  0.00000000e+00  3.79932896e+01 ...  0.00000000e+00\n",
       "     0.00000000e+00  4.90018039e+01]\n",
       "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
       "     0.00000000e+00  0.00000000e+00]\n",
       "   [ 5.50919976e+01  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
       "     0.00000000e+00  0.00000000e+00]\n",
       "   ...\n",
       "   [ 3.72361951e+01  0.00000000e+00  1.11807386e+01 ...  0.00000000e+00\n",
       "     8.92819951e+00  0.00000000e+00]\n",
       "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
       "     0.00000000e+00  0.00000000e+00]\n",
       "   [ 1.63553635e+01  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
       "     0.00000000e+00  5.81043598e+01]]\n",
       "\n",
       "  ...\n",
       "\n",
       "  [[ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
       "     0.00000000e+00  1.16403673e+01]\n",
       "   [-3.76522676e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
       "     0.00000000e+00  0.00000000e+00]\n",
       "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
       "     0.00000000e+00  0.00000000e+00]\n",
       "   ...\n",
       "   [ 0.00000000e+00  2.60750632e+01  2.65455981e+01 ...  0.00000000e+00\n",
       "     1.17105959e+01  0.00000000e+00]\n",
       "   [ 7.66281019e+01  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
       "     0.00000000e+00  2.52880872e+01]\n",
       "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
       "     0.00000000e+00  0.00000000e+00]]\n",
       "\n",
       "  [[-8.44681805e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
       "     0.00000000e+00  0.00000000e+00]\n",
       "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  5.24465802e+01\n",
       "     3.44817722e+01  0.00000000e+00]\n",
       "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
       "     0.00000000e+00  0.00000000e+00]\n",
       "   ...\n",
       "   [ 0.00000000e+00  0.00000000e+00  4.20135129e+01 ...  0.00000000e+00\n",
       "     1.33719023e+01  0.00000000e+00]\n",
       "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
       "     0.00000000e+00  2.18811989e+01]\n",
       "   [ 6.80345729e+01  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
       "     0.00000000e+00  0.00000000e+00]]\n",
       "\n",
       "  [[ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
       "     0.00000000e+00  0.00000000e+00]\n",
       "   [-1.72766440e+01  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
       "     2.71747411e+01  0.00000000e+00]\n",
       "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
       "     0.00000000e+00  1.98289108e+01]\n",
       "   ...\n",
       "   [ 0.00000000e+00  0.00000000e+00  4.78217958e+01 ...  1.00208670e+01\n",
       "     3.64464952e+01  0.00000000e+00]\n",
       "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
       "     0.00000000e+00  0.00000000e+00]\n",
       "   [ 4.60619302e+01  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
       "     0.00000000e+00  3.38160820e+01]]]\n",
       "\n",
       "\n",
       " [[[ 1.39714868e+01  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
       "     0.00000000e+00  4.73791600e+01]\n",
       "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  4.17827435e+01\n",
       "     0.00000000e+00  0.00000000e+00]\n",
       "   [ 0.00000000e+00  3.43353445e+01  0.00000000e+00 ...  3.70179612e+01\n",
       "     0.00000000e+00  3.02166808e+01]\n",
       "   ...\n",
       "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
       "     0.00000000e+00  0.00000000e+00]\n",
       "   [ 0.00000000e+00  3.76891467e+01  4.26287895e+01 ...  3.87531881e+01\n",
       "     0.00000000e+00  0.00000000e+00]\n",
       "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
       "     0.00000000e+00  5.29197041e+01]]\n",
       "\n",
       "  [[ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
       "     0.00000000e+00  1.47849887e+01]\n",
       "   [ 0.00000000e+00  3.31310346e+01  0.00000000e+00 ...  0.00000000e+00\n",
       "     0.00000000e+00  0.00000000e+00]\n",
       "   [ 0.00000000e+00  0.00000000e+00  4.33092510e+01 ...  0.00000000e+00\n",
       "     0.00000000e+00  0.00000000e+00]\n",
       "   ...\n",
       "   [ 0.00000000e+00  8.59877655e+01  0.00000000e+00 ...  1.02662114e+02\n",
       "     0.00000000e+00  0.00000000e+00]\n",
       "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
       "     0.00000000e+00  0.00000000e+00]\n",
       "   [ 0.00000000e+00  4.45388360e+01  0.00000000e+00 ...  4.98616109e+01\n",
       "     0.00000000e+00  9.11336832e+01]]\n",
       "\n",
       "  [[ 0.00000000e+00  6.56701744e+01  2.50179146e+01 ...  0.00000000e+00\n",
       "     0.00000000e+00  7.20042068e+01]\n",
       "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  5.17001119e+01\n",
       "     0.00000000e+00  0.00000000e+00]\n",
       "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
       "     0.00000000e+00  0.00000000e+00]\n",
       "   ...\n",
       "   [ 0.00000000e+00  1.23807777e+02  0.00000000e+00 ...  8.87377989e+01\n",
       "     0.00000000e+00  0.00000000e+00]\n",
       "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
       "     8.04469692e+01  0.00000000e+00]\n",
       "   [ 0.00000000e+00  4.02555421e+01  0.00000000e+00 ...  8.52808783e+00\n",
       "     0.00000000e+00  0.00000000e+00]]\n",
       "\n",
       "  ...\n",
       "\n",
       "  [[ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
       "     4.50811926e+01  0.00000000e+00]\n",
       "   [ 0.00000000e+00  1.00952234e+02  4.98769014e+01 ...  0.00000000e+00\n",
       "     0.00000000e+00  0.00000000e+00]\n",
       "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
       "     1.15999343e+02  0.00000000e+00]\n",
       "   ...\n",
       "   [ 0.00000000e+00  6.93147913e+01  0.00000000e+00 ... -8.62700464e+00\n",
       "     0.00000000e+00  0.00000000e+00]\n",
       "   [ 3.68386681e+01  0.00000000e+00  8.62343641e+01 ...  0.00000000e+00\n",
       "     0.00000000e+00  0.00000000e+00]\n",
       "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  4.65575555e+01\n",
       "     0.00000000e+00  1.09758145e+02]]\n",
       "\n",
       "  [[ 5.27426220e+01  0.00000000e+00  0.00000000e+00 ...  4.23305541e+01\n",
       "     0.00000000e+00  0.00000000e+00]\n",
       "   [ 0.00000000e+00  0.00000000e+00  4.99357248e+01 ...  0.00000000e+00\n",
       "     0.00000000e+00  2.00972395e+01]\n",
       "   [ 6.90427359e+01  0.00000000e+00  1.77495266e+02 ...  6.00413926e+01\n",
       "     1.08699684e+02  0.00000000e+00]\n",
       "   ...\n",
       "   [ 0.00000000e+00  0.00000000e+00  7.99108439e+00 ...  0.00000000e+00\n",
       "     5.33331212e+01  0.00000000e+00]\n",
       "   [ 3.79728514e+01  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
       "     9.02738998e+01  0.00000000e+00]\n",
       "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
       "     0.00000000e+00  0.00000000e+00]]\n",
       "\n",
       "  [[ 0.00000000e+00  6.70941278e+01  0.00000000e+00 ...  9.22333414e+01\n",
       "     0.00000000e+00  0.00000000e+00]\n",
       "   [ 0.00000000e+00  0.00000000e+00  7.08101462e+01 ...  0.00000000e+00\n",
       "     0.00000000e+00  2.66228694e+01]\n",
       "   [ 0.00000000e+00  6.10775349e+01  1.07360688e+02 ...  0.00000000e+00\n",
       "     9.67141436e+01  0.00000000e+00]\n",
       "   ...\n",
       "   [ 0.00000000e+00  0.00000000e+00  3.98393383e+01 ...  0.00000000e+00\n",
       "     5.63755930e+01  0.00000000e+00]\n",
       "   [ 8.00846999e+01  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
       "     0.00000000e+00  4.98154536e+01]\n",
       "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
       "     0.00000000e+00  0.00000000e+00]]]\n",
       "\n",
       "\n",
       " [[[ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ... -1.44655361e+00\n",
       "     0.00000000e+00  0.00000000e+00]\n",
       "   [ 0.00000000e+00  4.09644276e+01  0.00000000e+00 ...  0.00000000e+00\n",
       "     0.00000000e+00  4.38255500e+01]\n",
       "   [ 4.75997629e+01  0.00000000e+00  3.60797256e+01 ...  0.00000000e+00\n",
       "     0.00000000e+00  0.00000000e+00]\n",
       "   ...\n",
       "   [ 0.00000000e+00  2.70619336e+01  0.00000000e+00 ...  6.22542518e+01\n",
       "     0.00000000e+00  3.73448485e+01]\n",
       "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
       "     0.00000000e+00  3.79312482e+01]\n",
       "   [ 1.16960380e+01  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
       "     0.00000000e+00  0.00000000e+00]]\n",
       "\n",
       "  [[ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
       "     0.00000000e+00  0.00000000e+00]\n",
       "   [ 0.00000000e+00  6.16482275e+01  0.00000000e+00 ...  8.46744370e+01\n",
       "     0.00000000e+00  7.71556061e+01]\n",
       "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
       "     0.00000000e+00  9.07527122e+01]\n",
       "   ...\n",
       "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
       "     0.00000000e+00  5.90947229e+01]\n",
       "   [ 1.68750958e+01  0.00000000e+00  0.00000000e+00 ...  1.24131671e+01\n",
       "     0.00000000e+00  5.06997729e+01]\n",
       "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
       "     0.00000000e+00  0.00000000e+00]]\n",
       "\n",
       "  [[ 0.00000000e+00  3.14743417e+01  0.00000000e+00 ...  1.72604905e+01\n",
       "     6.80011771e+01  0.00000000e+00]\n",
       "   [ 0.00000000e+00  0.00000000e+00  8.22799941e+00 ...  0.00000000e+00\n",
       "     0.00000000e+00  0.00000000e+00]\n",
       "   [ 0.00000000e+00  7.88608708e+01  0.00000000e+00 ...  1.28620364e+01\n",
       "     0.00000000e+00  0.00000000e+00]\n",
       "   ...\n",
       "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
       "     0.00000000e+00  3.21934195e+01]\n",
       "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
       "     0.00000000e+00  0.00000000e+00]\n",
       "   [ 3.13111118e+01  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
       "     0.00000000e+00  5.72456166e+01]]\n",
       "\n",
       "  ...\n",
       "\n",
       "  [[ 0.00000000e+00  0.00000000e+00  9.06222840e+01 ...  0.00000000e+00\n",
       "     0.00000000e+00  1.91422367e+01]\n",
       "   [ 0.00000000e+00 -2.58523203e+01  0.00000000e+00 ...  3.18549625e+01\n",
       "     0.00000000e+00  0.00000000e+00]\n",
       "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ... -1.43239383e+01\n",
       "     0.00000000e+00  0.00000000e+00]\n",
       "   ...\n",
       "   [ 0.00000000e+00  5.31717410e+01  0.00000000e+00 ...  3.19716625e+01\n",
       "     0.00000000e+00  0.00000000e+00]\n",
       "   [ 0.00000000e+00  3.61504214e+01  0.00000000e+00 ...  0.00000000e+00\n",
       "     0.00000000e+00  5.28307931e+01]\n",
       "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
       "     0.00000000e+00  0.00000000e+00]]\n",
       "\n",
       "  [[ 0.00000000e+00  0.00000000e+00  1.02128952e+02 ...  0.00000000e+00\n",
       "     8.13626551e+01  0.00000000e+00]\n",
       "   [ 0.00000000e+00  3.94405746e+01  0.00000000e+00 ...  6.41975300e+01\n",
       "     0.00000000e+00  0.00000000e+00]\n",
       "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  2.91000491e+01\n",
       "     0.00000000e+00  6.98899203e+01]\n",
       "   ...\n",
       "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
       "     0.00000000e+00  0.00000000e+00]\n",
       "   [ 0.00000000e+00  2.88737197e+01  0.00000000e+00 ...  0.00000000e+00\n",
       "     0.00000000e+00  0.00000000e+00]\n",
       "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
       "     0.00000000e+00  6.25419472e+01]]\n",
       "\n",
       "  [[ 8.12381948e+00  0.00000000e+00  0.00000000e+00 ...  5.01495136e+00\n",
       "     0.00000000e+00  0.00000000e+00]\n",
       "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
       "     3.43646945e+01  0.00000000e+00]\n",
       "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  5.28731646e+01\n",
       "     0.00000000e+00  0.00000000e+00]\n",
       "   ...\n",
       "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
       "     0.00000000e+00  0.00000000e+00]\n",
       "   [ 0.00000000e+00  1.63149988e+01  0.00000000e+00 ...  2.38599168e+01\n",
       "     0.00000000e+00  0.00000000e+00]\n",
       "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
       "     2.94963243e+01  0.00000000e+00]]]], min_vals=<lazyrepeatarray data: -67.19430911126896 -> shape: (10, 32, 52, 52)>, max_vals=<lazyrepeatarray data: 216.86866103200174 -> shape: (10, 32, 52, 52)>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.layers[1].backward(pre_grad_dp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a452aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
