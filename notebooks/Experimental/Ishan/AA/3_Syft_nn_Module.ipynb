{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90222193-5eb7-4036-9a9a-b22847f94608",
   "metadata": {},
   "source": [
    "To Do:\n",
    "\n",
    "I need to create a Syft equivalent of nn.Module that lets you define a model if you initilize it with all the layers it will use, and define its forward pass using the activation functions.\n",
    "\n",
    "SyMPC seems to make a Module equivalent but for each type of layer- i.e. Conv2d is implemented as a Module, and (I think) their MPCTensor tracks all its gradients.\n",
    "\n",
    "Perhaps this will come down to modifying the loss function to take the DP Tensor as input, but I think if we use `publish` in order to do the conversion from DP Tensor -> array/tensor, we wouldn't have to do this modification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d485eeb8-ed85-4fc9-b3da-53b6d94bd5dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/Hagrid/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import syft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fc76e4b-e3d7-47de-b055-e89109b0fe17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "965bcdac-edf2-409d-965d-6414f64e7376",
   "metadata": {},
   "outputs": [],
   "source": [
    "from syft import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adfe944c-f7f2-45cc-a5e4-966178ba909f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import syft.core.tensor.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "59af5cb6-8b32-4ee1-af31-bc1ae5d04a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "from typing import Sequence\n",
    "from typing import Tuple, Optional\n",
    "from syft import PhiTensor\n",
    "\n",
    "class Conv2d(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channels:int, out_channels:int, kernel_size: Union[int, Sequence[int]], padding:int):\n",
    "        super(Conv2d, self).__init__()\n",
    "        \n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.padding = padding\n",
    "        self.func = torch.nn.Conv2d(in_channels=self.in_channels, out_channels=self.out_channels, kernel_size=self.kernel_size, padding=self.padding)\n",
    "        \n",
    "    def forward(self, x: PhiTensor):\n",
    "        return nn.Conv2d(\n",
    "            image=x, \n",
    "            in_channels=self.in_channels, \n",
    "            out_channels=self.out_channels, \n",
    "            kernel_size=self.kernel_size, \n",
    "            padding=self.padding\n",
    "        )\n",
    "    \n",
    "    def parameters(self):\n",
    "        return self.func.parameters()\n",
    "    \n",
    "    \n",
    "class BatchNorm2d(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, num_features, eps=1e-05, momentum=0.1, affine=True):\n",
    "        super(BatchNorm2d, self).__init__()\n",
    "        self.num_features = num_features\n",
    "        self.eps = eps\n",
    "        self.momentum = momentum\n",
    "        self.affine = affine\n",
    "        self.func = torch.nn.BatchNorm2d(num_features=self.num_features, \n",
    "            eps=self.eps, \n",
    "            momentum=self.momentum, \n",
    "            affine=self.affine\n",
    "        )\n",
    "        \n",
    "    def forward(self, x: PhiTensor):\n",
    "        return nn.BatchNorm2d(\n",
    "            image=x, \n",
    "            num_features=self.num_features, \n",
    "            eps=self.eps, \n",
    "            momentum=self.momentum, \n",
    "            affine=self.affine\n",
    "        )\n",
    "    \n",
    "    def parameters(self):\n",
    "        return self.func.parameters()\n",
    "\n",
    "class MaxPool2d(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, kernel_size: Union[int, Tuple[int, int]],\n",
    "                 stride: Optional[Union[int, Tuple[int, int]]] = None,\n",
    "                 padding: Union[int, Tuple[int, int]] = 0,\n",
    "                 dilation: int = 1,\n",
    "                 return_indices: bool = False,\n",
    "                 ceil_mode: bool = False,\n",
    "                ):\n",
    "        super(MaxPool2d, self).__init__()\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.dilation = dilation\n",
    "        self.return_indices = return_indices\n",
    "        self.ceil_mode = ceil_mode\n",
    "        self.func = torch.nn.MaxPool2d(kernel_size=self.kernel_size, \n",
    "            stride=self.stride, \n",
    "            padding=self.padding, \n",
    "            return_indices=self.return_indices, \n",
    "            ceil_mode=self.ceil_mode)\n",
    "        \n",
    "    def forward(self, x: PhiTensor):\n",
    "        return nn.MaxPool2d(\n",
    "            image=x, \n",
    "            kernel_size=self.kernel_size, \n",
    "            stride=self.stride, \n",
    "            padding=self.padding, \n",
    "            return_indices=self.return_indices, \n",
    "            ceil_mode=self.ceil_mode\n",
    "        )\n",
    "    \n",
    "    def parameters(self):\n",
    "        return self.func.parameters()\n",
    "    \n",
    "    \n",
    "class AvgPool2d(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        kernel_size: Union[int, Tuple[int, int]], \n",
    "        stride: Optional[Union[int, Tuple[int, int]]] = None, \n",
    "        padding: Union[int, Tuple[int, int]] = 0\n",
    "    ):\n",
    "        super(AvgPool2d, self).__init__()\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.func = torch.nn.AvgPool2d(kernel_size=self.kernel_size, stride=self.stride, padding=self.padding)\n",
    "        \n",
    "    def forward(self, x: PhiTensor):\n",
    "        return nn.AvgPool2d(image=x, kernel_size=self.kernel_size, stride=self.stride, padding=self.padding)\n",
    "    \n",
    "    def parameters(self):\n",
    "        return self.func.parameters()\n",
    "\n",
    "    \n",
    "class Linear(torch.nn.Module):\n",
    "    def __init__(self, in_features: int, out_features: int, bias: bool = True):\n",
    "        super(Linear, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.bias = bias\n",
    "        self.func = torch.nn.Linear(in_features=self.in_features, out_features=self.out_features, bias=self.bias)\n",
    "    \n",
    "    def forward(self, x: PhiTensor):\n",
    "        return nn.Linear(image=x, in_features=self.in_features, out_features=self.out_features, bias=self.bias)\n",
    "    \n",
    "    def parameters(self):\n",
    "        return self.func.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f779d70b-f285-4f1e-98a6-96f2c52fe4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=2)\n",
    "        self.conv2 = Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=2)\n",
    "        self.conv3 = Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=2)\n",
    "        self.conv4 = Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=2)\n",
    "        self.conv5 = Conv2d(in_channels=256, out_channels=512, kernel_size=3, padding=2)\n",
    "        self.bn1 = BatchNorm2d(32)\n",
    "        self.bn2 = BatchNorm2d(64)\n",
    "        self.bn3 = BatchNorm2d(128)\n",
    "        self.bn4 = BatchNorm2d(256)\n",
    "        self.bn5 = BatchNorm2d(512)\n",
    "        self.pool = MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.avg = AvgPool2d(3)\n",
    "        self.fc = Linear(512 * 1 * 1, 2)\n",
    "        \n",
    "    def forward(self, x: PhiTensor):\n",
    "        # First layer of CNN - running 1 at a time to debug and see if any individual componenet is failing\n",
    "#         x = self.conv1(x)\n",
    "#         x = self.bn1(x)\n",
    "#         x = F.leaky_relu(x)\n",
    "#         x = self.pool(x)\n",
    "        \n",
    "        # Subsequent layers\n",
    "        x = self.pool(F.leaky_relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(F.leaky_relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool(F.leaky_relu(self.bn3(self.conv3(x))))\n",
    "        x = self.pool(F.leaky_relu(self.bn4(self.conv4(x))))\n",
    "        x = self.pool(F.leaky_relu(self.bn5(self.conv5(x))))\n",
    "        x = self.avg(x)\n",
    "        x = x.view(-1, 512 * 1 * 1) # !!!\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "82bfdf71-1b51-43be-a0b3-5b66aaee7c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model = ConvNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7c989e27-74ac-4a9c-9f64-2e27fcc42559",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvNet(\n",
       "  (conv1): Conv2d(\n",
       "    (func): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
       "  )\n",
       "  (conv2): Conv2d(\n",
       "    (func): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
       "  )\n",
       "  (conv3): Conv2d(\n",
       "    (func): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
       "  )\n",
       "  (conv4): Conv2d(\n",
       "    (func): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
       "  )\n",
       "  (conv5): Conv2d(\n",
       "    (func): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
       "  )\n",
       "  (bn1): BatchNorm2d(\n",
       "    (func): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (bn2): BatchNorm2d(\n",
       "    (func): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (bn3): BatchNorm2d(\n",
       "    (func): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (bn4): BatchNorm2d(\n",
       "    (func): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (bn5): BatchNorm2d(\n",
       "    (func): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (pool): MaxPool2d(\n",
       "    (func): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avg): AvgPool2d(\n",
       "    (func): AvgPool2d(kernel_size=3, stride=3, padding=0)\n",
       "  )\n",
       "  (fc): Linear(\n",
       "    (func): Linear(in_features=512, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f0a39762-66c6-4965-8bce-0402fa99cd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from syft import PhiTensor\n",
    "import numpy as np\n",
    "\n",
    "N = 10\n",
    "C_in = 3\n",
    "H_in = 50\n",
    "W_in = 50\n",
    "\n",
    "input_shape = (N, C_in, H_in, W_in)\n",
    "x = PhiTensor(child=np.random.randint(low=0, high=255, size=input_shape),\n",
    "              data_subjects=np.zeros(input_shape),\n",
    "              min_vals=0,\n",
    "              max_vals=255\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "350b2a31-5583-4ad4-8133-47a011839084",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = cnn_model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f73108e-4e30-4c38-88fa-fffa623c3887",
   "metadata": {},
   "source": [
    "Alright so the results are terrible, but since it's random information I guess that's fine..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e20de325-c638-4d16-b0b5-5adba5f927c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lazyrepeatarray data: [[0.02670823 0.01745377]\n",
       " [0.02670823 0.01745377]\n",
       " [0.02670823 0.01745377]\n",
       " [0.02670823 0.01745377]\n",
       " [0.02670823 0.01745377]\n",
       " [0.02670823 0.01745377]\n",
       " [0.02670823 0.01745377]\n",
       " [0.02670823 0.01745377]\n",
       " [0.02670823 0.01745377]\n",
       " [0.02670823 0.01745377]] -> shape: (10, 2)>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.min_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3c346d0e-a086-4169-a6c3-fee99c43eca9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lazyrepeatarray data: [[-6.609332  -2.1688619]\n",
       " [-6.609332  -2.1688619]\n",
       " [-6.609332  -2.1688619]\n",
       " [-6.609332  -2.1688619]\n",
       " [-6.609332  -2.1688619]\n",
       " [-6.609332  -2.1688619]\n",
       " [-6.609332  -2.1688619]\n",
       " [-6.609332  -2.1688619]\n",
       " [-6.609332  -2.1688619]\n",
       " [-6.609332  -2.1688619]] -> shape: (10, 2)>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.max_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "78ab54b8-f903-4f4f-b331-90dc6d232b9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -87105.8359375 ,  -29459.04882812],\n",
       "       [ -92849.15625   ,  -28882.64648438],\n",
       "       [ -92739.2421875 ,  -27127.921875  ],\n",
       "       [ -96031.2578125 ,  -25348.609375  ],\n",
       "       [ -83334.6171875 ,  -28440.17773438],\n",
       "       [ -79925.5859375 ,  -25812.9375    ],\n",
       "       [-103203.09375   ,  -28766.57226562],\n",
       "       [ -88098.015625  ,  -28495.328125  ],\n",
       "       [ -94136.6328125 ,  -24086.13671875],\n",
       "       [ -92708.3203125 ,  -26001.5078125 ]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.child.decode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a4e052a5-28b5-464a-9e06-d0876f9937b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "classes = 2\n",
    "batch_size = 128\n",
    "alpha = 0.002\n",
    "device = 'cpu'\n",
    "\n",
    "model = ConvNet().to(device)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adamax(model.parameters(), lr=alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f5603dff-49e7-463b-99b6-a7d54d23decc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_phi_tensor():\n",
    "    return PhiTensor(\n",
    "        child=np.random.randint(0, 255, (50, 50, 3)),\n",
    "        data_subjects=np.ones((50, 50, 3)) * np.random.choice([0, 1]),\n",
    "        min_vals=0,\n",
    "        max_vals=255\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "70688784-1023-48eb-b4b1-6ad066387c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_train = [(create_phi_tensor(), torch.Tensor(np.random.choice([0, 1]))) for i in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2ebd8588-7ef7-4f63-80bf-6beb268b7bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "cc938670-3d8e-4fac-9f0e-1ead3deb0fcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new Ledger\n"
     ]
    }
   ],
   "source": [
    "from syft.core.adp.data_subject_ledger import DataSubjectLedger\n",
    "from syft.core.adp.ledger_store import DictLedgerStore\n",
    "from typing import Any\n",
    "\n",
    "\n",
    "ledger_store = DictLedgerStore()\n",
    "user_key = b\"1231\"\n",
    "ledger = DataSubjectLedger.get_or_create(store=ledger_store, user_key=user_key)\n",
    "\n",
    "def get_budget_for_user(*args: Any, **kwargs: Any) -> float:\n",
    "    return 999999\n",
    "\n",
    "def deduct_epsilon_for_user(*args: Any, **kwargs: Any) -> bool:\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "22aed3a8-ab54-491f-8267-04fdd323bcc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PUBLISHING TO GAMMA:\n",
      "FixedPrecisionTensor(child=[[1639069184 1318499456]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 59.20it/s]\u001b[A\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epsilon spend  [706263.4037034 706263.4037034]\n",
      "Highest possible spend  706263.403703397\n",
      "Attemping to spend epsilon: 706263.403703397. Try: 0\n",
      "got user budget 999999.0 epsilon_spent 706263.403703397\n",
      "We have filtered all the input tensors. Now to compute the result:\n",
      "Filtered inputs  [array([[1639069184, 1318499456]])]\n",
      "original output (before noise: [[[1639069184 1318499456]]]\n",
      "noise:  [[[20.32182046  7.32174347]]]\n",
      "Noise after FPT [[[1331810  479837]]]\n",
      "got output <class 'numpy.ndarray'> int64\n",
      "Final FPT Values FixedPrecisionTensor(child=[1640400994 1318979293])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "size mismatch (got input: [2], target: [1])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [95]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(images)\n\u001b[1;32m      9\u001b[0m published_output \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mpublish(\n\u001b[1;32m     10\u001b[0m     get_budget_for_user\u001b[38;5;241m=\u001b[39mget_budget_for_user, \n\u001b[1;32m     11\u001b[0m     deduct_epsilon_for_user\u001b[38;5;241m=\u001b[39mdeduct_epsilon_for_user, \n\u001b[1;32m     12\u001b[0m     ledger\u001b[38;5;241m=\u001b[39mledger, \n\u001b[1;32m     13\u001b[0m     sigma\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m\n\u001b[1;32m     14\u001b[0m )\n\u001b[0;32m---> 15\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpublished_output\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Backward and optimize\u001b[39;00m\n\u001b[1;32m     18\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/Hagrid/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/anaconda3/envs/Hagrid/lib/python3.8/site-packages/torch/nn/modules/loss.py:1163\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1162\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m-> 1163\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1164\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1165\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/Hagrid/lib/python3.8/site-packages/torch/nn/functional.py:2996\u001b[0m, in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   2994\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2995\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 2996\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: size mismatch (got input: [2], target: [1])"
     ]
    }
   ],
   "source": [
    "total_step = len(loader_train)\n",
    "for epoch in range(epochs):\n",
    "    for i, (images, labels) in tqdm(enumerate(loader_train)):        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        published_output = outputs.publish(\n",
    "            get_budget_for_user=get_budget_for_user, \n",
    "            deduct_epsilon_for_user=deduct_epsilon_for_user, \n",
    "            ledger=ledger, \n",
    "            sigma=10\n",
    "        )\n",
    "        loss = criterion(torch.Tensor(published_output.decode()), labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                   .format(epoch+1, epochs, i+1, total_step, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667a3384-7313-4ccc-b921-047f5fa798c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Hagrid",
   "language": "python",
   "name": "hagrid"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
