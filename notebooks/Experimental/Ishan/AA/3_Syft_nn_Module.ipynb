{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90222193-5eb7-4036-9a9a-b22847f94608",
   "metadata": {},
   "source": [
    "To Do:\n",
    "\n",
    "I need to create a Syft equivalent of nn.Module that lets you define a model if you initilize it with all the layers it will use, and define its forward pass using the activation functions.\n",
    "\n",
    "SyMPC seems to make a Module equivalent but for each type of layer- i.e. Conv2d is implemented as a Module, and (I think) their MPCTensor tracks all its gradients.\n",
    "\n",
    "Perhaps this will come down to modifying the loss function to take the DP Tensor as input, but I think if we use `publish` in order to do the conversion from DP Tensor -> array/tensor, we wouldn't have to do this modification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d485eeb8-ed85-4fc9-b3da-53b6d94bd5dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/Hagrid/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import syft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fc76e4b-e3d7-47de-b055-e89109b0fe17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "965bcdac-edf2-409d-965d-6414f64e7376",
   "metadata": {},
   "outputs": [],
   "source": [
    "from syft import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adfe944c-f7f2-45cc-a5e4-966178ba909f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import syft.core.tensor.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59af5cb6-8b32-4ee1-af31-bc1ae5d04a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "from typing import Sequence\n",
    "from typing import Tuple, Optional\n",
    "from syft import PhiTensor\n",
    "\n",
    "class Conv2d(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channels:int, out_channels:int, kernel_size: Union[int, Sequence[int]], padding:int):\n",
    "        super(Conv2d, self).__init__()\n",
    "        \n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.padding = padding\n",
    "        \n",
    "    def forward(self, x: PhiTensor):\n",
    "        return nn.Conv2d(\n",
    "            image=x, \n",
    "            in_channels=self.in_channels, \n",
    "            out_channels=self.out_channels, \n",
    "            kernel_size=self.kernel_size, \n",
    "            padding=self.padding\n",
    "        )\n",
    "    \n",
    "    \n",
    "class BatchNorm2d(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, num_features, eps=1e-05, momentum=0.1, affine=True):\n",
    "        super(BatchNorm2d, self).__init__()\n",
    "        self.num_features = num_features\n",
    "        self.eps = eps\n",
    "        self.momentum = momentum\n",
    "        self.affine = affine\n",
    "        \n",
    "    def forward(self, x: PhiTensor):\n",
    "        return nn.BatchNorm2d(\n",
    "            image=x, \n",
    "            num_features=self.num_features, \n",
    "            eps=self.eps, \n",
    "            momentum=self.momentum, \n",
    "            affine=self.affine\n",
    "        )\n",
    "\n",
    "class MaxPool2d(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, kernel_size: Union[int, Tuple[int, int]],\n",
    "                 stride: Optional[Union[int, Tuple[int, int]]] = None,\n",
    "                 padding: Union[int, Tuple[int, int]] = 0,\n",
    "                 dilation: int = 1,\n",
    "                 return_indices: bool = False,\n",
    "                 ceil_mode: bool = False,\n",
    "                ):\n",
    "        super(MaxPool2d, self).__init__()\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.dilation = dilation\n",
    "        self.return_indices = return_indices\n",
    "        self.ceil_mode = ceil_mode\n",
    "        \n",
    "    def forward(self, x: PhiTensor):\n",
    "        return nn.MaxPool2d(\n",
    "            image=x, \n",
    "            kernel_size=self.kernel_size, \n",
    "            stride=self.stride, \n",
    "            padding=self.padding, \n",
    "            return_indices=self.return_indices, \n",
    "            ceil_mode=self.ceil_mode\n",
    "        )\n",
    "    \n",
    "class AvgPool2d(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        kernel_size: Union[int, Tuple[int, int]], \n",
    "        stride: Optional[Union[int, Tuple[int, int]]] = None, \n",
    "        padding: Union[int, Tuple[int, int]] = 0\n",
    "    ):\n",
    "        super(AvgPool2d, self).__init__()\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        \n",
    "    def forward(self, x: PhiTensor):\n",
    "        return nn.AvgPool2d(image=x, kernel_size=self.kernel_size, stride=self.stride, padding=self.padding)\n",
    "    \n",
    "class Linear(torch.nn.Module):\n",
    "    def __init__(self, in_features: int, out_features: int, bias: bool = True):\n",
    "        super(Linear, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.bias = bias\n",
    "    \n",
    "    def forward(self, x: PhiTensor):\n",
    "        return nn.Linear(image=x, in_features=self.in_features, out_features=self.out_features, bias=self.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f779d70b-f285-4f1e-98a6-96f2c52fe4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=2)\n",
    "        self.conv2 = Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=2)\n",
    "        self.conv3 = Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=2)\n",
    "        self.conv4 = Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=2)\n",
    "        self.conv5 = Conv2d(in_channels=256, out_channels=512, kernel_size=3, padding=2)\n",
    "        self.bn1 = BatchNorm2d(32)\n",
    "        self.bn2 = BatchNorm2d(64)\n",
    "        self.bn3 = BatchNorm2d(128)\n",
    "        self.bn4 = BatchNorm2d(256)\n",
    "        self.bn5 = BatchNorm2d(512)\n",
    "        self.pool = MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.avg = AvgPool2d(3)\n",
    "        self.fc = Linear(512 * 1 * 1, 2)\n",
    "        \n",
    "    def forward(self, x: PhiTensor):\n",
    "        # First layer of CNN - running 1 at a time to debug and see if any individual componenet is failing\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = F.leaky_relu(x)\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        # Subsequent layers\n",
    "        x = self.pool(F.leaky_relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool(F.leaky_relu(self.bn3(self.conv3(x))))\n",
    "        x = self.pool(F.leaky_relu(self.bn4(self.conv4(x))))\n",
    "        x = self.pool(F.leaky_relu(self.bn5(self.conv5(x))))\n",
    "        x = self.avg(x)\n",
    "        x = x.view(-1, 512 * 1 * 1) # !!!\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82bfdf71-1b51-43be-a0b3-5b66aaee7c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model = ConvNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c989e27-74ac-4a9c-9f64-2e27fcc42559",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvNet(\n",
       "  (conv1): Conv2d()\n",
       "  (conv2): Conv2d()\n",
       "  (conv3): Conv2d()\n",
       "  (conv4): Conv2d()\n",
       "  (conv5): Conv2d()\n",
       "  (bn1): BatchNorm2d()\n",
       "  (bn2): BatchNorm2d()\n",
       "  (bn3): BatchNorm2d()\n",
       "  (bn4): BatchNorm2d()\n",
       "  (bn5): BatchNorm2d()\n",
       "  (pool): MaxPool2d()\n",
       "  (avg): AvgPool2d()\n",
       "  (fc): Linear()\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f0a39762-66c6-4965-8bce-0402fa99cd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from syft import PhiTensor\n",
    "import numpy as np\n",
    "\n",
    "N = 10\n",
    "C_in = 3\n",
    "H_in = 50\n",
    "W_in = 50\n",
    "\n",
    "input_shape = (N, C_in, H_in, W_in)\n",
    "x = PhiTensor(child=np.random.randint(low=0, high=255, size=input_shape),\n",
    "              data_subjects=np.zeros(input_shape),\n",
    "              min_vals=0,\n",
    "              max_vals=255\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "350b2a31-5583-4ad4-8133-47a011839084",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = cnn_model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e20de325-c638-4d16-b0b5-5adba5f927c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lazyrepeatarray data: [[0.05091886 0.01344587]\n",
       " [0.05091885 0.01344587]\n",
       " [0.05091886 0.01344587]\n",
       " [0.05091885 0.01344587]\n",
       " [0.05091886 0.01344587]\n",
       " [0.05091885 0.01344587]\n",
       " [0.05091886 0.01344587]\n",
       " [0.05091885 0.01344587]\n",
       " [0.05091886 0.01344587]\n",
       " [0.05091885 0.01344587]] -> shape: (10, 2)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.min_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3c346d0e-a086-4169-a6c3-fee99c43eca9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lazyrepeatarray data: [[-1.0008134 -1.4859134]\n",
       " [-1.0008131 -1.4859128]\n",
       " [-1.0008134 -1.4859134]\n",
       " [-1.0008131 -1.4859128]\n",
       " [-1.0008134 -1.4859134]\n",
       " [-1.0008131 -1.4859128]\n",
       " [-1.0008134 -1.4859134]\n",
       " [-1.0008131 -1.4859128]\n",
       " [-1.0008134 -1.4859134]\n",
       " [-1.0008131 -1.4859128]] -> shape: (10, 2)>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.max_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "78ab54b8-f903-4f4f-b331-90dc6d232b9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -9138.91601562, -32360.22460938],\n",
       "       [ -2589.08642578, -29962.58398438],\n",
       "       [ -4006.70947266, -27737.55664062],\n",
       "       [  -669.7623291 , -28234.01367188],\n",
       "       [   549.5892334 , -31208.20117188],\n",
       "       [ -6860.75634766, -26845.73632812],\n",
       "       [  5393.24658203, -29911.54492188],\n",
       "       [  1014.99353027, -34367.3203125 ],\n",
       "       [   647.54040527, -25028.42382812],\n",
       "       [  1125.26403809, -30544.484375  ]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.child.decode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e821016b-e211-472a-96b3-85d590b3a26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_layer = Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f667e7a-bf1c-41b8-b867-e69b5c1a9024",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 3, 50, 50)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.child.decode().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f1073c53-3166-412b-baef-2ef1ed8b8d05",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 32, 52, 52)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_layer(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e260d4-20c6-4b6e-ac8a-90879a3be232",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "f6f1f6da-2443-46c4-aeee-4b63a7aed2d2",
   "metadata": {},
   "source": [
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=2)\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=2)\n",
    "        self.conv4 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=2)\n",
    "        self.conv5 = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, padding=2)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.bn4 = nn.BatchNorm2d(256)\n",
    "        self.bn5 = nn.BatchNorm2d(512)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.avg = nn.AvgPool2d(7)\n",
    "        self.fc = nn.Linear(512 * 1 * 1, 2) # !!!    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b41efcec-bcac-4a10-819c-877c4a05da70",
   "metadata": {},
   "outputs": [],
   "source": [
    "bn = torch.nn.BatchNorm2d(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "718d0c4a-d255-4d3b-8e8b-217bc791aac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = bn(torch.ones(10, 3, 5, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7f06722c-420a-4809-bb3f-ccd4898419b3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 3, 5, 5])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6ca88ea4-f7d6-406a-b2bd-2f897c3757f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9c61e1c5-ca06-4c53-99d2-ff088390b6fa",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected 1 arguments, got 0 instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [18]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: expected 1 arguments, got 0 instead"
     ]
    }
   ],
   "source": [
    "output.grad_fn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07864a8-2974-4dc2-bfbd-25abdf9e7db9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Hagrid",
   "language": "python",
   "name": "hagrid"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
