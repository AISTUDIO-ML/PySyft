{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90222193-5eb7-4036-9a9a-b22847f94608",
   "metadata": {},
   "source": [
    "To Do:\n",
    "\n",
    "I need to create a Syft equivalent of nn.Module that lets you define a model if you initilize it with all the layers it will use, and define its forward pass using the activation functions.\n",
    "\n",
    "SyMPC seems to make a Module equivalent but for each type of layer- i.e. Conv2d is implemented as a Module, and (I think) their MPCTensor tracks all its gradients.\n",
    "\n",
    "Perhaps this will come down to modifying the loss function to take the DP Tensor as input, but I think if we use `publish` in order to do the conversion from DP Tensor -> array/tensor, we wouldn't have to do this modification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d485eeb8-ed85-4fc9-b3da-53b6d94bd5dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/Hagrid/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import syft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fc76e4b-e3d7-47de-b055-e89109b0fe17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "965bcdac-edf2-409d-965d-6414f64e7376",
   "metadata": {},
   "outputs": [],
   "source": [
    "from syft import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adfe944c-f7f2-45cc-a5e4-966178ba909f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import syft.core.tensor.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "59af5cb6-8b32-4ee1-af31-bc1ae5d04a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "from typing import Sequence\n",
    "from typing import Tuple, Optional\n",
    "from syft import PhiTensor\n",
    "\n",
    "class Conv2d(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channels:int, out_channels:int, kernel_size: Union[int, Sequence[int]], padding:int):\n",
    "        super(Conv2d, self).__init__()\n",
    "        \n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.padding = padding\n",
    "        \n",
    "    def forward(self, x: PhiTensor):\n",
    "        return nn.Conv2d(\n",
    "            image=x, \n",
    "            in_channels=self.in_channels, \n",
    "            out_channels=self.out_channels, \n",
    "            kernel_size=self.kernel_size, \n",
    "            padding=self.padding\n",
    "        )\n",
    "    \n",
    "    \n",
    "class BatchNorm2d(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, num_features, eps=1e-05, momentum=0.1, affine=True):\n",
    "        super(BatchNorm2d, self).__init__()\n",
    "        self.num_features = num_features\n",
    "        self.eps = eps\n",
    "        self.momentum = momentum\n",
    "        self.affine = affine\n",
    "        \n",
    "    def forward(self, x: PhiTensor):\n",
    "        return nn.BatchNorm2d(\n",
    "            image=x, \n",
    "            num_features=self.num_features, \n",
    "            eps=self.eps, \n",
    "            momentum=self.momentum, \n",
    "            affine=self.affine\n",
    "        )\n",
    "\n",
    "class MaxPool2d(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, kernel_size: Union[int, Tuple[int, int]],\n",
    "                 stride: Optional[Union[int, Tuple[int, int]]] = None,\n",
    "                 padding: Union[int, Tuple[int, int]] = 0,\n",
    "                 dilation: int = 1,\n",
    "                 return_indices: bool = False,\n",
    "                 ceil_mode: bool = False,\n",
    "                ):\n",
    "        super(MaxPool2d, self).__init__()\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.dilation = dilation\n",
    "        self.return_indices = return_indices\n",
    "        self.ceil_mode = ceil_mode\n",
    "        \n",
    "    def forward(self, x: PhiTensor):\n",
    "        return nn.MaxPool2d(\n",
    "            image=x, \n",
    "            kernel_size=self.kernel_size, \n",
    "            stride=self.stride, \n",
    "            padding=self.padding, \n",
    "            return_indices=self.return_indices, \n",
    "            ceil_mode=self.ceil_mode\n",
    "        )\n",
    "    \n",
    "class AvgPool2d(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        kernel_size: Union[int, Tuple[int, int]], \n",
    "        stride: Optional[Union[int, Tuple[int, int]]] = None, \n",
    "        padding: Union[int, Tuple[int, int]] = 0\n",
    "    ):\n",
    "        super(AvgPool2d, self).__init__()\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        \n",
    "    def forward(self, x: PhiTensor):\n",
    "        return nn.AvgPool2d(image=x, kernel_size=self.kernel_size, stride=self.stride, padding=self.padding)\n",
    "    \n",
    "class Linear(torch.nn.Module):\n",
    "    def __init__(self, in_features: int, out_features: int, bias: bool = True):\n",
    "        super(Linear, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.bias = bias\n",
    "    \n",
    "    def forward(self, x: PhiTensor):\n",
    "        return nn.Linear(image=x, in_features=self.in_features, out_features=self.out_features, bias=self.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f779d70b-f285-4f1e-98a6-96f2c52fe4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=2)\n",
    "        self.conv2 = Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=2)\n",
    "        self.conv3 = Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=2)\n",
    "        self.conv4 = Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=2)\n",
    "        self.conv5 = Conv2d(in_channels=256, out_channels=512, kernel_size=3, padding=2)\n",
    "        self.bn1 = BatchNorm2d(32)\n",
    "        self.bn2 = BatchNorm2d(64)\n",
    "        self.bn3 = BatchNorm2d(128)\n",
    "        self.bn4 = BatchNorm2d(256)\n",
    "        self.bn5 = BatchNorm2d(512)\n",
    "        self.pool = MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.avg = AvgPool2d(7)\n",
    "        self.fc = Linear(512 * 1 * 1, 2)\n",
    "        \n",
    "    def forward(self, x: PhiTensor):\n",
    "        # First layer of CNN - running 1 at a time to debug and see if any individual componenet is failing\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = F.leaky_relu(x)\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        # Subsequent layers\n",
    "        x = self.pool(F.leaky_relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool(F.leaky_relu(self.bn3(self.conv3(x))))\n",
    "        x = self.pool(F.leaky_relu(self.bn4(self.conv4(x))))\n",
    "        x = self.pool(F.leaky_relu(self.bn5(self.conv5(x))))\n",
    "        x = self.avg(x)\n",
    "        x = x.view(-1, 512 * 1 * 1) # !!!\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "82bfdf71-1b51-43be-a0b3-5b66aaee7c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model = ConvNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7c989e27-74ac-4a9c-9f64-2e27fcc42559",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvNet(\n",
       "  (conv1): Conv2d()\n",
       "  (conv2): Conv2d()\n",
       "  (conv3): Conv2d()\n",
       "  (conv4): Conv2d()\n",
       "  (conv5): Conv2d()\n",
       "  (bn1): BatchNorm2d()\n",
       "  (bn2): BatchNorm2d()\n",
       "  (bn3): BatchNorm2d()\n",
       "  (bn4): BatchNorm2d()\n",
       "  (bn5): BatchNorm2d()\n",
       "  (pool): MaxPool2d()\n",
       "  (avg): AvgPool2d()\n",
       "  (fc): Linear()\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f0a39762-66c6-4965-8bce-0402fa99cd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from syft import PhiTensor\n",
    "import numpy as np\n",
    "\n",
    "N = 10\n",
    "C_in = 3\n",
    "H_in = 50\n",
    "W_in = 50\n",
    "\n",
    "input_shape = (N, C_in, H_in, W_in)\n",
    "x = PhiTensor(child=np.random.randint(low=0, high=255, size=input_shape),\n",
    "              data_subjects=np.zeros(input_shape),\n",
    "              min_vals=0,\n",
    "              max_vals=255\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "350b2a31-5583-4ad4-8133-47a011839084",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Given input size: (512x3x3). Calculated output size: (512x0x0). Output size is too small",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [31]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcnn_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/Hagrid/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[0;32mIn [27]\u001b[0m, in \u001b[0;36mConvNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     29\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool(F\u001b[38;5;241m.\u001b[39mleaky_relu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn4(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv4(x))))\n\u001b[1;32m     30\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool(F\u001b[38;5;241m.\u001b[39mleaky_relu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn5(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv5(x))))\n\u001b[0;32m---> 31\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mavg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m512\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;66;03m# !!!\u001b[39;00m\n\u001b[1;32m     33\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc(x)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/Hagrid/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[0;32mIn [26]\u001b[0m, in \u001b[0;36mAvgPool2d.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: PhiTensor):\n\u001b[0;32m---> 84\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAvgPool2d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkernel_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/PycharmProjects/PySyft/packages/syft/src/syft/core/tensor/nn/pooling.py:47\u001b[0m, in \u001b[0;36mAvgPool2d\u001b[0;34m(image, kernel_size, stride, padding)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mAvgPool2d\u001b[39m(\n\u001b[1;32m     41\u001b[0m     image: PhiTensor,\n\u001b[1;32m     42\u001b[0m     kernel_size: Union[\u001b[38;5;28mint\u001b[39m, Tuple[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mint\u001b[39m]],\n\u001b[1;32m     43\u001b[0m     stride: Optional[Union[\u001b[38;5;28mint\u001b[39m, Tuple[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mint\u001b[39m]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     44\u001b[0m     padding: Union[\u001b[38;5;28mint\u001b[39m, Tuple[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mint\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m     45\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m PhiTensor:\n\u001b[1;32m     46\u001b[0m     avg_pool \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mAvgPool2d(kernel_size, stride, padding)\n\u001b[0;32m---> 47\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mavg_pool\u001b[49m\u001b[43m(\u001b[49m\u001b[43mTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchild\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m PhiTensor(\n\u001b[1;32m     49\u001b[0m         child\u001b[38;5;241m=\u001b[39mdata,\n\u001b[1;32m     50\u001b[0m         data_subjects\u001b[38;5;241m=\u001b[39mDSL(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     55\u001b[0m         max_vals\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mones_like(data) \u001b[38;5;241m*\u001b[39m image\u001b[38;5;241m.\u001b[39mmax_vals\u001b[38;5;241m.\u001b[39mdata,\n\u001b[1;32m     56\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/Hagrid/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/anaconda3/envs/Hagrid/lib/python3.8/site-packages/torch/nn/modules/pooling.py:622\u001b[0m, in \u001b[0;36mAvgPool2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    621\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 622\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mavg_pool2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkernel_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    623\u001b[0m \u001b[43m                        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mceil_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcount_include_pad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdivisor_override\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given input size: (512x3x3). Calculated output size: (512x0x0). Output size is too small"
     ]
    }
   ],
   "source": [
    "cnn_model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e821016b-e211-472a-96b3-85d590b3a26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_layer = Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f667e7a-bf1c-41b8-b867-e69b5c1a9024",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x.child.decode().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1073c53-3166-412b-baef-2ef1ed8b8d05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "conv_layer(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e260d4-20c6-4b6e-ac8a-90879a3be232",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "f6f1f6da-2443-46c4-aeee-4b63a7aed2d2",
   "metadata": {},
   "source": [
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=2)\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=2)\n",
    "        self.conv4 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=2)\n",
    "        self.conv5 = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, padding=2)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.bn4 = nn.BatchNorm2d(256)\n",
    "        self.bn5 = nn.BatchNorm2d(512)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.avg = nn.AvgPool2d(7)\n",
    "        self.fc = nn.Linear(512 * 1 * 1, 2) # !!!    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41efcec-bcac-4a10-819c-877c4a05da70",
   "metadata": {},
   "outputs": [],
   "source": [
    "bn = torch.nn.BatchNorm2d(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718d0c4a-d255-4d3b-8e8b-217bc791aac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = bn(torch.ones(10, 3, 5, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f06722c-420a-4809-bb3f-ccd4898419b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca88ea4-f7d6-406a-b2bd-2f897c3757f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c61e1c5-ca06-4c53-99d2-ff088390b6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "output.grad_fn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07864a8-2974-4dc2-bfbd-25abdf9e7db9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Hagrid",
   "language": "python",
   "name": "hagrid"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
