{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fb44f8-999c-43af-a5c6-651a5ad1633f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "\n",
    "import syft as sy\n",
    "from utils import *\n",
    "from syft import NewDataSubject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a893263-a9d2-44ea-a90f-2918ff95beb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "MY_DATASET_URL = \"https://raw.githubusercontent.com/OpenMined/datasets/main/BreastCancerDataset/subsets/BreastCancerDataset-02ec48b840824b1ea3e1f5d11c45314b.pkl\"\n",
    "dataset = download_dataset(MY_DATASET_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a796742b-33f0-4627-a3ba-839d9f8e386b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4571eb4b-e537-4a54-b516-7539618cc48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell\n",
    "train, val, test = split_and_preprocess_dataset(data=dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7f8544-f498-4fbd-a5d7-b00a1aed273f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell\n",
    "data_subjects_image = np.ones(train[\"images\"].shape).astype(object)\n",
    "for i,patient in enumerate(train[\"patient_ids\"]):\n",
    "    data_subjects_image[i] = NewDataSubject([str(patient)])\n",
    "\n",
    "data_subjects_labels = np.ones(train[\"labels\"].shape).astype(object)\n",
    "for i,patient in enumerate(train[\"patient_ids\"]):\n",
    "    data_subjects_labels[i] = NewDataSubject([str(patient)])\n",
    "\n",
    "    \n",
    "train_image_data = sy.Tensor(train[\"images\"]).annotated_with_dp_metadata(\n",
    "    min_val=0, max_val=255, data_subjects=data_subjects_image\n",
    ")\n",
    "train_label_data = sy.Tensor(train[\"labels\"]).annotated_with_dp_metadata(\n",
    "    min_val=0, max_val=1, data_subjects=data_subjects_labels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a041dc9-5e3d-4a63-a23f-b8788c08c5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from syft import PhiTensor\n",
    "# def correct_dsl(input_tensor: PhiTensor):\n",
    "#     \"\"\" Corrects for the new DSL shape requirements \n",
    "#     e.g. (1915,) -> (1915, 3, 50, 50) \n",
    "#     \"\"\"\n",
    "#     output_dsi = np.ones((input_tensor.shape[0], *input_tensor.shape[1:]))\n",
    "#     print(output_dsi.shape)\n",
    "    \n",
    "#     for index, val in enumerate(input_tensor.data_subjects.data_subjects_indexed[0]):\n",
    "#         output_dsi[index] *= val\n",
    "    \n",
    "#     input_tensor.data_subjects.data_subjects_indexed = output_dsi\n",
    "#     # print(output_dsi.shape)\n",
    "#     # print(output_dsi[0])\n",
    "#     # output_dsi = np.ones(input_tensor.shape)  # b/c PhiTensor\n",
    "#     # for i in range(input_tensor.shape[0]):\n",
    "#     #      output_dsi[i] *= input_tensor.data_subjects.data_subjects_indexed[i]\n",
    "#     # input_tensor.data_subjects.data_subjects_indexed = output_dsi\n",
    "\n",
    "# correct_dsl(train_image_data.child)  \n",
    "# # .shape, train_image_data.child.data_subjects.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b70c6a-36d4-4964-bb90-ccb7ad63a2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_subjects = DataSubjectList.from_series(val[\"patient_ids\"])\n",
    "# val_image_data = sy.Tensor(val[\"images\"]).annotated_with_dp_metadata(\n",
    "#     min_val=0, max_val=255, data_subjects=data_subjects\n",
    "# )\n",
    "# val_label_data = sy.Tensor(val[\"labels\"]).annotated_with_dp_metadata(\n",
    "#     min_val=0, max_val=1, data_subjects=data_subjects\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bf70cc-ffbd-4806-aafe-16034fc3d1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_subjects = DataSubjectList.from_series(test[\"patient_ids\"])\n",
    "# test_image_data = sy.Tensor(test[\"images\"]).annotated_with_dp_metadata(\n",
    "#     min_val=0, max_val=255, data_subjects=data_subjects\n",
    "# )\n",
    "# test_label_data = sy.Tensor(test[\"labels\"]).annotated_with_dp_metadata(\n",
    "#     min_val=0, max_val=1, data_subjects=data_subjects\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7073645b-f617-434f-99a6-2d8f6490c9d7",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6091c8d8-e769-404b-a389-396cbc8a60b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from syft import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8d0b9b-8ec6-4e0c-83bb-f5a204ac7fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = train_image_data.public_shape\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67bd6211-bab4-4f52-a29c-66c69d4d095a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_label_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef1b4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = train_image_data[:2].child.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a24bb79-7212-4728-8f3e-3a41df6bc558",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Model()\n",
    "\n",
    "# Layer 1\n",
    "model.add(nn.Convolution(nb_filter=32, filter_size=3, padding=2, input_shape=input_shape))  # May need to change input_shape to reflect we are passing in 2 images and not 2000+\n",
    "model.add(nn.BatchNorm(activation=nn.leaky_ReLU()))\n",
    "model.add(nn.MaxPool(pool_size=2, stride=2))\n",
    "\n",
    "# # Layer 2\n",
    "model.add(nn.Convolution(nb_filter=64, filter_size=3, padding=2))\n",
    "model.add(nn.BatchNorm(activation=nn.leaky_ReLU()))\n",
    "model.add(nn.MaxPool(pool_size=2, stride=2))\n",
    "\n",
    "# Layer 3\n",
    "model.add(nn.Convolution(nb_filter=128, filter_size=3, padding=2))\n",
    "model.add(nn.BatchNorm(activation=nn.leaky_ReLU()))\n",
    "model.add(nn.MaxPool(pool_size=2, stride=2))\n",
    "\n",
    "# Layer 4\n",
    "model.add(nn.Convolution(nb_filter=256, filter_size=3, padding=2))\n",
    "model.add(nn.BatchNorm(activation=nn.leaky_ReLU()))\n",
    "model.add(nn.MaxPool(pool_size=2, stride=2))\n",
    "\n",
    "# Layer 5\n",
    "# model.add(nn.Convolution(nb_filter=512, filter_size=3, padding=2))\n",
    "# model.add(nn.BatchNorm(activation=nn.leaky_ReLU()))\n",
    "# model.add(nn.MaxPool(pool_size=2, stride=2))\n",
    "\n",
    "# Layer 6\n",
    "model.add(nn.AvgPool(5))\n",
    "\n",
    "# # Layer 7\n",
    "model.add(nn.Flatten())\n",
    "\n",
    "# # Layer 8\n",
    "model.add(nn.Linear(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65dad679-54fc-4904-9641-f1728e67ffe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474d58fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for layer in model.layers[::-1]:\n",
    "#     print(f\"Layer: {layer}\")\n",
    "#     print(f\"InputShape: {layer.input_shape}, OutputShape: {layer.out_shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e571bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "out = train_image_data[:2].child\n",
    "total_time = 0.0\n",
    "for layer in model.layers:\n",
    "    start  = time.time()\n",
    "    print(\"Layer Name: \", layer)\n",
    "    out = layer.forward(out)\n",
    "    end = time.time()\n",
    "    print(f\"Time for Layer: {layer}\" , end-start)\n",
    "    total_time += (end-start)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed259d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total time to execute forward pass\n",
    "total_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22cd8f71-1083-4ad1-92c0-e455c732e511",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "69faf43a-0a83-41c3-a06c-d8a75d2d7c9f",
   "metadata": {},
   "source": [
    "## Backwards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e18627-5fa6-4685-a085-a8ee288218df",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = train_label_data[:2].child"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2dd7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true.child, out.child"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3513de2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "out.data_subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b457a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_loss = model.loss.forward(out, y_true)\n",
    "print(\"Loss on the batch\", curr_loss.child)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882162ef-564f-4ac2-a6b7-1fdaf8cad2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "next_grad = model.loss.backward(out, y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724d3f4f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for layer in model.layers[::-1]:\n",
    "#     print(f\"Layer: {layer}\")\n",
    "#     print(f\"InputShape: {layer.input_shape}, OutputShape: {layer.out_shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1839a320",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "total_time_backward = 0.0\n",
    "for layer in model.layers[::-1]:\n",
    "    print(layer)\n",
    "    start = time.time()\n",
    "    next_grad = layer.backward(next_grad)\n",
    "    end = time.time()\n",
    "    print(f\"Time to execute backward for {layer}: {end-start}\")\n",
    "    print(f\"Child Shape: {next_grad.shape}, DS Shape: {next_grad.data_subjects.shape}\")\n",
    "    \n",
    "    total_time_backward += end-start\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd198f75-414d-496e-b331-cc1df4061902",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_time_backward"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2455a4",
   "metadata": {},
   "source": [
    "#### Update Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d607679",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.optimizer.update(model.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3ad649-6d76-436b-b943-28a8a20e54ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
