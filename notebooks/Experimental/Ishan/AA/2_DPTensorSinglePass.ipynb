{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9dfb1f3f-4a02-4075-8150-fb2a3c299823",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from syft.core.tensor.autodp.phi_tensor import PhiTensor\n",
    "from syft.core.tensor.autodp.gamma_tensor import GammaTensor\n",
    "from syft.core.tensor.fixed_precision_tensor import FixedPrecisionTensor as FPT\n",
    "from syft.core.adp.data_subject_list import DataSubjectList\n",
    "from syft.core.tensor.lazy_repeat_array import lazyrepeatarray as lra"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c0d17f-fa56-4752-8907-f5a7d0fd938f",
   "metadata": {},
   "source": [
    "## Torch Dataset equivalent"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6a748ba2-8e67-45c9-b7b2-b415a20a983e",
   "metadata": {},
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, df_data,transform=None):\n",
    "        super().__init__()\n",
    "        self.df = df_data.values\n",
    "        self.transform = transform\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    def __getitem__(self, index):\n",
    "        img_path,label = self.df[index]\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.resize(image, (50,50))\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "        \n",
    "trans_train = transforms.Compose([transforms.ToPILImage(),\n",
    "                                  transforms.Pad(64, padding_mode='reflect'),\n",
    "                                  transforms.RandomHorizontalFlip(), \n",
    "                                  transforms.RandomVerticalFlip(),\n",
    "                                  transforms.RandomRotation(20), \n",
    "                                  transforms.ToTensor(),\n",
    "                                  transforms.Normalize(mean=[0.5, 0.5, 0.5],std=[0.5, 0.5, 0.5])])\n",
    "\n",
    "trans_valid = transforms.Compose([transforms.ToPILImage(),\n",
    "                                  transforms.Pad(64, padding_mode='reflect'),\n",
    "                                  transforms.ToTensor(),\n",
    "                                  transforms.Normalize(mean=[0.5, 0.5, 0.5],std=[0.5, 0.5, 0.5])])\n",
    "\n",
    "dataset_train = MyDataset(df_data=train, transform=trans_train)\n",
    "dataset_valid = MyDataset(df_data=val,transform=trans_valid)\n",
    "\n",
    "loader_train = DataLoader(dataset = dataset_train, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "loader_valid = DataLoader(dataset = dataset_valid, batch_size=batch_size//2, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9282abb3-fbbb-494e-92f0-cbd94025e3f6",
   "metadata": {},
   "source": [
    "We have to implement:\n",
    "- padding -> DONE!\n",
    "- random horizontal flip -> DONE!\n",
    "- random vertical flip -> DONE!\n",
    "- random rotation -> Done but not confident about resultant LRA, or what to do with 0 values. -> Might try training the model without random rotations to see how testing accuracy suffers.\n",
    "- normalize -> DONE!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d774fc0d-3f87-4847-8ce9-8278f7f13d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = PhiTensor(child=np.random.random((5,5)),data_subjects=np.ones((5,5)), min_vals=0, max_vals=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "595a2adb-f737-4320-94a2-77bd8ce329a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PhiTensor(child=FixedPrecisionTensor(child=[[35364 22056 14629 24277 31407]\n",
       " [11692 45525  3860 64992 41154]\n",
       " [ 7451 15905  7127 48296 34807]\n",
       " [14745 61587 49996 41563 54958]\n",
       " [63873 51892 39111 37338 32073]]), min_vals=<lazyrepeatarray data: 0 -> shape: (5, 5)>, max_vals=<lazyrepeatarray data: 1 -> shape: (5, 5)>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0339b54c-3e28-40e0-a672-e4e24725842e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PhiTensor(child=FixedPrecisionTensor(child=[[45525 11692 45525  3860 64992 41154 64992]\n",
       " [22056 35364 22056 14629 24277 31407 24277]\n",
       " [45525 11692 45525  3860 64992 41154 64992]\n",
       " [15905  7451 15905  7127 48296 34807 48296]\n",
       " [61587 14745 61587 49996 41563 54958 41563]\n",
       " [51892 63873 51892 39111 37338 32073 37338]\n",
       " [61587 14745 61587 49996 41563 54958 41563]]), min_vals=<lazyrepeatarray data: 0 -> shape: (7, 7)>, max_vals=<lazyrepeatarray data: 1 -> shape: (7, 7)>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.pad(width=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00870aa9-37e8-408a-a5ed-b25cc50a55af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PhiTensor(child=FixedPrecisionTensor(child=[[35364 22056 14629 24277 31407]\n",
       " [11692 45525  3860 64992 41154]\n",
       " [ 7451 15905  7127 48296 34807]\n",
       " [14745 61587 49996 41563 54958]\n",
       " [63873 51892 39111 37338 32073]]), min_vals=<lazyrepeatarray data: 0 -> shape: (5, 5)>, max_vals=<lazyrepeatarray data: 1 -> shape: (5, 5)>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.random_horizontal_flip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d677ebe-88ee-4d24-9c75-db92ab7d23b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PhiTensor(child=FixedPrecisionTensor(child=[[63873 51892 39111 37338 32073]\n",
       " [14745 61587 49996 41563 54958]\n",
       " [ 7451 15905  7127 48296 34807]\n",
       " [11692 45525  3860 64992 41154]\n",
       " [35364 22056 14629 24277 31407]]), min_vals=<lazyrepeatarray data: 0 -> shape: (5, 5)>, max_vals=<lazyrepeatarray data: 1 -> shape: (5, 5)>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.random_vertical_flip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "492273fe-2df1-427d-ac8f-de1186542f47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PhiTensor(child=FixedPrecisionTensor(child=[[    0     0     0     0     0     0]\n",
       " [    0 15518 38283 12735 27378     0]\n",
       " [    0 11753 11166 19484 64343     0]\n",
       " [    0 40891 42166 35037 41630     0]\n",
       " [    0 53974 46353 39784 53730     0]\n",
       " [    0     0     0     0     0     0]]), min_vals=<lazyrepeatarray data: 0 -> shape: (5, 5)>, max_vals=<lazyrepeatarray data: 1 -> shape: (5, 5)>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.random_rotation(degrees=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "11b96ab3-cbad-4dd0-8255-2b79a289ba48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PhiTensor(child=FixedPrecisionTensor(child=[[  5192 -21424 -36278 -16982  -2722]\n",
       " [-42152  25514 -57816  64448  16772]\n",
       " [-50634 -33726 -51282  31056   4078]\n",
       " [-36046  57638  34456  17590  44380]\n",
       " [ 62210  38248  12686   9140  -1390]]), min_vals=<lazyrepeatarray data: -1.0 -> shape: ()>, max_vals=<lazyrepeatarray data: 1.0 -> shape: ()>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.normalize(mean=0.5, std=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b52c8c4-5c9a-496c-8043-c98c46ee515a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.53961182, 0.33654785, 0.22322083, 0.37043762, 0.47923279],\n",
       "       [0.17840576, 0.69465637, 0.05889893, 0.99169922, 0.62796021],\n",
       "       [0.11369324, 0.24269104, 0.10874939, 0.73693848, 0.53111267],\n",
       "       [0.22499084, 0.93974304, 0.76287842, 0.63420105, 0.83859253],\n",
       "       [0.97462463, 0.79180908, 0.5967865 , 0.56973267, 0.48939514]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.child.decode()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd668c0c-9421-406e-8b99-278d9c604b2b",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93df76a4-6fef-4e21-a349-d4bd39098c9a",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "\n",
    "\n",
    "To Do:\n",
    "- Implement the layers needed for a ConvNet for DP Tensors:\n",
    "    - Conv layer\n",
    "    - BatchNorm2D\n",
    "    - LeakyReLU\n",
    "    - AvgPool2d\n",
    "    - Linear\n",
    "- Do 1 forward pass with these layers\n",
    "- Do 1 backprop with these layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e3552c7c-4e61-453d-ac72-e03bb8519579",
   "metadata": {},
   "outputs": [],
   "source": [
    "from syft.core.tensor.nn.conv_layers import Conv2d\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "45320db0-0e08-4e0b-949d-e7a483636c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Update image path below\n",
    "img_path = \"/home/shubham/PySyft/notebooks/medical-federated-learning-program/network-operators/archive/10253/0/10253_idx5_x1051_y651_class0.png\"\n",
    "img = cv2.imread(img_path)\n",
    "img = cv2.resize(img, (50, 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7400b14b-0a5f-4ffa-93dd-d848a1c1af16",
   "metadata": {},
   "outputs": [],
   "source": [
    "dp_tensor = PhiTensor(child=img, data_subjects=[0]  , min_vals=0, max_vals=255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e4b248c6-3890-4cee-97d9-bba052501218",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = Conv2d(dp_tensor, in_channels=3, out_channels=32, kernel_size=3, padding=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3888e6d3-0385-4945-94a0-22fc613d50bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from syft.core.tensor.nn.batch_norm import BatchNorm2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4322be65-971f-4424-ae0f-2698221d8821",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 50, 3)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1c4a3dce-a94c-464d-8e4d-107171a18461",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 50, 50])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.BatchNorm2d(3)(torch.Tensor(img.reshape(1, *img.shape[::-1]))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cfd8ade0-ef72-4f20-9bfc-ea3903f9e781",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3, 50, 50)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dpt2 = dp_tensor.copy()\n",
    "dpt2.child = dp_tensor.child.reshape(1, *dp_tensor.shape[::-1])\n",
    "BatchNorm2d(dpt2, 3).child.decode().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ab3e83c7-f012-4bda-af0b-d3882e0cbbc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.0870, -1.5196,  1.0985,  ...,  1.2473,  0.1762, -1.1923],\n",
       "          [ 1.0985,  0.5927, -0.8353,  ..., -1.7874, -0.3891, -0.2998],\n",
       "          [-1.8469, -0.3593,  0.2952,  ...,  0.0572, -1.7279, -0.0023],\n",
       "          ...,\n",
       "          [-1.4304,  0.1167,  0.6523,  ...,  0.1762, -1.2816, -0.1808],\n",
       "          [ 0.5332, -0.8651,  1.1580,  ...,  1.2770,  0.7415, -0.4188],\n",
       "          [ 1.2473,  0.8308, -0.2105,  ...,  0.5035,  1.3960,  0.4440]],\n",
       "\n",
       "         [[-0.8683,  0.8349,  0.5916,  ..., -0.0471, -1.5982,  0.1354],\n",
       "          [ 0.2875, -1.1724,  0.6524,  ...,  1.4128,  0.0746, -1.5982],\n",
       "          [ 0.9870,  0.4091, -1.0508,  ..., -1.2028,  1.1086,  0.5308],\n",
       "          ...,\n",
       "          [ 1.2303, -0.0471, -1.6286,  ..., -0.2904,  1.2303, -0.3208],\n",
       "          [-1.7199, -0.3208, -0.0775,  ...,  0.1354, -1.3549,  1.0478],\n",
       "          [ 0.4395, -0.8683,  1.2607,  ...,  0.9566, -0.0775, -1.8415]],\n",
       "\n",
       "         [[ 0.9140,  0.1708, -1.1032,  ...,  0.3300,  1.0201,  1.1528],\n",
       "          [ 0.5424,  1.2059,  0.5689,  ...,  0.3035, -0.9970,  0.8078],\n",
       "          [ 0.4893, -0.6785,  0.8609,  ..., -0.3335, -0.2008, -1.5810],\n",
       "          ...,\n",
       "          [ 0.2504, -1.1032,  0.9140,  ...,  0.2504, -0.3070, -1.8198],\n",
       "          [-0.4928, -0.5724, -2.1383,  ..., -1.2359,  0.8078,  0.3300],\n",
       "          [-1.0767,  0.8078,  0.1973,  ...,  1.2590,  0.6751,  1.2590]]]],\n",
       "       grad_fn=<NativeBatchNormBackward>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.BatchNorm2d(3)(torch.Tensor(img.reshape(1, *img.shape[::-1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e5a2faf9-e299-4d75-bf68-8f7bf699a293",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 0.08695984, -1.51960754,  1.09851074, ...,  1.24726868,\n",
       "           0.17622375, -1.19233704],\n",
       "         [ 1.09851074,  0.59274292, -0.83532715, ..., -1.78736877,\n",
       "          -0.38905334, -0.29978943],\n",
       "         [-1.84687805, -0.35929871,  0.29522705, ...,  0.0572052 ,\n",
       "          -1.72787476, -0.00227356],\n",
       "         ...,\n",
       "         [-1.43035889,  0.11671448,  0.65223694, ...,  0.17622375,\n",
       "          -1.28160095, -0.18078613],\n",
       "         [ 0.53323364, -0.86508179,  1.15802002, ...,  1.27702332,\n",
       "           0.74150085, -0.41879272],\n",
       "         [ 1.24726868,  0.83074951, -0.21054077, ...,  0.503479  ,\n",
       "           1.39602661,  0.44398499]],\n",
       "\n",
       "        [[-0.86825562,  0.8348999 ,  0.59159851, ..., -0.04708862,\n",
       "          -1.59819031,  0.13537598],\n",
       "         [ 0.28744507, -1.1723938 ,  0.65242004, ...,  1.4127655 ,\n",
       "           0.07455444, -1.59819031],\n",
       "         [ 0.98696899,  0.40910339, -1.05075073, ..., -1.20281982,\n",
       "           1.10862732,  0.53076172],\n",
       "         ...,\n",
       "         [ 1.23028564, -0.04708862, -1.62861633, ..., -0.29039001,\n",
       "           1.23028564, -0.32081604],\n",
       "         [-1.71984863, -0.32081604, -0.07749939, ...,  0.13537598,\n",
       "          -1.35488892,  1.04780579],\n",
       "         [ 0.43952942, -0.86825562,  1.26069641, ...,  0.95655823,\n",
       "          -0.07749939, -1.84150696]],\n",
       "\n",
       "        [[ 0.91395569,  0.17077637, -1.10321045, ...,  0.33003235,\n",
       "           1.02012634,  1.15283203],\n",
       "         [ 0.54237366,  1.20591736,  0.56890869, ...,  0.30349731,\n",
       "          -0.99703979,  0.80778503],\n",
       "         [ 0.48928833, -0.67854309,  0.86087036, ..., -0.33349609,\n",
       "          -0.20079041, -1.58096313],\n",
       "         ...,\n",
       "         [ 0.25041199, -1.10321045,  0.91395569, ...,  0.25041199,\n",
       "          -0.3069458 , -1.81983948],\n",
       "         [-0.49275208, -0.57237244, -2.13833618, ..., -1.23591614,\n",
       "           0.80778503,  0.33003235],\n",
       "         [-1.07666016,  0.80778503,  0.19732666, ...,  1.25898743,\n",
       "           0.67507935,  1.25898743]]]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BatchNorm2d(dpt2, 3).child.decode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f6751012-f1f9-4be6-8816-2bac342fdb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from syft import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5c6932b6-06b7-4822-8c15-7b5092db5ac7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 16, 1)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.AvgPool2d(dp_tensor, 3).child.decode().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "89b08cc5-c74c-41d7-b9e1-0cf09494d46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import AvgPool2d, MaxPool2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c47fc51a-1f74-4e99-9a6a-fa283d221a2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 16, 1])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import Tensor\n",
    "AvgPool2d(3)(Tensor(dp_tensor.child.decode())).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "962a1e87-a1af-49c6-be01-ad282a5d5f1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[183.],\n",
       "        [191.],\n",
       "        [194.],\n",
       "        ...,\n",
       "        [205.],\n",
       "        [195.],\n",
       "        [190.]],\n",
       "\n",
       "       [[207.],\n",
       "        [199.],\n",
       "        [199.],\n",
       "        ...,\n",
       "        [193.],\n",
       "        [200.],\n",
       "        [196.]],\n",
       "\n",
       "       [[196.],\n",
       "        [190.],\n",
       "        [201.],\n",
       "        ...,\n",
       "        [188.],\n",
       "        [228.],\n",
       "        [183.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[188.],\n",
       "        [196.],\n",
       "        [213.],\n",
       "        ...,\n",
       "        [202.],\n",
       "        [199.],\n",
       "        [227.]],\n",
       "\n",
       "       [[195.],\n",
       "        [195.],\n",
       "        [192.],\n",
       "        ...,\n",
       "        [196.],\n",
       "        [198.],\n",
       "        [195.]],\n",
       "\n",
       "       [[201.],\n",
       "        [181.],\n",
       "        [198.],\n",
       "        ...,\n",
       "        [188.],\n",
       "        [169.],\n",
       "        [230.]]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.MaxPool2d(dp_tensor, kernel_size=2, stride=2).child.decode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "df375499-7cf0-49eb-bb41-cbdbe2dc0711",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[183.],\n",
       "         [191.],\n",
       "         [194.],\n",
       "         ...,\n",
       "         [205.],\n",
       "         [195.],\n",
       "         [190.]],\n",
       "\n",
       "        [[207.],\n",
       "         [199.],\n",
       "         [199.],\n",
       "         ...,\n",
       "         [193.],\n",
       "         [200.],\n",
       "         [196.]],\n",
       "\n",
       "        [[196.],\n",
       "         [190.],\n",
       "         [201.],\n",
       "         ...,\n",
       "         [188.],\n",
       "         [228.],\n",
       "         [183.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[188.],\n",
       "         [196.],\n",
       "         [213.],\n",
       "         ...,\n",
       "         [202.],\n",
       "         [199.],\n",
       "         [227.]],\n",
       "\n",
       "        [[195.],\n",
       "         [195.],\n",
       "         [192.],\n",
       "         ...,\n",
       "         [196.],\n",
       "         [198.],\n",
       "         [195.]],\n",
       "\n",
       "        [[201.],\n",
       "         [181.],\n",
       "         [198.],\n",
       "         ...,\n",
       "         [188.],\n",
       "         [169.],\n",
       "         [230.]]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MaxPool2d(kernel_size=2, stride=2)(Tensor(dp_tensor.child.decode()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f63a42e0-fc4d-4123-be2c-69dbaf07113c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 8.6960e-02, -1.5196e-02,  1.0985e+00,  ...,  1.2473e+00,\n",
       "            1.7622e-01, -1.1923e-02],\n",
       "          [ 1.0985e+00,  5.9274e-01, -8.3533e-03,  ..., -1.7874e-02,\n",
       "           -3.8905e-03, -2.9979e-03],\n",
       "          [-1.8469e-02, -3.5930e-03,  2.9523e-01,  ...,  5.7205e-02,\n",
       "           -1.7279e-02, -2.2736e-05],\n",
       "          ...,\n",
       "          [-1.4304e-02,  1.1671e-01,  6.5224e-01,  ...,  1.7622e-01,\n",
       "           -1.2816e-02, -1.8079e-03],\n",
       "          [ 5.3323e-01, -8.6508e-03,  1.1580e+00,  ...,  1.2770e+00,\n",
       "            7.4150e-01, -4.1879e-03],\n",
       "          [ 1.2473e+00,  8.3075e-01, -2.1054e-03,  ...,  5.0348e-01,\n",
       "            1.3960e+00,  4.4398e-01]],\n",
       "\n",
       "         [[-8.6826e-03,  8.3490e-01,  5.9160e-01,  ..., -4.7089e-04,\n",
       "           -1.5982e-02,  1.3538e-01],\n",
       "          [ 2.8745e-01, -1.1724e-02,  6.5242e-01,  ...,  1.4128e+00,\n",
       "            7.4554e-02, -1.5982e-02],\n",
       "          [ 9.8697e-01,  4.0910e-01, -1.0508e-02,  ..., -1.2028e-02,\n",
       "            1.1086e+00,  5.3076e-01],\n",
       "          ...,\n",
       "          [ 1.2303e+00, -4.7089e-04, -1.6286e-02,  ..., -2.9039e-03,\n",
       "            1.2303e+00, -3.2082e-03],\n",
       "          [-1.7198e-02, -3.2082e-03, -7.7499e-04,  ...,  1.3538e-01,\n",
       "           -1.3549e-02,  1.0478e+00],\n",
       "          [ 4.3953e-01, -8.6826e-03,  1.2607e+00,  ...,  9.5656e-01,\n",
       "           -7.7499e-04, -1.8415e-02]],\n",
       "\n",
       "         [[ 9.1396e-01,  1.7078e-01, -1.1032e-02,  ...,  3.3003e-01,\n",
       "            1.0201e+00,  1.1528e+00],\n",
       "          [ 5.4237e-01,  1.2059e+00,  5.6891e-01,  ...,  3.0350e-01,\n",
       "           -9.9704e-03,  8.0779e-01],\n",
       "          [ 4.8929e-01, -6.7854e-03,  8.6087e-01,  ..., -3.3350e-03,\n",
       "           -2.0079e-03, -1.5810e-02],\n",
       "          ...,\n",
       "          [ 2.5041e-01, -1.1032e-02,  9.1396e-01,  ...,  2.5041e-01,\n",
       "           -3.0695e-03, -1.8198e-02],\n",
       "          [-4.9275e-03, -5.7237e-03, -2.1383e-02,  ..., -1.2359e-02,\n",
       "            8.0779e-01,  3.3003e-01],\n",
       "          [-1.0767e-02,  8.0779e-01,  1.9733e-01,  ...,  1.2590e+00,\n",
       "            6.7508e-01,  1.2590e+00]]]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.functional.leaky_relu(Tensor(BatchNorm2d(dpt2, 3).child.decode()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "334af087",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 8.69598389e-02, -1.51824951e-02,  1.09851074e+00, ...,\n",
       "           1.24726868e+00,  1.76223755e-01, -1.19171143e-02],\n",
       "         [ 1.09851074e+00,  5.92742920e-01, -8.34655762e-03, ...,\n",
       "          -1.78680420e-02, -3.87573242e-03, -2.99072266e-03],\n",
       "         [-1.84631348e-02, -3.58581543e-03,  2.95227051e-01, ...,\n",
       "           5.72052002e-02, -1.72729492e-02, -1.52587891e-05],\n",
       "         ...,\n",
       "         [-1.42974854e-02,  1.16714478e-01,  6.52236938e-01, ...,\n",
       "           1.76223755e-01, -1.28021240e-02, -1.80053711e-03],\n",
       "         [ 5.33233643e-01, -8.63647461e-03,  1.15802002e+00, ...,\n",
       "           1.27702332e+00,  7.41500854e-01, -4.18090820e-03],\n",
       "         [ 1.24726868e+00,  8.30749512e-01, -2.09045410e-03, ...,\n",
       "           5.03479004e-01,  1.39602661e+00,  4.43984985e-01]],\n",
       "\n",
       "        [[-8.68225098e-03,  8.34899902e-01,  5.91598511e-01, ...,\n",
       "          -4.57763672e-04, -1.59759521e-02,  1.35375977e-01],\n",
       "         [ 2.87445068e-01, -1.17187500e-02,  6.52420044e-01, ...,\n",
       "           1.41276550e+00,  7.45544434e-02, -1.59759521e-02],\n",
       "         [ 9.86968994e-01,  4.09103394e-01, -1.04980469e-02, ...,\n",
       "          -1.20239258e-02,  1.10862732e+00,  5.30761719e-01],\n",
       "         ...,\n",
       "         [ 1.23028564e+00, -4.57763672e-04, -1.62811279e-02, ...,\n",
       "          -2.89916992e-03,  1.23028564e+00, -3.20434570e-03],\n",
       "         [-1.71966553e-02, -3.20434570e-03, -7.62939453e-04, ...,\n",
       "           1.35375977e-01, -1.35345459e-02,  1.04780579e+00],\n",
       "         [ 4.39529419e-01, -8.68225098e-03,  1.26069641e+00, ...,\n",
       "           9.56558228e-01, -7.62939453e-04, -1.84020996e-02]],\n",
       "\n",
       "        [[ 9.13955688e-01,  1.70776367e-01, -1.10321045e-02, ...,\n",
       "           3.30032349e-01,  1.02012634e+00,  1.15283203e+00],\n",
       "         [ 5.42373657e-01,  1.20591736e+00,  5.68908691e-01, ...,\n",
       "           3.03497314e-01, -9.96398926e-03,  8.07785034e-01],\n",
       "         [ 4.89288330e-01, -6.77490234e-03,  8.60870361e-01, ...,\n",
       "          -3.32641602e-03, -1.99890137e-03, -1.58081055e-02],\n",
       "         ...,\n",
       "         [ 2.50411987e-01, -1.10321045e-02,  9.13955688e-01, ...,\n",
       "           2.50411987e-01, -3.06701660e-03, -1.81884766e-02],\n",
       "         [-4.91333008e-03, -5.72204590e-03, -2.13775635e-02, ...,\n",
       "          -1.23443604e-02,  8.07785034e-01,  3.30032349e-01],\n",
       "         [-1.07574463e-02,  8.07785034e-01,  1.97326660e-01, ...,\n",
       "           1.25898743e+00,  6.75079346e-01,  1.25898743e+00]]]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.functional.leaky_ReLU(BatchNorm2d(dpt2, 3)).decode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0eb441e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9946047",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
