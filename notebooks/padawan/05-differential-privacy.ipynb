{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "976a0663-06ec-4b40-8acd-90287760544a",
   "metadata": {},
   "source": [
    "# Differential Privacy\n",
    "\n",
    "> \"You can't stop change any more than you can stop the sun from setting.\" ~ Shmi Skywalker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a37a71-cd1f-401a-a8fe-8d4da49e06b4",
   "metadata": {},
   "source": [
    "In this lesson we'll be learning about **Differential Privacy.** This is divided into two sections.\n",
    "\n",
    "Section 1 will focus on **Intuition**: \n",
    "* Intuition\n",
    "    * What is differential privacy (DP)?\n",
    "    * How does DP work?\n",
    "        * How does adding noise protect privacy?\n",
    "        * How much noise do we add?\n",
    "        * What is the tradeoff?\n",
    "    * What is the privacy budget?\n",
    "        * Connection between privacy budget and risk\n",
    "    * What is epsilon?\n",
    "    \n",
    "Section 2 will focus on DP in **our codebase.**\n",
    "* DP in PySyft\n",
    "    * How DP in PySyft is different than DP elsewhere\n",
    "        * Adversarial\n",
    "        * Individual\n",
    "        * Automatic\n",
    "    * Differential Privacy Tensors\n",
    "        * PhiTensors\n",
    "        * GammaTensors\n",
    "        * Helper Classes:\n",
    "            * LazyRepeatArrays\n",
    "            * DataSubjectArrays\n",
    "    * Ledgers and Privacy Budget Accounting\n",
    "    * Sigma and noise addition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e3f897-ad31-4c82-92b6-63d2e269b191",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ba4cd2-7d00-41d3-bcab-565fcbd12223",
   "metadata": {},
   "source": [
    "## Motivation \n",
    "\n",
    "In a previous lesson, we had discussed how difficult it is to protect people's privacy when working with or releasing data. We discussed the Netflix prize, where participants were de-anonymized with shocking accuracy. We mentioned problems caused by Data Linkages, and talked about the copy problem.\n",
    "\n",
    "Differential Privacy is one of the Privacy Enhancing Technologies (PETs) that we had discussed in a previous session. Like other PETs, it tries to solve some of these problems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc857d5e-6bc8-4e3a-9b3e-848bfd54a9f0",
   "metadata": {},
   "source": [
    "We'll unpack this in more detail. But first, let's quickly standardize some terminology.\n",
    "\n",
    "<img src=\"imgs/ds_terminology.png\">\n",
    "\n",
    "This is the standard \"journey\" of data in data science:\n",
    "* Raw data is collected from lots of people (like you and I, called **data subjects**). \n",
    "* This raw data is collected and often cleaned/preprocessed by **data owners**,\n",
    "* The data owners then pass on these datasets to their data scientists, who then test their algorithms or workflows on the data to draw useful conclusions, or build products."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bfdd78b-de87-4fd6-88ee-0f652e131a61",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9ee453-dcc7-477d-8207-61c10a3986b5",
   "metadata": {},
   "source": [
    "## Section 1: Intuition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556472e1-5be0-4528-93d8-48742b25e836",
   "metadata": {},
   "source": [
    "Put simply, differential privacy is a mathematical guarantee that the output of an algorithm is similar when data belonging to one person is removed.\n",
    "\n",
    "<img src=\"imgs/dp_definition.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc9f50e-7f85-4c06-841e-a09cc0f2aa2e",
   "metadata": {},
   "source": [
    "Because the outputs are so similar, adding even the tiniest amount of noise can completely hide the effect of the person's data.\n",
    "\n",
    "<img src=\"imgs/dp_similarity.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d85b0b-fdc8-41a8-9934-12234c0c9829",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "This means the Data Scientist still gets a reasonable and accurate answer (~25.7) but won't clue into the effect of your data.\n",
    "\n",
    "So in a nutshell, DP makes it so that the data scientist doesn't work with just the datasets- they work with datasets plus some noise that serves to protect the privacy of the data subjects.\n",
    "\n",
    "<img src=\"imgs/dp_ds.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5e688f-01e5-4ce0-a341-20876fea7dea",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Thus far, we've seen how differential privacy (DP) leads to the addition of a small amount of noise to protect the privacy of someone's data.\n",
    "\n",
    "A reasonable next question to ask is ***how much noise do we add?***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abefdbd0-a3ce-4c57-97cc-48e99469aba4",
   "metadata": {},
   "source": [
    "### How Much Noise To Add? (in English)\n",
    "\n",
    "Let's start with an easy, intuitive answer:\n",
    "\n",
    "<img src=\"imgs/dp_enuf2hide.png\">\n",
    "\n",
    "In the image above, we haven't added enough noise to properly protect the person's privacy. We need to add more!\n",
    "\n",
    "\n",
    "<img src=\"imgs/dp_not_enuf.png\">\n",
    "\n",
    "This time, we went way overboard with adding noise. The Data Scientist is going to suffer a serious loss of accuracy in their calculations. We need to add less!\n",
    "\n",
    "What this should hopefully convey to you is that there is a **tradeoff** between the amount of noise we add, and the corresponding privacy and utility of the results we get from our algorithm.\n",
    "* If we too much noise, the results are no longer accurate, rendering the algorithm useless.\n",
    "* If we don't add enough noise, the results are accurate, but we aren't able to protect anyone's privacy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90557045-a9a9-4833-bace-014344e50407",
   "metadata": {},
   "source": [
    "### How Much Noise to Add? (in Math)\n",
    "\n",
    "\n",
    "DP is a mathematical guarantee, and so there is a mathematical answer to this question.\n",
    "But before we can answer this question of how much noise to add, we'll need to understand a key insight: **datasets are distributions.**\n",
    "\n",
    "\n",
    "This might seem a bit strange to some of you. Let's take a simple example.\n",
    "\n",
    "Imagine you had a dataset consisting of the numbers [1, 2, 3, 4 and 5].\n",
    "An easy way you could convert this from a dataset into a distribution is if you iterated through every datapoint in the dataset, and asked what was the probability of this number being in this dataset.\n",
    "\n",
    "You'd then get a graph that looks a lot like this:\n",
    "\n",
    "<img src=\"imgs/dp_datasets_distr.png\">\n",
    "\n",
    "\n",
    "Voila! Using this simple scheme, we've converted our dataset into a probability distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa3ac32-ee2c-4b70-8801-bbf9382dbc76",
   "metadata": {},
   "source": [
    "Now, you might ask- what was the point of that? Why did we need to convert our dataset into a distribution?\n",
    "\n",
    "Well, it turns out- there are lots of ways to compare two distributions! Here's 16 of them, just for illustration:\n",
    "\n",
    "<img src=\"imgs/dp_distr_comp.png\">\n",
    "\n",
    "This means we now have a way to compare two datasets- by converting them to distributions, and then comparing them using any of the methods shown in the image above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c49e3d-6b02-468b-a298-996d6b85ffda",
   "metadata": {},
   "source": [
    "You might ask- but Ishan, **Why is it important to compare datasets?** What does this have to do with figuring out how much noise we want to add?\n",
    "\n",
    "Well, let's revisit the definition of Differential Privacy:\n",
    "\n",
    "Differential Privacy: The outcome of an algorithm is ***similar*** when a single person's data is removed from a dataset.\n",
    "\n",
    "**Intuition:** As soon as we know how similar the outcomes are, we immediately know how much noise is enough, and how much is too much. And it's easier to calculate this similarity by thinking about our datasets as if they were distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2357300e-47c9-4ea7-a9a2-9037d96d630a",
   "metadata": {},
   "source": [
    "### Introducing $\\epsilon$, the privacy budget\n",
    "\n",
    "This \"similarity\" or difference is captured in a parameter called $\\epsilon$ (**epsilon**). It's also called the **privacy budget.**\n",
    "\n",
    "$\\epsilon$ has different formulas (depending on which method we used to compare our datasets/distributions), but it is always a measure of how much your data affects the outcome of the result:\n",
    "\n",
    "<img src=\"imgs/dp_intro_epsilon.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850121a3-82a6-4e47-85d2-f3597197b4c0",
   "metadata": {},
   "source": [
    "$\\epsilon$, or the privacy budget, is probably the most important idea in differential privacy, so it's worth taking some time to emphasize what is exactly is.\n",
    "\n",
    "\n",
    "The privacy budget, $\\epsilon$, is a measure of:\n",
    "* How much your data stands out\n",
    "    * Thus, it's also a measure of *privacy risk*; how likely your data is going to be identified\n",
    "* How much your data affects the outcome of the query or algorithm\n",
    "* How much noise is needed to hide your data's influence.\n",
    "\n",
    "**Note:** \n",
    "There is a mathematical definition of epsilon (see resources below), but thinking about it in this way helps to build intuition."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4385da44-0397-4eea-9c13-efbd7b71d864",
   "metadata": {},
   "source": [
    "### Effects of $\\epsilon$\n",
    "\n",
    "**The higher the $\\epsilon$, the more your data affects the outcome of an algorithm.**\n",
    "\n",
    "<img src=\"imgs/dp_epsilon_eff1.png\">\n",
    "\n",
    "For example:\n",
    "* Imagine if we're trying to calculate the net worth of all the people living inside a single city, and we did this for every city in the US. Warren Buffet and Elon Musk would have gigantic values of $\\epsilon$, whereas someone who's homeless probably has a much lower $\\epsilon$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5fa7aa-b51d-4246-814c-982cbe2e4f4b",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b6b04f-1c7f-46ba-8a46-e84e84cfab1e",
   "metadata": {},
   "source": [
    "**The higher the $\\epsilon$, the more noise needs to be added to protect your privacy.**\n",
    "\n",
    "This should make intuitive sense:\n",
    "* As we discussed above, the higher the epsilon, the more your data affects the outcome of an algorithm.\n",
    "* The more your data affects the outcome of an algorithm, the more noise you need to add to mask the effects of your data.\n",
    "\n",
    "<img src=\"imgs/dp_epsilon_eff2.png\">\n",
    "\n",
    "\n",
    "In theory, noise is a random value that depends on $\\epsilon$. In practice, we obtain it from sampling from a distribution where $\\epsilon$ is a parameter. \n",
    "\n",
    "Often, it's a normal (Gaussian) distribution where $\\epsilon$ affects the standard deviation.\n",
    "So the bigger the $\\epsilon$, the wider the range of values the noise will be likely be sampled from [1]:\n",
    "\n",
    "<img src=\"imgs/dp_sigma.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33970d9-4013-4738-be12-c622d403a0d8",
   "metadata": {},
   "source": [
    "[1]: We know this because of the empirical (68-95-99.7) rule in statistics, which says that when you sample a normal distribution, approximately 68% of the values will be within one standard deviation of the mean, 95% will be within 2 standard deviations of the mean, and 99.7% will be within 3 deviations of the mean, and so forth. (This rule is also how the company Six Sigma got its name! They aim to get manufacturing processes error rates to a six sigma rate.)\n",
    "\n",
    "<img src=\"imgs/dp_empirical_rule.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3b2597-9d9b-4a73-b730-69f9db35016f",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a77243-ed47-47a0-acd1-250501b15caf",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Final Intuition- Why does DP work?\n",
    "\n",
    "I'd like to leave you with a intuitive, gut feeling as to why differential privacy, this way of adding noise, actually works. \n",
    "\n",
    "The intuition is that when it comes to protecting privacy, your data \"hides\" in the background of other people's data. The more your data fits in with other people's data, the easier it is to blend in and hide in plain sight.\n",
    "\n",
    "Put it this way- it's much easier to spot the horse in the first image than the second one.\n",
    "\n",
    "<img src=\"imgs/dp_horse.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199df156-7b58-42bb-b69d-c96c62c62c45",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3026c3-c9ee-4318-8b47-9f8818a4eec8",
   "metadata": {},
   "source": [
    "Put it another way- the best way to hide a data point is to surround it with other, very similar data points! They'll be hard to tell apart, and it'll be like trying to look for a piece of **hay** in a very large, fluffy haystack:\n",
    "\n",
    "\n",
    "<img src=\"imgs/dp_haystack.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4222515c-d5b6-457e-a41f-5b0c84a78fbc",
   "metadata": {},
   "source": [
    "By adding noise, we're doing something very similar- we're making it hard to discern one data point from another; the same way how dumping all your hay in a haystack makes it hard to single out individual pieces of hay."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb8aa79-506f-4809-9d83-cdf7c7c6a1c7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "23b58aaf-7204-4e49-b09f-52f912ea2049",
   "metadata": {},
   "source": [
    "### Takeaways\n",
    "\n",
    "* Differential Privacy allows you to learn high level statistics and trends (how big is the haystack? Am I running out of hay? Is my hay on fire?) but not individual data (is the piece of hay in the center getting moldy?)\n",
    "    * You can answer questions such as \"What causes cancer?\" and not \"Does Walter White have cancer?\"\n",
    "* Differential Privacy works by adding noise to the output of an algorithm to protect privacy.\n",
    "* $\\epsilon$, the privacy budget, is an indicator of how likely it is that someone's data stands out and can be identified.\n",
    "    * The higher the $\\epsilon$, the more likely that person's data stands out and will be identified.\n",
    "    * $\\epsilon$ can be calculated in many ways, but it's always an indicator of the risk of being identified and having your privacy violated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ecaadf0-a248-4ff6-a1f3-8bf1ae57c54b",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42fbd93-ccb2-496f-8ca4-a487d322ec60",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Section 2: DP in PySyft\n",
    "\n",
    "The goal of this section is to help you understand the major components of the Differential Privacy system in PySyft, as well as how PySyft's DP system is different than regular DP systems elsewhere.\n",
    "\n",
    "\n",
    "\n",
    "Differential Privacy in PySyft is different in 3 crucial ways:\n",
    "\n",
    "1. It's **Adversarial**\n",
    "    - There is a hard limit on how much any data scientist who interacts with your dataset can learn about it.\n",
    "    - This limit is how much privacy budget ($\\epsilon$) the data owner gives them.\n",
    "    - For instance- the data owner gives you 5 $\\epsilon$ of privacy budget. Every time you'd like to get a result, it would cost you a few $\\epsilon$, and deduct from your available budget.\n",
    "2. It's **Individual**\n",
    "    - We track the privacy risk for **every individual in a dataset.** (every data subject.)\n",
    "    - This is useful because we know exactly how much each person's data and privacy is at risk.\n",
    "        - If the risk for any particular individual becomes too high, we can remove their data, and still use other people's data. This gives you more \"mileage,\" since you're able to wring out as much signal as possible from the dataset while still ensuring no one's privacy is blown.\n",
    "        - If a given algorithm violates any individual person's privacy too much, the data scientist gets penalized by having more $\\epsilon$ deducted.\n",
    "    - Note: [2]\n",
    "3. It's **Automatic**\n",
    "    - If you have enough privacy budget ($\\epsilon$), you can get the results of your algorithms without waiting.\n",
    "\n",
    "\n",
    "[2]: This is in contrast to regular Differential Privacy, where an entire dataset is characterized by a single $\\epsilon$. This is because regular DP only considers the privacy risk of the individual whose data is most at risk. (There's a good reason for this- as soon as one person's privacy is blown, you have a data leak and your infrastructure is by definition not secure.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec87748c-9c6e-44d7-8a7e-7a4c255fe0bb",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87779fd5-1b82-4540-8578-b858cf27b5b9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ace81797-ed29-4f2f-bac6-280175b10405",
   "metadata": {},
   "source": [
    "## PySyft's DP Scenario\n",
    "\n",
    "Let's say we have a Data Scientist. This person was given $\\epsilon$ = 10 of privacy budget to work with.\n",
    "The dataset they're using has 3 people's data in it- Rob, Bob, and Job.\n",
    "\n",
    "<img src=\"imgs/dp_scen.png\">\n",
    "\n",
    "\n",
    "Let's say Rob and Bob's data is both \"4\", and Job's data is \"6\".\n",
    "Although this dataset is small, we can intuitively tell that Job's data sticks out more than Rob's and Bob's. Thus, we expect his privacy to be more at risk, and any epsilon for Job to be higher.\n",
    "\n",
    "(The fact that PySyft is able to reason this way, and deduce privacy risk for each person in the dataset- is an example of its **individual** nature at work.)\n",
    "\n",
    "Let's say the Data Scientist wants to do a `sum()` operation:\n",
    "\n",
    "<img src=\"imgs/dp_indiv.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f67179-b5a2-4aba-a4d4-b34e6c829f0a",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a65be9-7e2d-4427-a9dc-37d894f0ffb9",
   "metadata": {},
   "source": [
    "## Components\n",
    "\n",
    "Awesome- now that we've seen the entire DP process, end to end, in PySyft, let's deep dive into the key components- **Tensors**, **Ledgers**, and **Publishing.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60274b5b-1b3a-4acd-a06f-091312ec39b9",
   "metadata": {},
   "source": [
    "### DP Tensors in PySyft\n",
    "\n",
    "The first (and arguably most used) component in our DP system are our custom Tensor classes.\n",
    "The biggest difference between our Tensor classes and your standard Torch.tensor() or np.array() is that our Tensors not only store data, but also store *metadata.*\n",
    "\n",
    "Let me explain. This is a regular Tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6aeab8d-ed9c-4bae-b93b-b4538b1ec255",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3., 4.])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.Tensor([1,2,3,4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc80f391-7f25-4f5b-9e75-b6abd32ec140",
   "metadata": {},
   "source": [
    "<br>\n",
    "This is a regular NumPy array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e5db996-1849-4518-9393-fc491bd24845",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.array([1,2,3,4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397a5255-42d4-4708-b593-5074e3034120",
   "metadata": {},
   "source": [
    "<br>\n",
    "As you can see, they both store the same data- [1,2,3,4]. They go a step further and let you do math with that data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0338fa1-dcef-426d-80d2-9af664a1f323",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 4., 5., 6.])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Tensor([1,2,3,4]) + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "235c9d45-a667-4774-9dbc-328bf2f5ff78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 4, 5, 6])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([1,2,3,4]) + 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48983eb0-7baf-439d-9802-ba2fa222248f",
   "metadata": {},
   "source": [
    "<br>\n",
    "And so on and so forth."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe32a77b-e9a5-4370-b8f4-ab5de2639413",
   "metadata": {},
   "source": [
    "Our DP Tensors in PySyft also provide this ability to store data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b576d5d-a001-4532-bf10-ce26d2aaae0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(child=[1 2 3 4])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import syft as sy\n",
    "sy.Tensor([1,2,3,4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8135683c-7a26-41fe-9e68-b2024d06127e",
   "metadata": {},
   "source": [
    "<br>\n",
    "... as well as do arithmetic on them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6cd0ff08-90c5-47f9-a014-1bc7848f2447",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(child=[3 4 5 6])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sy.Tensor([1,2,3,4]) + 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611c7632-7771-462d-8c02-038df867b964",
   "metadata": {},
   "source": [
    "<br>\n",
    "But there's one key difference. Our tensors also store metadata, which helps us figure out how much noise we should add to protect privacy.\n",
    "\n",
    "Specifically, we track 3 kinds of metadata:\n",
    "* a theoretical lower bound on the data held in the tensor\n",
    "* a theoretical upper bound on the data held in the tensor\n",
    "* the data subjects, or the people whose data is stored in the tensor (and thus whose privacy we're protecting).\n",
    "\n",
    "This metadata is provided by calling `.private()` on a Syft Tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5da54d7-150c-44db-b14e-60dcd89a0cd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(child=PhiTensor(child=[1 2 3 4], min_vals=<lazyrepeatarray data: [0] -> shape: (4,)>, max_vals=<lazyrepeatarray data: [5] -> shape: (4,)>))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sy.Tensor([1,2,3,4]).private(min_val=0, max_val=5, data_subjects=\"Ishan\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0347cb-9733-4080-abb6-d58e2cd3cafb",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Let's understand why each of these is necessary:\n",
    "\n",
    "**Knowing the upper and lower bounds of the data helps us figure out how much noise is too much and too little.**\n",
    "\n",
    "For instance, if I add 10 data points in the in the range  of [0, 10], and I add a noise value of 300, that will probably drown all the signal and skew the results heavily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d00fa41-3602-4fdb-bc03-a46c979f5716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signal = 33\n",
      "Noise = 300\n",
      "Final result after DP =  333\n"
     ]
    }
   ],
   "source": [
    "signal = sum([1,2,3,4,5,3,4,2,1,8])\n",
    "print(\"Signal =\", signal)\n",
    "noise = 300\n",
    "print(\"Noise =\", noise)\n",
    "result = signal + noise\n",
    "print(\"Final result after DP = \", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997c9908-fd9b-4522-989b-035222b219d7",
   "metadata": {},
   "source": [
    "On the other hand, if I add 10 data points in the range of [1,000,000 , 10,000,000], and I add a noise value of 50, that's probably too little noise to meaningfully protect anyone's privacy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98b7a946-20f7-40ee-ab69-59902d5745a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signal = 33000000.0\n",
      "Noise = 50\n",
      "Final result after DP =  33000050.0\n"
     ]
    }
   ],
   "source": [
    "signal = sum([1e6,2e6,3e6,4e6,5e6,3e6,4e6,2e6,1e6,8e6])\n",
    "print(\"Signal =\", signal)\n",
    "noise = 50\n",
    "print(\"Noise =\", noise)\n",
    "result = signal + noise\n",
    "print(\"Final result after DP = \", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912ac0e2-8790-4b71-a7ba-095c4cc3ad80",
   "metadata": {},
   "source": [
    "For those of you who've done signal processing before, this might look similar to the idea of **signal-to-noise.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba5aa6d-2283-4d69-825e-e69a15dfdfee",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Meanwhile, **knowing the data subjects helps us figure out whose privacy we're protecting.**\n",
    "\n",
    "This is tremendously useful when it comes to things like Linkage Attacks (refer to Lesson 01- the Netflix Challenge example.)\n",
    "If we're able to keep track of which data belongs to which person, we could quantify in strict mathematical terms ($\\epsilon$) how much that individual's privacy is at risk.\n",
    "\n",
    "\n",
    "\n",
    "Based on the number of Data Subjects in a Tensor, we can ***categorize*** our DP Tensors in 2 categories:\n",
    "\n",
    "* PhiTensor: 1 unique data subject per data point in the Tensor\n",
    "* GammaTensor: 2 or more uniqud data subjects per data point in the Tensor\n",
    "\n",
    "\n",
    "Let's try playing around with them!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "30d9d952-9c72-414f-a1bb-a62084fd729a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6, 4, 4, 6, 5],\n",
       "       [5, 4, 3, 2, 2],\n",
       "       [1, 6, 2, 6, 5],\n",
       "       [1, 5, 6, 6, 1],\n",
       "       [6, 4, 5, 5, 1]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's say we have some data:\n",
    "data = np.random.randint(low=1, high=7, size=(5,5))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0a9268e5-6d2c-4949-b18a-0286844332d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(child=[[6 4 4 6 5]\n",
       " [5 4 3 2 2]\n",
       " [1 6 2 6 5]\n",
       " [1 5 6 6 1]\n",
       " [6 4 5 5 1]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We put it in our Syft Tensor:\n",
    "tensor = sy.Tensor(data)\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f0c55940-0745-421a-945f-ed705af615f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(child=PhiTensor(child=[[6 4 4 6 5]\n",
       " [5 4 3 2 2]\n",
       " [1 6 2 6 5]\n",
       " [1 5 6 6 1]\n",
       " [6 4 5 5 1]], min_vals=<lazyrepeatarray data: [0] -> shape: (5, 5)>, max_vals=<lazyrepeatarray data: [10] -> shape: (5, 5)>))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We then annotate our Tensor with Metadata, thus creating a PhiTensor underneath the hood:\n",
    "private_tensor = tensor.private(min_val=0, max_val=10, data_subjects=\"Ishan\")\n",
    "private_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bcefcd6b-27f0-4f90-ab2a-bc8f7734911a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PhiTensor(child=[[6 5 1 3 3]\n",
       " [4 1 1 3 6]\n",
       " [4 1 3 3 6]\n",
       " [3 1 4 3 1]\n",
       " [2 4 2 3 5]], min_vals=<lazyrepeatarray data: [0] -> shape: (5, 5)>, max_vals=<lazyrepeatarray data: [10] -> shape: (5, 5)>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "private_tensor.child"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01b8bd8-0575-420d-9e4a-073e1a2dd26c",
   "metadata": {},
   "source": [
    "This is the first of our DP tensors- called a **PhiTensor**.\n",
    "A PhiTensor only has one unique data subject per value in the Tensor. You can see this below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7159b6e2-3d61-4bf8-b9ce-1c7026841eaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[DataSubjectArray: {'Ishan'}, DataSubjectArray: {'Ishan'},\n",
       "        DataSubjectArray: {'Ishan'}, DataSubjectArray: {'Ishan'},\n",
       "        DataSubjectArray: {'Ishan'}],\n",
       "       [DataSubjectArray: {'Ishan'}, DataSubjectArray: {'Ishan'},\n",
       "        DataSubjectArray: {'Ishan'}, DataSubjectArray: {'Ishan'},\n",
       "        DataSubjectArray: {'Ishan'}],\n",
       "       [DataSubjectArray: {'Ishan'}, DataSubjectArray: {'Ishan'},\n",
       "        DataSubjectArray: {'Ishan'}, DataSubjectArray: {'Ishan'},\n",
       "        DataSubjectArray: {'Ishan'}],\n",
       "       [DataSubjectArray: {'Ishan'}, DataSubjectArray: {'Ishan'},\n",
       "        DataSubjectArray: {'Ishan'}, DataSubjectArray: {'Ishan'},\n",
       "        DataSubjectArray: {'Ishan'}],\n",
       "       [DataSubjectArray: {'Ishan'}, DataSubjectArray: {'Ishan'},\n",
       "        DataSubjectArray: {'Ishan'}, DataSubjectArray: {'Ishan'},\n",
       "        DataSubjectArray: {'Ishan'}]], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This array has the same shape as our NumPy data- so there's a 1:1 correspondence.\n",
    "private_tensor.child.data_subjects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51da1f9-8a2a-435b-8b22-1a2955cc395a",
   "metadata": {},
   "source": [
    "If you add two PhiTensors belonging to different people, you would get a **GammaTensor**.\n",
    "This is shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa1860e-fa24-4c8f-a1c3-0f2b4f301ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "second_tensor = sy.Tensor(data).private(min_val=0, max_val=10, data_subjects=\"Carl\")\n",
    "\n",
    "gamma_tensor = private_tensor + second_tensor\n",
    "gamma_tensor.child"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4a465f-f74a-457b-b5ec-3d0217c27ae2",
   "metadata": {},
   "source": [
    "And you can see the data subjects in this array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798440cb-a9d5-4e16-aa77-ae51d753f08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma_tensor.child.data_subjects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6192d57-67d8-4de2-bfc5-20d1fee0f59b",
   "metadata": {},
   "source": [
    "There's one important thing to note here. Once we have a GammaTensor, we need to be extra careful since we are combining private data belonging to two different people in a single Tensor.\n",
    "\n",
    "We keep track of every operation that occurs with a GammaTensor in a dictionary called `source`. You can think of this as a tree keeping track of which input tensors combined to give which output tensors.\n",
    "\n",
    "The key in this dictionary is an integer (unique to every GammaTensor) which maps to the corresponding GammaTensor.\n",
    "\n",
    "We can see below how `gamma_tensor`, which was created by adding `private_tensor` and `second_tensor`, has both of those tensors in its `source` tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2770bb40-197c-4b02-8b8b-1daf2a68d161",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma_tensor.child.sources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199012b4-6458-4b1d-afd4-a4806590d0d3",
   "metadata": {},
   "source": [
    "GammaTensors also tracks which operation created it in `self.func_str`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0190ff-5aa5-409a-9ea3-7002cc604529",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma_tensor.child.func_str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de64acfd-a941-4630-a525-e6e914a46acd",
   "metadata": {},
   "source": [
    "Notes:\n",
    "\n",
    "- You might imagine that as we do more and more operations, this source tree can become gigantic. You're correct.\n",
    "- This is why we keep track of PhiTensors separately. Many data science workflows can and are being done with data belonging to just a single individual, in which case we don't need to take the precautions associated with GammaTensor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc45c901-9e98-47b9-bd7c-d2a1d3177453",
   "metadata": {},
   "source": [
    "### DP Ledger in PySyft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a613d7c-b431-4bf4-8877-0fbe3336cbe1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "21f2e8b8-4a5e-4bbe-8fd2-0b2354051ea8",
   "metadata": {},
   "source": [
    "### Publishing in PySyft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c142bb6-6eeb-45fa-9993-6fb95b45d307",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
